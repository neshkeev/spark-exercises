{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cb13da9-ab2b-420e-a122-616049d56c0a",
   "metadata": {},
   "source": [
    "# Spark History Server (SHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf9581b-c42d-4d5b-ab57-60b44a169552",
   "metadata": {},
   "source": [
    "## Мотивация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43c421c-fd73-42bf-b905-cd803a0f5ca7",
   "metadata": {},
   "source": [
    "Анализ производительности обычно выполняют при помощи Spark Web UI (Spark UI), который традиционно стартует на порту 4040 машины, на которой запущено приложение Apache Spark. Основная проблема при этом заключается в том, что Spark UI доступен пока доступно приложение. После завершения работы приложения все данные пропадают, что делает невозможным ретроспективный анализ приложений.\n",
    "\n",
    "**Spark History Server (SHS)** призван решить эту проблему. Основная идея заключается в том, что приложение Spark генерирует события, а внешний по отношению к приложению Spark сервер (**Spark History Server**) считывает эти события и визуализирует их аналогично Spark UI. Основное требование - выгрузка событий в директорию, которая доступна **Spark History Server**. Для этих целей отлично подходит HDFS или S3. По умолчанию **SHS** стартует на порту `18080`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52be8336-b588-43ea-941c-7ad80f8fdfc6",
   "metadata": {},
   "source": [
    "Внешняя директория для логов должна быть создана заранее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f024be11-d9b5-447d-ad7d-d84f3d240086",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "hdfs dfs -mkdir -p /shared/spark-logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d5d516-349b-4412-972a-2d0ee8e8f9ae",
   "metadata": {},
   "source": [
    "## Конфигурация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869faa12-5b3f-408a-a085-08caf2e7252e",
   "metadata": {},
   "source": [
    "Чтобы начать использовать **Spark History Server**, необходимо добавить дополнительную конфигурацию как на стороне приложения, так и на стороне **Spark History Server**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29101659-491c-4706-8171-fbb57a1e9f4c",
   "metadata": {},
   "source": [
    "### Конфигурация Spark приложения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36706c4-c01e-499b-b522-4c0382eae46f",
   "metadata": {},
   "source": [
    "Необходимо разрешить **Spark** приложению логировать события, а также указать место, куда эти логи складывать:\n",
    "\n",
    "- `spark.eventLog.enabled` разрешает логирование событий,\n",
    "- `spark.eventLog.dir` указывает директорию для логов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73217b15-4ce2-4b00-adda-a08f02d933e9",
   "metadata": {},
   "source": [
    "### Конфигурация Spark History Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fc569e-198a-4013-840f-bd5cf6a8b7fd",
   "metadata": {},
   "source": [
    "**Spark History Server** должен знать, где находятся файлы с логами приложения. Для этого необходимо установить значение параметра `spark.history.fs.logDirectory`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435292c8-5d4c-44fd-beb8-870a66cde396",
   "metadata": {},
   "source": [
    "### Конфигурация приложений по умолчанию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca68cc7-73d7-45f7-b9d3-1ba89bc22d31",
   "metadata": {},
   "source": [
    "Традиционно параметры приложения указываются при помощи [`SparkSession.Builder#config`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.builder.config.html) при запуске приложения. Но это не единственный вариант передачи параметров, параметры можно передать через файл `$SPARK_HOME/conf/spark-defaults.conf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3178cbf6-1a10-490d-b02a-529c5ab66be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat ${SPARK_HOME}/conf/spark-defaults.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f22fec3-036e-4ed1-b797-136ddd396aac",
   "metadata": {},
   "source": [
    "Файл `$SPARK_HOME/conf/spark-defaults.conf` представляет собой текстовый файл в формате [`*.properties`](https://ru.wikipedia.org/wiki/.properties). При этом в дополнении к стандартному формату, можно использовать переменные окружения или системные переменные в значениях. Формат параметров можно найти в [документации](https://github.com/apache/spark/blob/39cc4abaff73cb49f9d79d1d844fe5c9fa14c917/sql/core/src/main/scala/org/apache/spark/sql/internal/VariableSubstitution.scala#L25)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71283b91-3932-4f64-abab-22f8cefaad9b",
   "metadata": {},
   "source": [
    "Параметры из файла `$SPARK_HOME/conf/spark-defaults.conf` будут автоматически добавлены к конфигурации каждого приложения, запускаемого на текущей машине. Файл `$SPARK_HOME/conf/spark-defaults.conf` может отсутствовать, пользователь при желании может создать этот файл самостоятельно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee50cedf-1427-4526-a35b-8bb64f92ba4e",
   "metadata": {},
   "source": [
    "## Запуск приложения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656445e6-846f-4ee2-88ca-2443a529b7cf",
   "metadata": {},
   "source": [
    "При корректной конфигурации **Spark History Server** будет не важно в каком режиме запущено приложение Spark: Local, Yarn, Mesos, k8s. Единственное требование, как было указано выше, $ - $ это выгрузка логов во внешнюю директорию (HDFS, S3 и т.д.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad78f7c-69a4-44dd-a9df-0a127c8ce423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1636a607-3cdd-41e0-963e-c243be19faa6",
   "metadata": {},
   "source": [
    "### Запуск приложения в локальном режиме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8486dc87-980f-4dcc-8810-f86afed636e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"Local History Server\")\n",
    "        .master(\"local\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2293a3-c548-45b5-abb8-857b46808fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_dir = spark.conf.get(\"spark.eventLog.dir\")\n",
    "status = f\"{external_dir}\" if spark.conf.get(\"spark.eventLog.enabled\") == 'true' else \"запрещен\"\n",
    "\n",
    "print(f\"Экспорт логов: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ee9e8a-97c4-4589-ab7e-9fbf563929b2",
   "metadata": {},
   "source": [
    "Команда выше показывает, что выгрузка логов выполняется в директорию `/shared/spark-logs` на HDFS, проверим состояние внешней директории:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfaeefe-c06c-4324-a0ec-cce8ece11b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "hdfs dfs -ls /shared/spark-logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b54744-7808-4f6f-9564-d23a4c9b68a5",
   "metadata": {},
   "source": [
    "Если открыть [`18080`](http://localhost:18080), то можно увидеть как завершенные, так и незавершенные приложения:\n",
    "\n",
    "- [завершенные приложения](http://localhost:18080/?showIncomplete=false),\n",
    "- [незавершенные приложения](http://localhost:18080/?showIncomplete=true)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3566ba-ee3b-4b16-8261-7ffe7b0c19af",
   "metadata": {},
   "source": [
    "Среди [незавершенных приложений](http://localhost:18080/?showIncomplete=true) можно увидеть приложение с именем (колонка `App Name`) **Local History Server** $ - $ текущее запущенное приложение."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df0d5bb-8d76-44e0-84fe-57244331bc0c",
   "metadata": {},
   "source": [
    "Запустим нагрузку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e100c7-e6d9-4455-b619-2384fc6f1880",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"select 'Hello, Local Mode Spark History Server!' as message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2872838d-5a71-43d4-b6e4-5ce7d9aaaf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dacd7db-28fc-4220-ab33-d00586529de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f55985a-450c-4f62-a42f-c2c53d12e2fd",
   "metadata": {},
   "source": [
    "### Запуск приложения на Yarn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f532c56e-1b63-4a33-bbc7-b56997542efb",
   "metadata": {},
   "source": [
    "В качестве демонстрации независимости **SHS** от режима работы приложений Spark, запустим приложение на `Yarn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa10bc25-af52-4bb6-adda-dc80d26666a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"Yarn Spark History Server\")\n",
    "        .master(\"yarn\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b0fb82-1451-4b2f-9544-e6228ee60727",
   "metadata": {},
   "source": [
    "Среди [незавершенных приложений](http://localhost:18080/?showIncomplete=true) можно увидеть приложение с именем (колонка `App Name`) **Yarn Spark History Server** $ - $ текущее запущенное приложение."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce9ec0b-674e-43b5-8b3b-1fdbd56f97b3",
   "metadata": {},
   "source": [
    "И выполним нагрузку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49b8bd8-9339-4bed-82b3-33fe3ad19a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"select 'Hello, Yarn Mode Spark History Server!' as message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e94507-f14f-423c-b8a9-ee5d9a69fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2b217f-92f6-4dd1-ac79-0723ac00e6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b273d61-da93-4d31-bad3-3410b1bc1cca",
   "metadata": {},
   "source": [
    "## Запуск Spark History Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7233e7d4-6b9d-41db-8a9e-43afd2d176b4",
   "metadata": {},
   "source": [
    "Может сложиться впечателние, что **Spark History Server** стартует автоматически при старте Spark приложения, но это не так. **Spark History Server** запускается при помощи команды `$SPARK_HOME/sbin/start-history-server.sh`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8266b5-5d3f-4ec8-908c-af569045a161",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -l $SPARK_HOME/sbin/start-history-server.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845b612a-39da-47f6-a6ac-0c2b79de804d",
   "metadata": {},
   "source": [
    "Текущий сетап организован таким образом, что среди docker сервисов есть сервис, который автоматически стартует **Spark History Server**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7258cf-730e-453a-a36b-18e010a0a71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose ps historyserver1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1713d76d-d298-4419-be92-bf70f7d23311",
   "metadata": {},
   "source": [
    "Процессы, запущенные в контейнере `historyserver1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300237ac-1c6f-4127-87e9-0da7f7f7dfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose top historyserver1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd5e92a-88f3-4ba7-9d54-60bd3f8dd5d2",
   "metadata": {},
   "source": [
    "Файл `/bin/entrypoint` является точкой входа (entrypoint) в контейнер, и запускается при старте контейнера.\n",
    "\n",
    "При старте контейнера `historyserver1` выполняется инициализация контейнера, а также и запуск **Spark History Server** при помощи команды `start-history-server.sh`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803eba4b-5b5d-4714-abcc-daa310e3ae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && HOST=historyserver1 execute \\\n",
    "grep 'start-history-server.sh' /bin/entrypoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe5adff-97ec-4dab-b234-35b2d762d5b9",
   "metadata": {},
   "source": [
    "## Высокая доступность Spark History Server $ - $ Spark History Server High Availability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7897c948-1d99-4fc2-9643-bdcb6d4edbda",
   "metadata": {},
   "source": [
    "**Spark History Server** не хранит состояние, вся его работа заключается в считывании событий с внешней директории и отрисовки Web UI. Поэтому для достижения высокой доступности (High Availability) можно просто запустить несколько **Spark History Server** серверов и поставить перед ними **Load Balancer**, например, `nginx`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35286cb5-f358-4006-a47e-498c80474d06",
   "metadata": {},
   "source": [
    "**Nginx** в этом случае может по кругу (Round Robin) перебирать запущенные **Spark History Server** серверы и направлять поступающие запросы. Текущий сетап содержит три **Spark History Server** сервиса и один сервис **Nginx** для балансировки нагрузки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddc0e0a-6d90-47aa-ae00-1dabe05a4320",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose ps nginx historyserver1 historyserver2 historyserver3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3a760a-387f-4e3e-a82e-2b9391b70b99",
   "metadata": {},
   "source": [
    "**Nginx** запущен на порту [8080](http://localhost:8080), поэтому можно работать с **SHS** через сервис `nginx`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52da1917-1606-4a3b-8434-54757d9f1f88",
   "metadata": {},
   "source": [
    "### Симуляция сбоев Spark History Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c9b5d5-4ec1-4f26-ae08-482bac23e973",
   "metadata": {},
   "source": [
    "**Spark History Server** может выйти из строя в любой момент, поэтому очень важно продолжать обслуживать клиентов независимо от сбоев. Так, если часть серверов **Spark History Server** доступны, то необходимо перенаправлять запросы им."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ed9fde-c4c1-4f8b-bac0-10e9447ed5c6",
   "metadata": {},
   "source": [
    "В качестве симуляции сбоя поставим `historyserver1` на паузу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22071775-8370-4617-be53-e4ac21e6f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose pause historyserver1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bae14c1-14a7-48ad-83cd-7739affe76e9",
   "metadata": {},
   "source": [
    "Сервис `historyserver1` находится на паузе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3233441e-0f47-4799-a4cc-8c5eeaaaf601",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose ps nginx historyserver1 historyserver2 historyserver3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb926fa-9f52-4b80-9ab7-e9f4113f25a7",
   "metadata": {},
   "source": [
    "При этом запросы к `nginx` по порту [8080](http://localhost:8080) по прежнему отрабатывают. В демонстрационных целях таймаут на ответ от сервера ограничен пятью секундами, поэтому необхдимо подождать, т.к. `nginx` автоматически будет перенаправлять запросы живым серверам при наступлении таймаута. По умолчанию Nginx использует 120 секунд (две минуты) в качестве значения таймаута."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d546d3-de75-4eea-995b-e9e9cccaa0ca",
   "metadata": {},
   "source": [
    "**Spark History Server** запущен на трех сервисах, а значит вполне можно потерять 2 сервиса без вреда для клиентов. В качестве симуляции нового сбоя поставим `historyserver2` на паузу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478e3d37-6416-408e-ad2b-05a0ac90a8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose pause historyserver2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685195a5-d052-4d01-a567-5cdc37bb5495",
   "metadata": {},
   "source": [
    "Теперь два из трёх **SHS** сервисов находятся на паузе (симулируют сбой):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fd22de-668c-44f3-9689-d36027e28c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose ps nginx historyserver1 historyserver2 historyserver3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247f530e-d1b4-407e-9b2d-763b588192e2",
   "metadata": {},
   "source": [
    "При этом запросы к `nginx` по порту [8080](http://localhost:8080) по прежнему отрабатывают: все запросы уходят на сервис `historyserver3`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd9f8cc-7a5a-472c-af3b-48d136385483",
   "metadata": {},
   "source": [
    "Если все три сервиса выйдут из строя, то **Spark History Server** перестанет быть доступным для клиентов. В качестве симуляции нового сбоя поставим `historyserver3` на паузу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b790bc-8e0b-4ba0-9413-ad882d67897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose pause historyserver3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349dc2bc-945f-472d-824c-9fb120f7fba6",
   "metadata": {},
   "source": [
    "Сейчас все три **SHS** сервиса находятся на паузе (симулируют сбой):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03caa334-f410-4613-998e-2cb65172d9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose ps nginx historyserver1 historyserver2 historyserver3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f0ff98-8d25-4265-97f1-637913303c21",
   "metadata": {},
   "source": [
    "Запросы к `nginx` по порту [8080](http://localhost:8080) невозможно обработать (`504 Gateway Time-out`), т.к. нет ни одного доступного **SHS** сервиса."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818dccfd-6028-4905-8237-9af51d80febc",
   "metadata": {},
   "source": [
    "Восставновление работы **SHS** сервисов вернет клиентам доступ к **Spark History Server**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02a47d2-9158-481c-bdb6-68440172aceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose unpause historyserver1 historyserver2 historyserver3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9eea59-d6ba-4038-82c4-7253eb47f2ac",
   "metadata": {},
   "source": [
    "Все три **SHS** сервиса доступны (сняты с паузы):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8941e34-f812-48ed-aae2-71c1a6a4f0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose ps nginx historyserver1 historyserver2 historyserver3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5cc675-1b6b-4acb-8b92-af9ef0d4d2c7",
   "metadata": {},
   "source": [
    "Запросы к `nginx` по порту [8080](http://localhost:8080) обрабатываются в штатном режиме."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721bc35b-634a-4a42-9683-9d6c35b70e2d",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541097a4-b48b-4f8b-927b-41a201a92a32",
   "metadata": {},
   "source": [
    "Анализ рабочей нагрузки (workload) играет ключевую роль в оптимизации производительности запросов. Очень важно уметь анализировать как активную нагрузку, так и исторические показатели. **Spark History Server** позволяет решить задачу анализа активных и ретроспективных задач. Основной недостаток **Spark History Server** заключается в небольшом оставании по времени визуализируемых данных, т.к. **SHS** необходимо обнаружить новые данные, а также потратить некоторое время на разбор файлов с логами. С другой стороны надежность **SHS** и простота его запуска в режиме высокой доступности делает его пригодным для эксплуатации в продуктовом окружении."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0ef1fe-96d3-4ada-b2ed-e58486981477",
   "metadata": {},
   "source": [
    "## Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55179a5c-7187-4b4a-a6f8-c5005cbb99f6",
   "metadata": {},
   "source": [
    "1. Запустить приложение со своим именем в режиме Yarn.\n",
    "\n",
    "<details>\n",
    "    <summary>Ответ</summary>\n",
    "\n",
    "1. Запустить\n",
    "```python\n",
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"Nikita's Yarn Spark Application\")\n",
    "        .master(\"yarn\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "2. Как через **Spark History Server** определить сколько воркеров доступно приложению?\n",
    "\n",
    "<details>\n",
    "    <summary>Ответ</summary>\n",
    "\n",
    "1. Найти приложение `Nikita's Yarn Spark Application` в списке приложений http://localhost:8080/\n",
    "1. Открыть вкладку Executors\n",
    "1. В разделе Executors в таблице находится три строки: 1 драйвер и 2 воркера\n",
    "\n",
    "**Ответ**: 2 воркера доступны приложению.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0bca41-8ca5-4712-ba12-740276635c87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
