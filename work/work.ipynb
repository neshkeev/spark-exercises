{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70023ab8-acb1-4cfa-b26c-f32086af657d",
   "metadata": {},
   "source": [
    "# Spark Advanced - Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a64d4f-101a-4ab8-8ba0-156cd848264f",
   "metadata": {},
   "source": [
    "## Мотивация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3fdbb9-f11b-47d3-9a43-d66a8f63a20f",
   "metadata": {},
   "source": [
    "При работе с Apache Spark соединения (Joins) являются одной из самых популярных операций, поэтому очень важно понимать как Apache Spark выполняет такие запросы, а также уметь анализировать результаты исполнения запросов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f069df97-ef1b-4bea-a863-d8e5a8adc15c",
   "metadata": {},
   "source": [
    "## Запуск приложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad78f7c-69a4-44dd-a9df-0a127c8ce423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark import StorageLevel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4ac936-4498-41a3-b7ef-07283b6cd1e4",
   "metadata": {},
   "source": [
    "### Создание сессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad143f9f-f53e-4010-926a-21ef7e7ebfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"Joins\")\n",
    "        .master(\"local[4]\")\n",
    "        .config(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")\n",
    "        .config(\"spark.sql.warehouse.dir\", \"/tmp/spark-warehouse\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2c143f-a46d-4fb1-beae-3df5cbe8aeea",
   "metadata": {},
   "source": [
    "Spark UI доступен на порту [4040](http://localhost:4040)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742667e7-b3fe-438e-9ee8-9d0990f1b063",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a63198-3574-4503-a228-4a998bd93f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd /tmp && rm -rf steam && rm -rf /tmp/spark-warehouse && unzip ~/work/data/steam.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58576d6a-16ac-4f8b-8c97-407dd2691f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setJobDescription(\"Разбить датафреймы на 8 партиции\")\n",
    "spark.read.parquet(\"/tmp/steam/games.parquet\").repartition(4).write.mode(\"overwrite\").parquet(\"/tmp/steam_partitions/games\")\n",
    "spark.read.parquet(\"/tmp/steam/details.parquet\").repartition(4).write.mode(\"overwrite\").parquet(\"/tmp/steam_partitions/details\")\n",
    "spark.read.parquet(\"/tmp/steam/tags.parquet\").repartition(4).write.mode(\"overwrite\").parquet(\"/tmp/steam_partitions/tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3db58f2-b5a1-4e05-9a22-7a069ff5eaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setJobDescription(\"Загрузка датафрейма\")\n",
    "games = spark.read.parquet(\"/tmp/steam_partitions/games\")\n",
    "details = spark.read.parquet(\"/tmp/steam_partitions/details\")\n",
    "tags = spark.read.parquet(\"/tmp/steam_partitions/tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af069c6b-cf8a-4fd9-ac4c-83eb13cebd06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "games.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2794aa-065f-42ec-90bd-5df4d0ac2bbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "details.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e24932-ed0c-4366-9599-9cdea340c2c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tags.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65292b2-3fb6-4251-acb7-4f2a8eb95b81",
   "metadata": {},
   "source": [
    "## Оптимизация через анализ потребления ресурсов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77df46d2-35d3-49f6-8fd0-43717da79edd",
   "metadata": {},
   "source": [
    "Два одинаковых по смыслу запроса могут показывать разницу в потреблении ресурсов. В качестве примера рассмотрим два запрос, которые отличаются лишь порядком соединения таблиц:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53d62c1-c9bc-49ba-86df-a3bbd461e544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc.setJobDescription(\"Соединение `details`, `tags`, `games`\")\n",
    "result = details \\\n",
    "  .join(tags, \"tag\") \\\n",
    "  .join(games, \"app_id\")\n",
    "result.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228cd626-3512-4918-a65f-1153677ba513",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setJobDescription(\"Соединение `details`, `games`, `tags`\")\n",
    "result = details \\\n",
    "  .join(games, \"app_id\") \\\n",
    "  .join(tags, \"tag\")\n",
    "result.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93936b9-b4ee-4082-82cc-535485f42525",
   "metadata": {},
   "source": [
    "Планы запросов доступны в Spark UI на вкладке [SQL / DataFrame](http://localhost:4040/SQL/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfffef7c-f538-43f8-b111-1bfec3d6bc10",
   "metadata": {},
   "source": [
    "Анализируя планы запросов, можно заключить следующее:\n",
    "\n",
    "- с диска читаются одни и те же файлы, но уже на первом перемешивании объем данных отличается по причине того, что соединяются разные таблицы:\n",
    "    - в первом запросе соединяются таблицы `details` и `tags` по колонке `tag` (ключ партиционирования),\n",
    "    - во втором запросе соединяются таблицы `details` и `games` по колонке `app_id` (ключ партиционирования).\n",
    "\n",
    "![](../imgs/spark-join-details-games-tags-exchange1.drawio.svg)\n",
    "\n",
    "- сортировка перед первым слиянием выполняется на разном объеме данных, что ведет к разному потреблению памяти;\n",
    "- на втором перемешивании партиционирование выполняется:\n",
    "    - по `app_id` в пером запросе,\n",
    "    - по `tag` во втором запросе.\n",
    "\n",
    "![](../imgs/spark-join-details-games-tags-exchange2.drawio.svg)\n",
    "\n",
    "- партиционирование по `tag` генерирует больше данных для перемешивания."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2572c178-e31a-4f54-9d33-3b36a8d752e6",
   "metadata": {},
   "source": [
    "Сравнение планов запросов с отображением основных отличий по таблице `details`:\n",
    "\n",
    "![](../imgs/spark-compare-plans.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d4b5f0-db7b-43a6-b204-0ce895742b18",
   "metadata": {},
   "source": [
    "## Порядок соединений (JOIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b0d289-f04e-4cf1-ad76-31f54c32c275",
   "metadata": {},
   "source": [
    "На примере выше было продемонстрировано, что Apache Spark не меняет порядок соединений таблиц: в каком порядке таблицы соеденены в тексте запроса, в том порядке они и будут соединены во время исполнения. Но одна из основных стратегий оптимизации заключается в определении наиболее оптимального порядка соединения таблиц."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fc20eb-4931-4cb0-bf87-0a93d81d9026",
   "metadata": {},
   "source": [
    "### Почему порядок соединений (JOIN) важен?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a110f4b-a80a-43ed-809d-031f3df50266",
   "metadata": {},
   "source": [
    "Рассмотрим следующий пример.\n",
    "\n",
    "Дано:\n",
    "\n",
    "1. Таблица `details` содержит 540 тысяч строк,\n",
    "1. Таблица `games` содержит 50 тысяч строк,\n",
    "1. Таблица `tags` содержит 441 строку,\n",
    "1. в таблице `games` только 12 тысяч игр поддерживают Mac OS.\n",
    "\n",
    "**Найти** оптимальный порядок join."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f9177e-6a59-4bda-9d25-8df9efa57d13",
   "metadata": {},
   "source": [
    "#### Порядок `details`, `tags`, `games`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d14172b-70c5-40c7-a690-14270f60cae9",
   "metadata": {},
   "source": [
    "1. после соединения `details` и `tags` получится 540 тысяч строк,\n",
    "1. результат предыдущего соединения соединяется с предварительно отфильтрованной таблицей `games` по признаку `mac`.\n",
    "\n",
    "В результате получится 145 тысяч строк, но на промежуточном этапе необходимо было перемешать 540 тысяч строк."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abfc1bc-33e1-4c7d-b34f-04c0aae670b5",
   "metadata": {},
   "source": [
    "#### Порядок `details`, `games`, `tags`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f0876c-9059-454d-8155-2793922dbe25",
   "metadata": {},
   "source": [
    "1. после соединения `details` с предварительно отфильтрованной таблицей `games` по признаку `mac` получится 145 тысяч строк,\n",
    "1. результат предыдущего соединения соединяется с `tags`.\n",
    "\n",
    "В результате получится 145 тысяч строк, но на промежуточном этапе необходимо было перемешать 145 тысяч строк.\n",
    "\n",
    "```\n",
    "540K / 145K = 3.72\n",
    "```\n",
    "\n",
    "**Уменьшение интернет трафика в 3.7 раза!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e877763-3b41-4ede-8f34-54a3a18e93f5",
   "metadata": {},
   "source": [
    "#### Порядок `games`, `tags`, `details`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f3f9d5-0ab4-4cf7-a99a-13d8bdf9d230",
   "metadata": {},
   "source": [
    "1. `games` и `tags` необходимо соединять декартовым произведением, т.к. у них нет общих колонок, получится 5.3 миллиона строк,\n",
    "1. результат предыдущего соединения соединяется с `games`.\n",
    "\n",
    "В результате получится 145 тысяч строк, но на промежуточном этапе необходимо было перемешать 5 миллионов строк.\n",
    "\n",
    "**Увеличение трафика в 10 раз по сравнению с первым вариантом!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3720c1b7-eef5-42e2-a181-0b976ddfa753",
   "metadata": {},
   "source": [
    "![](../imgs/spark-join-order.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8e58a2-8429-4a19-a8ff-94d6c2642c3a",
   "metadata": {},
   "source": [
    "#### Ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354abb9f-a2b7-44ab-a316-bbef990b5d18",
   "metadata": {},
   "source": [
    "Наиболее оптимальным порядком соединения является: (`details` + `games`) + `tags`.\n",
    "\n",
    "Таким образом, нужно стремиться к тому, чтобы на более ранних этапах отсекать как можно большее число строк\n",
    "\n",
    "> **Отсечение наибольшего числа строк на более ранних этапах - залог быстродействия запроса**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8e810e-caf6-4654-9494-f8b3e2ca310a",
   "metadata": {},
   "source": [
    "### Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefec5e9-25cf-490e-bfd1-a78fd9c7c5e0",
   "metadata": {},
   "source": [
    "1. Выполнить предыдущие три запроса с разным порядком таблиц в соеднении;\n",
    "1. Убедиться, что теоретические цифры соответствуют практическим цифрам."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bed739-773a-4d88-9140-939c42bd8eeb",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7946b935-7097-4447-8030-a07caacf993f",
   "metadata": {},
   "source": [
    "По умолчанию Apache Spark не применяет оптимизаций, связанных с порядком соединения таблиц, а значит пользователь должен сам решать какой порядок покажет наилучшую производительность."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278f27fd-23be-4d23-aa93-82b5eaf494ba",
   "metadata": {},
   "source": [
    "## Автоматический выбор наилучшего порядка соединения таблиц"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97219d31-22d2-4861-a4c1-472665de81ea",
   "metadata": {},
   "source": [
    "В Apache Spark 2.2 появился оптимизатор на базе стоимости (Cost Based Optimizer, CBO), который при помощи статистики может самостоятельно определить наилучший порядок соединения таблиц. По умолчанию он выключен:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590cd585-9065-48b4-8928-408009ab1cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Статус Cost Based Optimizer: {\"включен\" if spark.conf.get(\"spark.sql.cbo.enabled\") == \"true\" else \"выключен\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538470d4-f980-421b-a652-d9a74bbbd672",
   "metadata": {},
   "source": [
    "Основные задачи Cost Based Optimizer (CBO):\n",
    "\n",
    "- сбор, вывод и распространение статистики по таблицам, колонкам и промежуточным данными,\n",
    "- вычисление стоимости каждого оператора в терминах результирующего количества строк и размера итогового датасета,\n",
    "- выбора наилучшего плана исполнения на базе стоимости вычислений."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495c65a0-3fe0-4952-9485-3910fef4a6d3",
   "metadata": {},
   "source": [
    "### Активация CBO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d88abd-d373-418e-a953-e715899efa3a",
   "metadata": {},
   "source": [
    "Для включения оптимизатора на базе стоимости необходимо активировать опцию: `spark.sql.cbo.enabled`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b023daab-e2b9-4fa9-b048-47692fd46e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.cbo.enabled\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf5eea5-f937-4a1e-b9bf-f8198e5f65b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Статус Cost Based Optimizer: {\"включен\" if spark.conf.get(\"spark.sql.cbo.enabled\") == \"true\" else \"выключен\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8626c49-c209-4fff-b0b0-0ad881de4056",
   "metadata": {},
   "source": [
    "**Замечание:** Cost Based Optimizer можно включать и выключать во время работы приложения сколько угодно раз."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3e4a0b-2200-48a5-b241-22a27c73beec",
   "metadata": {},
   "source": [
    "### Активация автоматического поиска оптимального порядка таблиц"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81153eb-bc46-41fd-9f84-521dd371aa19",
   "metadata": {},
   "source": [
    "Для активации автоматического определения наилучшего порядка соединения таблиц в дополнении к опции `spark.sql.cbo.enabled` необходимо активировать еще опцию `spark.sql.cbo.joinReorder.enabled`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2fd0dd-b85c-4066-a7cf-b4d6c2d4a656",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.cbo.joinReorder.enabled\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fc6a3a-8e1c-459f-ab82-98391bb036b9",
   "metadata": {},
   "source": [
    "Поиск оптимального порядка таблиц в соединении выполняется при помощи динамического программирования, алгоритмы которого обычно имеют квадратичную сложность, поэтому авторы CBO ограничили количество таблиц в запросе числом 12: если таблиц больше, то CBO не будет определять наилучшй порядок. Чтобы изменить это ограничение, необходимо указать желаемое число таблиц в опции `spark.sql.cbo.joinReorder.dp.threshold`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a07842-572a-4c61-96e3-a81da303526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.cbo.joinReorder.dp.threshold\", 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f8cd53-59a1-4d34-95bd-33914b81722f",
   "metadata": {},
   "source": [
    "### Активация статистики"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6957df16-9020-445a-b684-3b9b7be712af",
   "metadata": {},
   "source": [
    "CBO активно использует статистику, поэтому необходимо наилучшим образом ее подготовить. Для этого необходимо активировать еще две опции:\n",
    "\n",
    "- `spark.sql.statistics.histogram.enabled` для сбора статистики в виде гистограмы по каждой колонке,\n",
    "- `spark.sql.statistics.size.autoUpdate.enabled` для автоматического обновления статистики, когда появляются новые данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0f249e-bd28-4068-938b-1976eeef24ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.statistics.histogram.enabled\", True)\n",
    "spark.conf.set(\"spark.sql.statistics.size.autoUpdate.enabled\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4de739-9ffb-4f4c-90da-19899213fcd2",
   "metadata": {},
   "source": [
    "### Особенность работы CBO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5985ca0d-cc96-4062-a90f-35fb950cb857",
   "metadata": {},
   "source": [
    "Особенностью работы CBO является тот факт, что поиск оптимального порядка таблиц может выполняться только при использовании Spark SQL: DataFrame API не поддерживается\n",
    "\n",
    "> **CBO не работает с DataFrame API!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5747cf9-1706-4f35-8848-9cf4ed8ea39d",
   "metadata": {},
   "source": [
    "### Создание таблиц"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47592a6d-c5b7-4ae8-85a5-e368bd595dfc",
   "metadata": {},
   "source": [
    "Для сравнения с предыдущими экспериментами необходимо создать три таблицы: `games`, `details`, `tags`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8667559-8c1d-4baa-a306-d855228aab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS games\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS details\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c600338-f1a6-427e-9a0d-12e0ac225a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "games.write.mode(\"overwrite\").saveAsTable(\"games\")\n",
    "details.write.mode(\"overwrite\").saveAsTable(\"details\")\n",
    "tags.write.mode(\"overwrite\").saveAsTable(\"tags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf35712-46aa-4f3a-bcab-5b58ff70e198",
   "metadata": {},
   "source": [
    "### Сбор статистики"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c61b2a5-5a78-4f04-9fa3-3d83c0409d91",
   "metadata": {},
   "source": [
    "Сбор статистики выполняется как на уровне таблицы, так и на уровне колонок. Статистика сохраняется в metastore (Hive, Derby)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5110db-4043-4357-ac3f-0c14861851a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"ANALYZE TABLE games COMPUTE STATISTICS FOR ALL COLUMNS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3306f8-a262-4256-9a26-67a487e15b9e",
   "metadata": {},
   "source": [
    "Интересное наблюдение: статистика собирается немедленно.\n",
    "\n",
    "> **Статистика собирается сразу**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e395c3f-f29f-45f4-be3f-0cef00f6d8ea",
   "metadata": {},
   "source": [
    "### Получение статистики"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87205b68-9d08-47f5-a7f1-10d52377fef0",
   "metadata": {},
   "source": [
    "При помощи `DESC EXTENDED games <column_name>` можно получить статистику по одной колонке. В результате будет показана общая статистика: минимальные, максимальные значения столбца, количество уникальных значений и т.д.\n",
    "\n",
    "В дополнение также будет отображена гистограмма: все значения столбца разложены по определенным корзинам (bin), а для каждой корзины вычислены минимальное и максимальные значения, а также общее число элементов в корзине."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec96641-c28f-40ce-adbe-e791e4daa495",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"DESC EXTENDED games app_id\") \\\n",
    "  .repartition(1) \\\n",
    "  .withColumn(\"id\", F.monotonically_increasing_id()) \\\n",
    "  .where(col(\"id\").between(0, 21) | col(\"id\").between(250, 270)) \\\n",
    "  .show(40, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05677a2d-ab6b-4435-994f-b73e5896f7ad",
   "metadata": {},
   "source": [
    "Запрос ниже вычисляет минимальное и максимальное значения столбца `app_id`, которые в точности совпадают со значениями в статистике:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f6fa33-04fc-44c6-8854-bbdc1084e065",
   "metadata": {},
   "outputs": [],
   "source": [
    "games \\\n",
    "  .select(\n",
    "    F.min(col(\"app_id\")),\n",
    "    F.max(col(\"app_id\"))\n",
    "  ) \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1201b9fe-c5a4-4d5d-9e5d-88cf7d8af05a",
   "metadata": {},
   "source": [
    "### Сбор статистики для остальных таблиц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6361b6-9660-4847-9b44-d91c2d3da5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"ANALYZE TABLE details COMPUTE STATISTICS FOR ALL COLUMNS\")\n",
    "spark.sql(\"ANALYZE TABLE tags COMPUTE STATISTICS FOR ALL COLUMNS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a495edeb-496f-4727-8935-ceb52f7f6914",
   "metadata": {},
   "source": [
    "### Демонстрация работы CBO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5f3894-6897-47e7-80ab-220ffdb992a3",
   "metadata": {},
   "source": [
    "Выполним запрос из начала ноутбука:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d81e26-2d9e-4b93-8169-0491060b7004",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = spark.sql(\"\"\"\n",
    "  SELECT *\n",
    "    FROM details\n",
    "    JOIN tags USING (tag)\n",
    "    JOIN games USING (app_id)\n",
    "\"\"\")\n",
    "res.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e12bd62-b9c3-402f-ac6d-b5bbf8ec260f",
   "metadata": {},
   "source": [
    "Поменяем порядок соединения таблиц:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03581c0-8ff4-4bc9-8d17-e7809ed39946",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = spark.sql(\"\"\"\n",
    "  SELECT *\n",
    "    FROM details\n",
    "    JOIN games USING (app_id)\n",
    "    JOIN tags USING (tag)\n",
    "\"\"\")\n",
    "res.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2fb35f-6e1a-4b42-aacb-352d98eb7b41",
   "metadata": {},
   "source": [
    "Порядок соединения таблиц в физическом плане совпадает с предыдущим запросом. Таким образом, CBO считает наиболее оптимальным порядком соединения таблиц:\n",
    "\n",
    "1. соединить `details` и `tags`,\n",
    "1. соединить результат с `games`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867ca995-33af-4cb6-8000-4ba0ab9b672a",
   "metadata": {},
   "source": [
    "### Теоретическое обоснование пользы статистики"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a7c8ee-a7ac-4459-aaf1-38564cd796a0",
   "metadata": {},
   "source": [
    "Статистика собирается как для всей таблицы, так и для каждой колонки. Собранная статистика по колонке раскладывается по корзинам (bin). У каждой корзны есть своя статистика, что позволяет отбрасывать корзины и строки, которые в них попали, при анализе запросов с фильтрами (`<`, `>`, `=`, `!=`, `BETWEEN`, `IN` и т.д.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377548e2-c2ec-4fa0-9113-388774fd965e",
   "metadata": {},
   "source": [
    "Особенность корзин заключается в том, что они хранят примерно одинаковое число значений, т.е. пространство значений столбца разбивается на неравные промежутки.\n",
    "\n",
    "На картинке ниже приведен пример:\n",
    "\n",
    "- тип элементов: `long`,\n",
    "- количество значений в колонке: 17\n",
    "- количество корзин гистограммы: 4\n",
    "- среднее (медиана) число элементов в корзине: 4\n",
    "\n",
    "![](../imgs/spark-statistics-bins.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6628c9-b18e-43cc-9b98-b33b01d4345b",
   "metadata": {},
   "source": [
    "#### Сравнение колонки с константой"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8026772b-d3b7-433c-b7b8-54e44172d9cd",
   "metadata": {},
   "source": [
    "Если имеется статистика, то для оценки числа строк в результате при сравнении колонки с константой, например, `A < 42`, возможны три варианта:\n",
    "\n",
    "1. минимальное значение колонки больше константы => ни одной строки не будет получено в результате,\n",
    "2. константа лежит в интервале от минимального до максимального значения колонки => количество строк в результате как процент от общего числа строк,\n",
    "3. константа больше максимального значения колонки => все строки попадают в результат.\n",
    "\n",
    "На картинке ниже можно увидеть результат сравнения колонки с константой:\n",
    "\n",
    "![](../imgs/spark-statistics-in-action-const.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c531d1ef-3a90-43dc-82e2-fd95f5fe1568",
   "metadata": {},
   "source": [
    "#### Сравнение двух колонок"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5fa982-744a-46fd-89ff-01495e9ebb41",
   "metadata": {},
   "source": [
    "Если сравниваются две колонки (`A < B`), то возможны 4 варианта:\n",
    "\n",
    "1. максимальное значение `A` меньше минимального значения `B` => все строки попадают в результирующее множество,\n",
    "2. максимальное значение `B` меньше минимального значения `A` => пустое множество,\n",
    "3. перекрытие множеств:\n",
    "    - минимальное значение `B` в интервале между минимальным и максимальным значениями `A` => в результате процент от общего числа строк,\n",
    "    - максимальное значение `B` в интервале между минимальным и максимальным значениями `A` (частный случай - вложение `B` в `A`) => в результате процент от общего числа строк.\n",
    "\n",
    "\n",
    "![](../imgs/spark-statistics-in-action-column.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054bb3f3-0645-432c-ad26-aa1d7efb510d",
   "metadata": {},
   "source": [
    "#### Общее число строк при соединении (JOIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eb8538-7e57-4813-b4cc-081b48942f3e",
   "metadata": {},
   "source": [
    "Для оценки соединения (join) двух таблиц:\n",
    "\n",
    "```sql\n",
    "SELECT *\n",
    "  FROM T\n",
    "  JOIN U ON (T.k1 = U.k1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe640491-5885-4545-9c73-235ff12091c4",
   "metadata": {},
   "source": [
    "можно оценить общее число строк в результате следующей формулой:\n",
    "\n",
    "$$\n",
    "|T \\Join U| = \\frac{|T| * |U|} {max(|T.k1|, |U.k1|)}\n",
    "$$\n",
    "\n",
    "где:\n",
    "\n",
    "- `|T|` - число строк в таблице `T`,\n",
    "- `|T.k1|` - число уникальных значений столбца `k1` в таблице `T`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e068aa5f-6e6c-4669-b513-b0e395e512cd",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b377b56-d76f-4ee4-a0ac-10f18dafc9e9",
   "metadata": {},
   "source": [
    "Поиск налучшего порядка соединения таблиц может быть нетривиальной задачей, особенно, когда запрос соедржит большое число таблиц. Оптимизатор на базе стоимости позволяет в автоматическом режиме определять наилучший порядок соединения таблиц, но работает он только в Spark SQL. Несмотря на это ограчение, можно использовать CBO для сравнения двух вариантов одного запроса для выработки интуиции при оптимизации запросов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d477f3-3439-4b97-9e20-bcd50c6f6d75",
   "metadata": {},
   "source": [
    "### Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e017eccd-3cce-428d-9cb8-a54ab90c47d7",
   "metadata": {},
   "source": [
    "Добавить различные фильтры `WHERE` в запросы с JOIN и проанализировать планы запросов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a7543e-f7e8-4b0c-828a-ecfce34eddbc",
   "metadata": {},
   "source": [
    "## Оптимизация на базе hint инструкций"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589cace5-0884-49ab-b15e-d43cc9e223dc",
   "metadata": {},
   "source": [
    "### Типы соединений (JOIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee51f8a-2295-4cb0-b77e-1e2944bf62e3",
   "metadata": {},
   "source": [
    "Существуют несколько алгоритмов соединения таблиц. Далее перечислены все алгоритмы от быстрого к медленному:\n",
    "\n",
    "| Имя | Описание | Особенности |\n",
    "|-----|----------|-------------|\n",
    "| BROADCAST | Скопировать наименьший по размеру датафрейм на каждый воркер и выполнить соединение с теми партициями, которые уже находятся на воркерах | Датафрейм не может превышать 10МБ (можно настроить), а также нужно следить за памятью. При увеличении числа воркеров, производительность запроса снижается (Почему?) |\n",
    "| HASH | Строки наименьшего по размеру датафрейма разложить по воркерам в HashMap, строки второго датафрейма отправить на воркеры и положить их в HashMap, если такой ключ существует. Из HashMap сформировать результирующий датафрейм | HashMap может занять очень много места в памяти, что может привести к OutOfMemoryError |\n",
    "| MERGE | Оба датафрейма сортируются и отправляются (shuffle) на воркеры. На каждом воркере хранится часть каждого датафрейма. После того, как все строки обоих датафреймов отправлены, на каждом воркере запускается merge алгоритм аналогичный [Алгоритму Сортировки Слиянием](https://ru.wikipedia.org/wiki/%D0%A1%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0_%D1%81%D0%BB%D0%B8%D1%8F%D0%BD%D0%B8%D0%B5%D0%BC) | Изначально данные сохраняются в раздел \"исполнение\" (execution) памяти воркера, но если места перестает хватать, то Apache Spark начинает выполнять спилы. Так оба датафрейма могут попасть на диск, что сильно снизит производительность алгоритма. Работает на данных любого размера. Принят в качестве алгоритма соединения (join) по умолчанию |\n",
    "| NESTED LOOP | Декартово произведение | Самый медленный, на практике не используется |\n",
    "\n",
    "> **MERGE JOIN - алгоритм соединения по умолчанию**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381f46b3-740b-4860-81af-f652d89cfe4b",
   "metadata": {},
   "source": [
    "### BROADCAST JOIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea73763-5aa3-4105-b0ef-03aab93c2f5f",
   "metadata": {},
   "source": [
    "На картинке ниже представлен `BROADCAST JOIN`, который выполняется за две стадии:\n",
    "\n",
    "1. **Broadcast Exchange** - отправить все партиции небольшого датафрейма на все воркеры,\n",
    "2. **Broadcast Merge Join** - выполнить локальную операцию соединения (join) на каждом воркере одновременно.\n",
    "\n",
    "![](../imgs/spark-broadcast-join.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf41fd7-07f8-4c5c-8463-a6465c4441a6",
   "metadata": {},
   "source": [
    "### HASH JOIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d132196-9ed4-418b-9f5d-121790cb61f2",
   "metadata": {},
   "source": [
    "На картинке ниже представлены основные стадии HASH JOIN, которые включают в себя:\n",
    "\n",
    "1. перемешивание (Exchange, Shuffle) меньшего по размеру датафрейма по ключу соединения (JOIN),\n",
    "2. создание HashMap на базе полученных данных,\n",
    "3. перемешивание (Exchange, Shuffle) второго датафрейма с немедленным отсечением строк, для которых нет значения в созданном на предыдущем шаге к HashMap по ключу соединения (join),\n",
    "4. создание результирующего датафрейма на базе HashMap по записям, для которых нашлись пары в обоих датафреймах по ключу хеширования/соединения.\n",
    "\n",
    "![](../imgs/spark-hash-join.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69bc003-e7ac-4fb1-af1f-217c341011ca",
   "metadata": {},
   "source": [
    "### SORT MERGE JOIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3223d6c8-b9f7-447c-bec1-a5d6b95c86a0",
   "metadata": {},
   "source": [
    "На картинке ниже представлены основные стадии Sort Merge Join:\n",
    "\n",
    "- перемешивание обоих датафреймов по ключу соединения,\n",
    "- сортировка на каждом воркере одновременно,\n",
    "- слияние отсортированных датасетов (time: `O(N)`, space: `O(1)`),\n",
    "- создание результрующего датафрейма по ключам, которые нашлись в обоих отсортированных датафреймах.\n",
    "\n",
    "![](../imgs/spark-sort-merge-join.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb52ac6-7b9c-47ef-9185-e900e68b0e15",
   "metadata": {},
   "source": [
    "### Настройка типа соединения (JOIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605ab58b-e5a8-4b40-bc4f-e2a92ffcaacc",
   "metadata": {},
   "source": [
    "Как было указано выше Apache Spark использует Sort Merge JOIN в качестве алгоритма по умолчани, т.к. он позволяет гаратировано обработать данные любого размера.\n",
    "\n",
    "Но на датафреймах небольшого размера предпочтительно использовать HASH JOIN, если есть гарантии, что этот датафрейм не будет расти.\n",
    "\n",
    "Для того, чтобы указать тип соединения, можно воспользоваться [hint](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.hint.html)-инструкциями (хинтами)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d0cb6b-b174-4bdf-b565-4c37f6ffde1f",
   "metadata": {},
   "source": [
    "В качестве примера рассмотрим следующий запрос:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206da7d2-dffd-4973-b5cd-b5a572400c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "details.join(tags, \"tag\").explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9002dde3-3dcf-49ef-8d77-5880a4dcca6f",
   "metadata": {},
   "source": [
    "План запроса показывает, что Apache Spark будет выполнять его при помощи `SortMergeJoin`. Учитывая, что датафрейм `tags` является небольшим и вряд ли в будущем будет сильно расти, можно выбрать HASH JOIN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff81888-9593-49cf-a475-d41a14d9dd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "details.join(tags.hint(\"SHUFFLE_HASH\"), \"tag\").explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefcdc57-98b1-47e4-bc51-4f5c14072406",
   "metadata": {},
   "source": [
    "В плане выше можно заметить, что Apache Spark будет выполнять этот запрос при помощи `ShuffledHashJoin`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80463cac-9d2e-4ea6-bd66-f922e639d849",
   "metadata": {},
   "source": [
    "Можно пойти еще дальше запросить BROADCAST join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a5dc08-782a-4ec2-8856-6a2e9e78ef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.hint(\"BROADCAST\").join(details, \"tag\").explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dd1d30-83a2-497d-a277-16a6265dada9",
   "metadata": {},
   "source": [
    "### Настройка соединений в Spark SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cb39b2-e3e0-4c03-b4eb-a57fef8150d7",
   "metadata": {},
   "source": [
    "Хинты можно применять и в Spark SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a182dc0b-f29b-4c80-a242-2e27292063a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM details JOIN tags USING (tag)\").explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b567a6-8690-46e2-9002-9010f1fe22d7",
   "metadata": {},
   "source": [
    "Apache Spark использует `SortMergeJoin` по умолчанию. Чтобы выбрать другой алгоритм необходимо указать его в хинте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c96b9e-56c0-459b-bf71-516b80191fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT /*+ SHUFFLE_HASH(t) */ * FROM details d JOIN tags t USING (tag)\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c63315d-911f-47c4-ad98-9b8e3ea1a763",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT /*+ BROADCAST(t) */ * FROM details d JOIN tags t USING (tag)\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1727c4-f10c-4069-9a89-26b138a41d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT /*+ SHUFFLE_REPLICATE_NL(t) */ * FROM details d JOIN tags t USING (tag)\").explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec4169f-0b8e-4c4d-81e8-6b1045a65935",
   "metadata": {},
   "source": [
    "### Количество промежуточных партиций"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f9ecb4-578b-457a-b5b6-40f0afdac266",
   "metadata": {},
   "source": [
    "Результатом соединения таблиц будет новый датафрейм, в котором количество партиций определяется значением опции `spark.sql.shuffle.partitions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8894465-c95b-40cf-b380-924fb5753b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'После JOIN любой датафрейм будет иметь {spark.conf.get(\"spark.sql.shuffle.partitions\")} партиций')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdfcc71-3e2d-4448-88ed-258371f034df",
   "metadata": {},
   "source": [
    "Нужно учитывать тот факт, что некоторые партиции могут быть пустыми."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df68d306-52aa-45b1-9d39-d29da5353d7e",
   "metadata": {},
   "source": [
    "Значение по умолчанию принято 200, но на практике почти всегда это значение является неверным и можно получить результат быстрее, если это значение изменить."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734b79e7-6532-4a4f-90ee-ec6fb5a323fb",
   "metadata": {},
   "source": [
    "### Как определить нужное число партиций?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e91d64c-3196-40f5-b3a0-f8ec15a395d1",
   "metadata": {},
   "source": [
    "Оптимальное значение `spark.sql.shuffle.partitions` нужно подбирать под каждый запрос, т.е. нужно добавлять `spark.conf.set(\"spark.sql.shuffle.partitions\", X)` перед запросом, где `X` вычисляется по следующей формуле:\n",
    "\n",
    "$$\n",
    "X = \\frac {Stage Input Data} {200МБ}\n",
    "$$\n",
    "\n",
    ", где\n",
    "\n",
    "- $StageInputData$ - объем данных на входе стадии,\n",
    "- `200МБ` - оптимальный объем партиции в Apache Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6de1546-c205-4bf8-ba46-3ca8b9348337",
   "metadata": {},
   "source": [
    "**Дано**:\n",
    "\n",
    "- 100 воркеров,\n",
    "- 32ГБ оперативной памяти на воркер,\n",
    "- 20 CPU на воркере,\n",
    "- размер данных на входе (Stage Input Data) = 210ГБ.\n",
    "\n",
    "**Найти**: оптимальное значение для `spark.sql.shuffle.partitions`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b44979-928a-4937-84c8-bfc1224a7180",
   "metadata": {},
   "source": [
    "**Решение**\n",
    "\n",
    "Примем за оптимальный размер партиции 200МБ.\n",
    "\n",
    "Тогда:\n",
    "\n",
    "```\n",
    "210ГБ / 200МБ = 1050 партиций всего\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072b62b0-fc57-4d92-a401-11fb0f6f5f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 1050)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514fcccc-b62e-4706-862a-17f76bd576e3",
   "metadata": {},
   "source": [
    "Но у нас в кластере количество CPU равно 2000 ($100\\spaceворкеров \\times 20\\space CPU$), поэтому нужно установить значение 2000, чтобы равномерно загрузить кластер:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e978b4a4-a2ab-46df-b9c8-82e15a6f4cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb83a85-0410-4db5-8b0a-3459a86ef18d",
   "metadata": {},
   "source": [
    "## Оптимизация перекошенных (ассиметричных, skew) партиций"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b078b4d-20a0-46f6-8d17-e47bb0476017",
   "metadata": {},
   "source": [
    "Перекос в данных по партициям сильно вредит производительности запроса, потому что:\n",
    "\n",
    "- вся работа разбивается на стадии (stage), которые выполняются друг за другом,\n",
    "- стадия (stage) разбивается на задания (task),\n",
    "- одно задание соответствует одной партиции датафрейма,\n",
    "- за один раз один воркер может обработать одно задание,\n",
    "- каждое задание (task) стадии должно быть обработано, чтобы стадия завершилась,\n",
    "- следующая стадия должна дождаться выполнения всех заданий предыдущей стадии.\n",
    "\n",
    "Таким образом, если существует очень большая партиция, то она будет препятствовать скорейшему завершению стадии."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa00c99-ba11-4322-baaa-37613b311e34",
   "metadata": {},
   "source": [
    "На картинке ниже приведен пример датафрейма с перекосом в распределении строк в пользу партиции `P1`:\n",
    "\n",
    "![](../imgs/spark-skew-partitions.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c246f0b9-43e2-4537-82c7-fab50050b617",
   "metadata": {},
   "source": [
    "При наличии трех воркеров обработка датафрейма на картике выше будет выглядеть следующим образом:\n",
    "\n",
    "![](../imgs/spark-skew-partitions-processing.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac99070-6898-4737-a893-9eea52443e9b",
   "metadata": {},
   "source": [
    "Из картики видно, что большую часть времени два воркера простаивало, т.к. необходимо было дождаться завершения обрабтки партиции `P1`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe7df34-f413-4d93-85dc-57f7fa053e1a",
   "metadata": {},
   "source": [
    "Интуитивно можно догадаться, что необходимо разбить большую партицию на части и обрабатывать их одновременно:\n",
    "\n",
    "![](../imgs/spark-skew-partitions-processing-fix.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061c3b19-9bb8-424a-afae-91f2346b62a3",
   "metadata": {},
   "source": [
    "Существует два способа борьбы с таким классом проблем при соединениях (join):\n",
    "\n",
    "- использование AQE,\n",
    "- ручная подготовка ключа (Salting)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f8f89d-edce-43dd-afe7-7fd6fb370119",
   "metadata": {},
   "source": [
    "### Использование AQE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b9ea36-1535-4517-9763-c930809afc59",
   "metadata": {},
   "source": [
    "#### Описание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4014cefd-9894-47ce-ab23-f1ba69808f8a",
   "metadata": {},
   "source": [
    "В Apache Spark 3.0 появился адаптивный оптимизатор (Adaptive Query Execution, AQE), который умеет автоматически обрабатывать проблемы с перекосом. Он активирован по умолчанию, но чтобы убедиться в этом необходимо выполнить следующую инструкцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792d9497-edea-4f26-a3e5-ba120226c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "active = \"Включена\" if spark.conf.get(\"spark.sql.adaptive.skewJoin.enabled\") == \"true\" else \"Выключена\"\n",
    "print(f'Автоматическая обработка перекошенных партиций: {active}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cf276b-5886-4875-aa76-94920f86bdb4",
   "metadata": {},
   "source": [
    "Если автоматическая обработка перекошенных партиций выключена, то включить ее можно таким образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e694718-7176-48a9-b252-332168d4cfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.adaptive.skewJoin.enabled\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bba629-6adb-4c6a-bfca-11d03403265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "active = \"Включена\" if spark.conf.get(\"spark.sql.adaptive.skewJoin.enabled\") == \"true\" else \"Выключена\"\n",
    "print(f'Автоматическая обработка перекошенных партиций: {active}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f204edf-fbf3-49f3-919a-9651f93bfe4c",
   "metadata": {},
   "source": [
    "Но просто активировать опцию `spark.sql.adaptive.skewJoin.enabled` недостаточно, необходимо активировать сам AQE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70028f9d-568f-4c12-b6c9-9d9127010c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.adaptive.enabled\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4070bfcf-f2d1-4c98-b92e-e5a0b9c316dc",
   "metadata": {},
   "source": [
    "По умолчанию AQE будет считать перекошенными не все партиции, а только те, которые выбиваются из ограничений:\n",
    "\n",
    "- партиция больше медианного (среднего) размера партиций в 5 раз,\n",
    "- партиция больше 250МБ в размере.\n",
    "\n",
    "Если оба ограничения должны быть превышены, то партиция будет считаться перекошенной."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07578b8d-01d4-4fca-be50-29751a6580d1",
   "metadata": {},
   "source": [
    "Оба ограничения можно настраивать:\n",
    "\n",
    "- `spark.sql.adaptive.skewJoin.skewedPartitionFactor` контролирует во сколько раз партиция должна быть больше средней, чтобы считаться перекошенной (skew),\n",
    "- `spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes` контролирует минимальный размер партиции для перекоса.\n",
    "\n",
    "На небольших данных может быть эффективнее обработать как есть, вместо того, чтобы активировать автоматическую обработку перекоса."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58286de-1e28-4460-9556-1474b21d17cf",
   "metadata": {},
   "source": [
    "AQE может добавить дополнительную Exchange операцию, но при этом Catalyst может найти более оптимальный план без дополнительной операции перемешивания, поэтому оптимизация skew join может не сработать. В версии Apache Spark 3.3 добавили дополнительную настройку `spark.sql.adaptive.forceOptimizeSkewedJoin`, которая вынудит Spark использовать план с дополнительной операцией Exchange."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0cd2be-e510-4a76-a1d5-415f0b5e88c7",
   "metadata": {},
   "source": [
    "**Внимание**: Оптимизация перекошенных партиций в Apache Spark находится в зачаточном состоянии, поэтому может не всегда работать. Например, если в запросе участвуют кэши, то оптимизация перекошенных партиций при помощи AQE не сработает."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebd3e34-f181-4449-a2c1-b5ad7c86de3d",
   "metadata": {},
   "source": [
    "### Ручная подготовка ключа"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8350863f-d122-4168-8627-57596afcaf79",
   "metadata": {},
   "source": [
    "#### Описание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429a7668-23fe-482d-9b05-2441f4d35fe3",
   "metadata": {},
   "source": [
    "Традиционным способом борьбы с перекошенными партициями является ручная подготовка ключа (salting). Идея следующая:\n",
    "\n",
    "- в соединении (join) участвуют две таблицы: \"правая\" и \"левая\";\n",
    "- в \"левой\" таблице для колонки соединения (в ней перекосом по данным) создается новая колонка с суффиксом `_1`, `_2`, `_3` и т.д. из заранее подготовленного списка суффиксов;\n",
    "- в \"правой\" таблице для колонки из соединения (в ней перекос по данным), создается новая колонка типа array, где перечислены все возможные значения колонки с суффиксом из левой таблицы;\n",
    "- правая таблица \"взрывается\" (`explode`) копиями по созданной колонке типа array;\n",
    "- соединение выполняется по новой колонке с двух сторон.\n",
    "\n",
    "![](../imgs/spark-salted-join.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9039aee0-f2b2-4376-ac39-d445b9d3c6fc",
   "metadata": {},
   "source": [
    "На картике выше цветом отображаются:\n",
    "\n",
    "- одинаковые значения `app_id`,\n",
    "- воркер на который попадет строка после перемешивания по `app_id_salted`.\n",
    "\n",
    "В целях облегчения восприятия картинки, строки со значениями 5, 9, 11, не были отображены на воркерах после перемешивания, т.к. они не попадут в финальный результат. Но для единообразия цветом показано на какие воркеры они бы попали."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e83b5f-5dfe-4dbc-ba93-b421084558eb",
   "metadata": {},
   "source": [
    "#### Демонстрация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546a764a-ed2d-458e-be5e-2262691488d9",
   "metadata": {},
   "source": [
    "Соединение (join) таблицы `details` и `games` будет выполняться по колонке `app_id`:\n",
    "\n",
    "- `details` - левая таблица,\n",
    "- `games` - правая таблица."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4df2650-9239-4c4d-ae91-49c701e19606",
   "metadata": {},
   "source": [
    "В \"левую\" таблицу `details` необходимо добавить новую колонку: `app_id_salted`, которая будет конкатенацией колонки `app_id` со случайным префиксом `_1`, `_2` или `_0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c3a3ec-3a83-440a-b568-c56b6d0dc014",
   "metadata": {},
   "outputs": [],
   "source": [
    "details_salted = details \\\n",
    "    .withColumn(\n",
    "        \"app_id_salted\",\n",
    "        F.concat(\n",
    "            col(\"app_id\"),\n",
    "            F.lit(\"_\"),\n",
    "            F.floor(F.rand() * 3))\n",
    "    )\n",
    "details_salted.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5205d7-5d48-4985-a627-50e8f7decb0a",
   "metadata": {},
   "source": [
    "В правую таблицу необходимо добавить колонку типа \"array\", а потом \"взорвать\" датафрейм по ней, чтобы получить дубликаты строк с колонкой `app_id_salted`, которая имеет все возможные значения суффикса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5a49f2-ff63-4a96-b9d3-342a096c0858",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_ids_salted = [\n",
    "    F.concat(col(\"app_id\"), F.lit(\"_\"), F.lit(x))\n",
    "    for x in range(3)\n",
    "]\n",
    "\n",
    "games_salted = games \\\n",
    "    .withColumn(\n",
    "        \"app_id_salted\",\n",
    "        F.explode(F.array(app_ids_salted))\n",
    "    )\n",
    "\n",
    "games_salted.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b605d5a3-e97a-4101-a0d9-9d5b91cf798d",
   "metadata": {},
   "source": [
    "Теперь вместо `app_id` ключом соединения (join) будет `app_id_salted`. После соединения лишние колонки нужно удалить:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2507677d-d2a8-42ea-8601-2e30bccf5ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_details = details_salted.join(games_salted, \"app_id_salted\") \\\n",
    "    .drop(games_salted.app_id) \\\n",
    "    .drop(games_salted.app_id_salted)\n",
    "games_details.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69701295-a29c-43cd-bd07-bf6e69ac2375",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_details.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d18de74-ea1d-4c23-8e60-ceb3d79b70dd",
   "metadata": {},
   "source": [
    "Обратите внимание, что [`explode`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.explode.html) является локальной операцией, поэтому необходимо убедиться, что \"взрываться\" будет меньшая по размеру таблица."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1ec8f3-e8ba-4d29-9c3c-4d1f2b8d32dc",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958b1b3e-0ceb-417f-b1b5-697e9d24627d",
   "metadata": {},
   "source": [
    "Несмотря на наличие AQE и его возможности по оптимизации перекошенных партиций, его возможности все ещё достаточно ограничены. Хотя ручная подготовка ключа и даст больший контроль над процессом, но оптимизатор Apache Spark постоянно улучшается и в будущем его возможности будут превосходить результаты с явной подготовкой ключа, т.к. это правило оптимизации будет работать вместе со всеми остальными правилами, что даст лучший эффект. Поэтому рекомендуется, периодически возвращаться к запросам с ручной подготовкой ключа после каждого нового релиза, и проверять можно ли отказаться от ручного способа подготовки ключа."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b1b47d-379d-4cf5-950d-3fcecc15dc86",
   "metadata": {},
   "source": [
    "### Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b9bd2-3c53-4a0b-a972-612b11dc9d99",
   "metadata": {},
   "source": [
    "Выполнить соединение:\n",
    "\n",
    "```sql\n",
    "SELECT *\n",
    "  FROM details d\n",
    "  JOIN tags t ON (d.tag = t.tag)\n",
    "```\n",
    "\n",
    "при помощи ручной подготовки ключа с использованием:\n",
    "\n",
    "- DataFrame API,\n",
    "- Spark SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cba31e-7ffd-4af4-801e-44f2332d7589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
