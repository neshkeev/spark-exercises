{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad78f7c-69a4-44dd-a9df-0a127c8ce423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39931ce-9294-4b87-980a-91f9d5763e5b",
   "metadata": {},
   "source": [
    "# Проверка доступа к Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d857969-9ec1-4b2b-8429-f8528dcbfa92",
   "metadata": {},
   "source": [
    "Hadoop стартует в однонодовом режиме: все демоны на одном компьютере. Демоны Hadoop:\n",
    "\n",
    "- демон [NameNode](http://localhost:9870) запущен на `9870` порту,\n",
    "- демон [DataNode](http://localhost:9864) запущен на `9864` порту,\n",
    "- демон [ResourceManager](http://localhost:8088) запущен на `8088` порту порту,\n",
    "- демон [NodeManager](http://localhost:8042) запущен на `8042` порту,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3d8ceb-8ccd-4fba-8032-e0c5d4973dfc",
   "metadata": {},
   "source": [
    "# Настройка количества воркеров"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fe54a9-d4e4-4939-93c0-b59e8aaed3ca",
   "metadata": {},
   "source": [
    "## Статическое число воркеров"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a8f7db-9baf-4cf2-86dd-858b38c2baaa",
   "metadata": {},
   "source": [
    "Число контейненров для воркеров можно настраивать через `spark.executor.instances` (по умолчанию 2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625005be-8db2-41b0-bf04-caaee092f020",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"Yarn Static Workers\")\n",
    "        .master(\"yarn\")\n",
    "        .config(\"spark.executor.instances\", 3)\n",
    "        .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9e3abe-90dd-4935-a0bb-844c25939897",
   "metadata": {},
   "source": [
    "Yarn выделит один контейнер для драйвера (Application Master) и `spark.executor.instances` контейнеров для воркеров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddbcc34-5271-4cca-88aa-3ec82ccd6183",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "yarn application -list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93434d72-207d-44fe-ad19-f02d89af6d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "yarn container -list $( \\\n",
    "    yarn applicationattempt -list $( \\\n",
    "        yarn application -appTypes SPARK -appStates RUNNING -list | awk '/application_/{print $1}' \\\n",
    "    ) | awk '/appattempt_/{print $1}' \\\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094d70a6-9e34-429f-8fe7-b35d9896cde1",
   "metadata": {},
   "source": [
    "Как и ожидалось, команда выше показывает, что для текущего приложения запущено 4 контейнера: `3 (spark.executor.instances) + 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803e665a-0bad-43ce-8a19-c3b320423ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185f26d3-3156-4aff-8f97-37c81043850c",
   "metadata": {},
   "source": [
    "## Динамическое число воркеров"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f92541d-4b0f-4951-ae39-0798684f56ed",
   "metadata": {},
   "source": [
    "Число контейнеров Yarn выделенных Spark приложению остается неизменным. Но для интерактивных нагрузок, потребность в ресурсах может появляться и исчезать, а значит приложение может отпускать ресурсы, чтобы другие приложения могли ими воспользоваться или запросить больше ресурсов, для более быстрого исполнения больших задач. На этот случай Apache Spark позволяет динамически запрашивать ресурсы в кластере."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04828419-5abc-47a6-bd59-2644a4dc0d07",
   "metadata": {},
   "source": [
    "### Способ активации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c643d055-de8e-486f-ae2d-fa269ae99c90",
   "metadata": {},
   "source": [
    "По умолчанию динамическое выделение ресурсов отключено на стороне Apache Spark. Для включения необходимо установить значение `True` в `spark.dynamicAllocation.enabled`.\n",
    "\n",
    "Дополнительно необходимо указать сколько контейнеров должно быть доступно всегда `spark.dynamicAllocation.minExecutors` (по умолчанию 0) и сколько можно запросить контейнеров всего `spark.dynamicAllocation.maxExecutors` (не ограничено)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397067c7-79ac-454b-b8ff-26ec15b1b89f",
   "metadata": {},
   "source": [
    "Если воркер не выполняет ниакой работы в течении `spark.dynamicAllocation.executorIdleTimeout` секунд (по умолчанию 60), то воркер удаляется."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9896919d-2101-48ec-be1a-b7a1666854bd",
   "metadata": {},
   "source": [
    "Если на воркере закешированы данные, то Apache Spark не будет его удалять, даже если он находится без работы дольше чем `spark.dynamicAllocation.executorIdleTimeout`. Для установки времени жизни воркеров с закешированными данными необходимо указать значение в секундах в `spark.dynamicAllocation.cachedExecutorIdleTimeout` (по умолчанию, бесконечно)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee93dec-7af1-4f94-aec1-a784a16b00b2",
   "metadata": {},
   "source": [
    "Указанные настройки должны быть установлены во время старта приложения и не могут меняться на всем протяжении жизни приложения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f60377-e5c0-45cd-8037-0db200306d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"Yarn Dymanic Workers\")\n",
    "        .master(\"yarn\")\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\n",
    "        .config(\"spark.dynamicAllocation.minExecutors\", 1)\n",
    "        .config(\"spark.dynamicAllocation.maxExecutors\", 4)\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\", 20)\n",
    "        .config(\"spark.dynamicAllocation.cachedExecutorIdleTimeout\", 60)\n",
    "        .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833741da-0694-41e0-a600-3d6f69731865",
   "metadata": {},
   "source": [
    "После старта приложения Yarn выделит один контейнер для драйвера (Application Master) и `spark.dynamicAllocation.maxExecutors` контейнеров для воркеров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d53b5b1-dbeb-41bf-a7bd-b73a2172b8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "yarn application -list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf86075-5039-4e28-bc8b-37735ff8f296",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "yarn container -list $( \\\n",
    "    yarn applicationattempt -list $( \\\n",
    "        yarn application -appTypes SPARK -appStates RUNNING -list | awk '/application_/{print $1}' \\\n",
    "    ) | awk '/appattempt_/{print $1}' \\\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485334e5-1844-4157-b0d2-0b87ad2e2066",
   "metadata": {},
   "source": [
    "Но по прошествии `spark.dynamicAllocation.executorIdleTimeout` останется один контейнер для драйвера (Application Master) и `spark.dynamicAllocation.minExecutors` контейнеров для воркеров:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4756a9f4-c7e1-4dd6-bee6-7b27dbf67462",
   "metadata": {},
   "source": [
    "Если подождать 20 секунд с момента старта приложения перед запуском следующей команды, то можно увидеть, что для текущего приложения запущено 2 контейнера: `1 (spark.dynamicAllocation.minExecutors) + 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d483d6e4-2d28-4394-bac3-eaa153599eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "yarn container -list $( \\\n",
    "    yarn applicationattempt -list $( \\\n",
    "        yarn application -appTypes SPARK -appStates RUNNING -list | awk '/application_/{print $1}' \\\n",
    "    ) | awk '/appattempt_/{print $1}' \\\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847d3426-cd5c-447a-867b-f14392f32f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffced7f-fb1a-43aa-aacd-4300c03cdbd6",
   "metadata": {},
   "source": [
    "## Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4290c0f8-54af-4a9b-a692-c0ed257e681e",
   "metadata": {},
   "source": [
    "Apache Spark позволяет гибко настроить приложение под любой тип нагрузки: как для интерактивной аналитики с динамическим выделением ресурсов, так и батчевой или стримовой нагрузки со статическим выделением ресурсов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d24a4f-6dc5-4638-b553-9375efb78cf5",
   "metadata": {},
   "source": [
    "## Задания"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b3f70e-81ca-443e-b65b-e7d009789345",
   "metadata": {},
   "source": [
    "1. Запустить Apache Spark приложение с настройками по умолчанию. Сколько контейнеров Yarn выделяет такому приложению?\n",
    "2. Запустить Apache Spark приложение с динамическим выделением ресурсов в соответствии со следующими требованиями:\n",
    "    - в ждушем режиме не должно быть ниодного контейнера для воркеров,\n",
    "    - максимальное число контейнеров 3,\n",
    "    - время работы контейнера в ждущем режиме две минуты.\n",
    "3. Запустить приложение с динамическим выделением ресурсов из предыдущего шага. При этом время жизни воркеров в ждущем режиме с закешированными данными должно не превышать 2 минуты 30 секунд. Поставить эксперимент и проверить на практике.\n",
    "\n",
    "<details>\n",
    "    <summary>Нужна помощь?</summary>\n",
    "\n",
    "    Ответы внизу страницы\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145eb7b9-399a-4920-96ae-e9278872e7ae",
   "metadata": {},
   "source": [
    "# Настройка памяти"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe87c233-1be0-4cc5-80d6-6f075b342737",
   "metadata": {},
   "source": [
    "## Выделение памяти в Yarn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e017f1e-fa04-4c46-bbff-2c471dfc5f33",
   "metadata": {},
   "source": [
    "Программист определяет объем памяти:\n",
    "\n",
    "- необходимый драйверу:\n",
    "    - в кластерном режиме через настройку `spark.driver.memory` (1GB по умолчанию),\n",
    "    - в клиентском режиме через настройку `spark.yarn.am.memory` (512MB по умолчанию),\n",
    "- необходимый воркеру через настройку `spark.executor.memory` (1GB по умолчанию). При этом каждому воркеру будет выделен объем памяти указанный в `spark.executor.memory`.\n",
    "\n",
    "**Внимание**: PySpark в ноутбуке можно запустить только в клиентском режиме!\n",
    "\n",
    "> PySpark работает только в клиентском режиме!\n",
    "\n",
    "Yarn выделяет ресурсы слотами: один слот содержит минимальный объем памяти. В соответствии с настройками приложение Apache Spark запрашивает определенный объем памяти, а Yarn выдаст число слотов, которое будет покрывать запрощенный объем."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8553f89b-ea02-48d8-8492-fbcaae28710a",
   "metadata": {},
   "source": [
    "Пример:\n",
    "\n",
    "Дано:\n",
    "\n",
    "- минимальный размер памяти: 1024MB\n",
    "- объем памяти для воркера 1500MB\n",
    "\n",
    "Найти: объем памяти одного воркера.\n",
    "\n",
    "Решение:\n",
    "\n",
    "Одного слота недостаточно, т.к. 1024MB < 1500MB, поэтому yarn выделит 2 слота. Итого у каждого воркера будет по $ 2 \\space слота \\times 1024MB \\space (минимальный \\space размер \\space памяти) = 2048MB$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237c08ac-a36f-4df6-b70d-d4652277b62b",
   "metadata": {},
   "source": [
    "### Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0a1920-47c0-4ecc-966e-66909567dee5",
   "metadata": {},
   "source": [
    "Сколько памяти выделит Yarn на запрос `32MB`, если минимальный размер слота раверн `512MB`?\n",
    "\n",
    "<details>\n",
    "    <summary>Ответ</summary>\n",
    "\n",
    "    выделится 1 слот, в котором 512MB (минимальный размер слота)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54927f24-0c1a-4331-a660-f43de74759cc",
   "metadata": {},
   "source": [
    "### Максимальный объем"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765039a6-3bee-42a3-b0eb-b3d22ee3a0a4",
   "metadata": {},
   "source": [
    "Yarn может обрабтать не любой запрос. Так, если запрос некоторое превышает пороговое значение, то Yarn откажет в обработке такого запроса."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b091d7f5-a58b-4c6c-ac78-d16e16c68d6a",
   "metadata": {},
   "source": [
    "Пороговое значение по умолчанию для Yarn является 8GB, даже при наличии свободных слотов Yarn не будет выпделять память за пределами этого значения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d43d5ea-f5f2-43de-955d-86928d018d81",
   "metadata": {},
   "source": [
    "## Настройка Yarn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7650ec54-36c6-4d64-acc1-f72564d088c0",
   "metadata": {},
   "source": [
    "[Настройка Yarn](https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-common/yarn-default.xml) выполняется через `yarn-site.xml` файл. В частности:\n",
    "\n",
    "- минимальный размер памяти в слоте настраивается через `yarn.scheduler.minimum-allocation-mb`,\n",
    "- максимальный размер памяти настраивается через `yarn.scheduler.maximum-allocation-mb`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e8a9c4-97b9-4ef0-b62b-f74e8e01ba96",
   "metadata": {},
   "source": [
    "В текущей конфигурации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3d5edd-fd47-4e35-80a8-0ff7762f2a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl -s http://${RESOURCEMANAGER_HOST}:8088/conf | grep 'yarn.scheduler.minimum-allocation-mb' | xmllint --format -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb298c8-6c7d-43b3-b598-faed49bb7520",
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl -s http://${RESOURCEMANAGER_HOST}:8088/conf | grep 'yarn.scheduler.maximum-allocation-mb' | xmllint --format -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0af3a4-7117-4d07-ae35-5a1208413dc0",
   "metadata": {},
   "source": [
    "## Запрос ресурсов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54305a8-eec3-43f1-ba53-a2df10badeee",
   "metadata": {},
   "source": [
    "Для проверки выделения ресурсов следующее приложение стартует с\n",
    "\n",
    "- одним контейнером для драйвера (Application Master),\n",
    "- тремя контейнерами для воркеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529370f2-2f78-4b7f-921b-d3e662a1d503",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"Yarn\")\n",
    "        .master(\"yarn\")\n",
    "        .config(\"spark.executor.instances\", 3)\n",
    "        .config(\"spark.yarn.am.memory\", \"512m\")\n",
    "        .config(\"spark.executor.memory\", \"1g\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a380ebe7-1a52-4fab-adc2-18e395501f9c",
   "metadata": {},
   "source": [
    "Следующая команда покажет запущенное Apache Spark приложение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0def2d47-2c25-498c-ad59-881bc34fa242",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "yarn application -list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5694c3df-4fae-4e48-be9f-8df93040b923",
   "metadata": {},
   "source": [
    "Проверим, что действительно запущено 4 контейнера:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6aa1c1-0278-4fd6-b940-7cbafc2d39e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "yarn container -list $( \\\n",
    "    yarn applicationattempt -list $( \\\n",
    "        yarn application -appTypes SPARK -appStates RUNNING -list | awk '/application_/{print $1}' \\\n",
    "    ) | awk '/appattempt_/{print $1}' \\\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e522bc-efb6-4460-8ed8-975b6d773f16",
   "metadata": {},
   "source": [
    "Можно ожидать, что всего будет выделено $ 1 \\space драйвер \\times 1G (слот \\space для \\space spark.yarn.am.memory) + 3 \\space воркера \\times 1G (spark.driver.memory) = 4G = 4096MB$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71920ad5-ce25-4465-898e-653071e3fe02",
   "metadata": {},
   "source": [
    "Текущий сетап кластера Hadoop состоит из одного узла, который одновременно играет все 4 роли:\n",
    "\n",
    "- NameNode,\n",
    "- DataNode,\n",
    "- ResourceManager,\n",
    "- NodeManager.\n",
    "\n",
    "Поэтому можно заключить, что ресурсы выделенные на NodeManager - это все ресурсы выделенные на приложение Apache Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ac3c95-4302-4d4e-80e7-4e91f6180513",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "yarn node -all -list -showDetails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a079b1-6c1e-42cf-b546-84f4739f4452",
   "metadata": {},
   "source": [
    "Команда выше показывает, что выделено всего `7168MB` (Allocated Resources), хотя ожидалось, что будет `4096MB`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4031efdb-a341-4f92-ad63-6a9ef31a6705",
   "metadata": {},
   "source": [
    "Откуда разница почти в $7168MB - 4096MB \\approx 3G$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d347bd-8f4d-49a2-ba8f-3167cea4c0d5",
   "metadata": {},
   "source": [
    "Можно предположить, что Hadoop занимает память какими-то своими служебными процессами. Но если остановить приложение Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9d825b-f786-4e2e-832f-2a00244a3a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2930ea0-9ea3-4a6c-832f-de6a7e727669",
   "metadata": {},
   "source": [
    "То объем выделенных ресурсов будет равен нулю:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8556352-ceeb-413b-8e5d-28f3fe6a158a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "yarn node -all -list -showDetails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7b6200-eb30-4ce2-aa7d-329d3c43f05b",
   "metadata": {},
   "source": [
    "Команда выше демонстрирует, что ни памяти, ни ядер процессора не выделено: `Allocated Resources : <memory:0, vCores:0>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a54e83-31b2-4127-bce7-24b013bf714e",
   "metadata": {},
   "source": [
    "В приложении с тремя воркерами разница в три гигабайта намекает на то, что каждый воркер забрал себе по одному дополнительному гигабайту."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b73a26a-9857-4baf-b56d-d5a18fbb0572",
   "metadata": {},
   "source": [
    "Для продолжения экспериментов запустим Spark приложение с предыдущей конфигурацией:\n",
    "\n",
    "- 1 драйвер,\n",
    "- 3 воркера,\n",
    "- 512MБ на драйвер,\n",
    "- 1ГБ на воркер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efc73df-46e4-4fa3-89a8-432e3426cdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"Yarn\")\n",
    "        .master(\"yarn\")\n",
    "        .config(\"spark.executor.instances\", 3)\n",
    "        .config(\"spark.yarn.am.memory\", \"512m\")\n",
    "        .config(\"spark.executor.memory\", \"1g\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a943642-db09-4bc4-a0b9-0899191c0d5b",
   "metadata": {},
   "source": [
    "Запущенное приложение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2f5881-46c7-49c6-8ac3-3d6233b427c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "yarn application -appTypes SPARK -appStates RUNNING -list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3fda8c-3d94-4062-a4d8-c96fc53edffe",
   "metadata": {},
   "source": [
    "Если посмотреть в логи, то можно увидеть какие ресурсы и в каком объеме запрашивал драйвер для воркеров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c3bb87-c25a-48ad-b446-4e2b08ebdcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "yarn logs -am -1 -log_files stderr -applicationId $( \\\n",
    "    yarn application -appTypes SPARK -appStates RUNNING -list | awk '/application_/{print $1}' \\\n",
    ") | grep YarnAllocator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c37cfab-ceee-4c4e-97a6-381b7b6ac544",
   "metadata": {},
   "source": [
    "В выводе выше видно, что драйвер запрашивает:\n",
    "\n",
    "- три контейнера: `Will request 3 executor container(s)`;\n",
    "- `1408MB` объем памяти для одного контейнера: `with custom resources: <memory:1408...`;\n",
    "- одно ядро для контейнера: `with custom resources: <..., vCores:1>`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2036156-1873-4a8a-a345-b8b4efb0f1de",
   "metadata": {},
   "source": [
    "Учитывая, что минимальный объем памяти в слоте равен `1024MB`, `Yarn` ничего не остается как выделить по два слота на контейнер, поэтому каждый воркер получает по `2` гигабайта памяти."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6a9989-0bc6-4788-b8a2-750a7320c477",
   "metadata": {},
   "source": [
    "Тогда всё сходится: $ 1024MB (слот \\space для \\space spark.yarn.am.memory) + 3 \\space (spark.executor.instances) \\times 1024 (минимальный \\space размер \\space слота) \\times 2 (слота) = 7168MB $\n",
    "\n",
    "**Внимание**: Помним, что хотя `spark.yarn.am.memory` равен `512MB`, но Yarn не может выделить меньше `1024MB` за раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad28a42e-3a9c-46f6-871d-0132fea70e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "yarn node -all -list -showDetails 2>/dev/null | grep 'Allocated Resources'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fbde5f-3928-49fd-af44-9eccd1900010",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3137a11d-77c6-4bc3-b55f-4c47e1a16f05",
   "metadata": {},
   "source": [
    "### Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7480db06-1953-445e-98b6-e9d986a063b5",
   "metadata": {},
   "source": [
    "1. Аналитически определить сколько памяти будет выделено на аналогичное приложение с двумя воркерами.\n",
    "2. Запустить приложение с двумя воркерами. Проверить, что теоретические и практические значения совпадают.\n",
    "\n",
    "<details>\n",
    "    <summary>Нужна помощь?</summary>\n",
    "\n",
    "    Ответы внизу страницы\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bec0965-1607-406b-9a12-85cf38ff1693",
   "metadata": {},
   "source": [
    "## Off-Heap память"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cde2065-ba82-4de7-a312-b8860aa6dd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d74434-dc19-419a-843e-a88ee8202577",
   "metadata": {},
   "source": [
    "Так откуда же берётся число `1408` при запросе контейнеров для воркеров?\n",
    "\n",
    "Помимо указания `spark.executor.memory` присутствует еще одна настройка `spark.executor.memoryOverhead`, которая указывает сколько памяти воркер будет использовать для Off-Heap памяти. Off-Heap память используется для хранния стек-трейсов потоков, прямых операциях с памятью, кешировании (при указании `StorageLevel.OFF_HEAP`) и других структур данных, которые воркер создает вне общей памяти. Off-Heap память управляется программистом напрямую и не участвует в сборке мусора."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94451a74-2e8c-422e-93eb-bac56e198b23",
   "metadata": {},
   "source": [
    "По умолчанию ее объем равен 10% от `spark.executor.memory`, но не меньше `384MB`. Так $ 1024MB (spark.memory.executor) + 384MB (spark.executor.memoryOverhead) = 1408MB $, ровно то самое число, которое Spark Application Master запрашивает у Yarn при создании воркеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20b181b-cf04-4ddd-ae91-d49bf4cb77bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"Yarn\")\n",
    "        .master(\"yarn\")\n",
    "        .config(\"spark.executor.instances\", 3)\n",
    "        .config(\"spark.yarn.am.memory\", \"512m\")\n",
    "        .config(\"spark.executor.memory\", \"1g\")\n",
    "        .config(\"spark.executor.memoryOverhead\", \"500m\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a48909-0106-42ec-bac6-9b23db2fe20d",
   "metadata": {},
   "source": [
    "Проверим какие ресурсы и в каких объемах Spark запрашивал при создании воркеров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3154d1-4711-44ef-a402-5c7b2befd079",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "yarn logs -am -1 -log_files stderr -applicationId $( \\\n",
    "    yarn application -appTypes SPARK -appStates RUNNING -list |& awk '/application_/{print $1}' \\\n",
    ") |& grep 'YarnAllocator: Will request'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cc57bf-edaa-4629-afb5-e28aca396233",
   "metadata": {},
   "source": [
    "В логах теперь значится ожидаемое значение `1524`: $ 1024MB (spark.executor.memory) + 500MB (spark.executor.memoryOverhead) = 1524MB $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46193daf-464f-4af7-8598-766b2a0dab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971570f9-beec-4195-a3c4-6305e65b3d16",
   "metadata": {},
   "source": [
    "### Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dab3d4-ca2d-4899-bbec-70394879f70e",
   "metadata": {},
   "source": [
    "1. Аналитически вычислить объем оперативной памяти для аналогичного приложения с двумя воркерами без Off-Heap памяти?\n",
    "2. Сравнить полученый ответ с реальными значениями.\n",
    "\n",
    "<details>\n",
    "    <summary>Нужна помощь?</summary>\n",
    "\n",
    "    Ответы внизу страницы\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e1c141-f0ec-4d6a-99b5-530a5dea94d1",
   "metadata": {},
   "source": [
    "### Off-Heap память для драйвера"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015373ee-d15d-4c19-b60f-52150f4c154b",
   "metadata": {},
   "source": [
    "Если воркеры могут иметь off-heap память, то логично предположить, что и драйвер имеет off-heap память тоже. Подобные рассуждения не далеки от истины, и действительно Off-Heap память для драйвера также можно сконфигурировать:\n",
    "\n",
    "- если Spark запущен в **_кластерном_** режиме, то необходимо установить значение настройки `spark.driver.memoryOverhead` (`384MB` по умолчанию);\n",
    "- если Spark запущен в **_клиентском_** режиме, то необходимо установить значение настройки `spark.yarn.am.memoryOverhead` (`384MB` по умолчанию).\n",
    "\n",
    "PySpark запускается в **_клиентском_** режиме, поэтому будет использоваться настройка `spark.yarn.am.memoryOverhead`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713ba5b5-081b-496b-a979-aec415240cca",
   "metadata": {},
   "source": [
    "Для эксперимента установим `600MB` в качестве объема Off-Heap памяти для драйвера:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2ddc2a-117a-48a8-9c62-817cd3e5b622",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"Yarn\")\n",
    "        .master(\"yarn\")\n",
    "        .config(\"spark.executor.instances\", 2)\n",
    "        .config(\"spark.yarn.am.memory\", \"512m\")\n",
    "        .config(\"spark.yarn.am.memoryOverhead\", \"600m\")\n",
    "        .config(\"spark.executor.memory\", \"1g\")\n",
    "        .config(\"spark.executor.memoryOverhead\", \"0\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8370e4a0-0d6c-4c3c-a470-d31210031f0e",
   "metadata": {},
   "source": [
    "Общий объем памяти драйвера будет равен: $ 512MB (spark.yarn.am.memory) + 600MB (spark.yarn.am.memoryOverhead) = 1112MB $, что превышает размер слота Yarn (`1024MB`), а следовательно Yarn будет вынужен выделить два слота под драйвер."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31eb40a-21d4-4d64-882b-8faf9e9bdb24",
   "metadata": {},
   "source": [
    "Тогда общий объем памяти выделенный приложению будет равен:\n",
    "\n",
    "Объем памяти драйвера: $ 512MB (spark.yarn.am.memory) + 600MB (spark.yarn.am.memoryOverhead) = 1112MB $\n",
    "\n",
    "Число слотов для драйвера: $ ceil(1112 / 1024) = 2 $\n",
    "\n",
    "Объем памяти воркеров: $ 1024MB (spark.executor.memory) + 0MB (spark.executor.memoryOverhead) = 1024MB $\n",
    "\n",
    "Число слотов для воркеров: $ 2 (spark.executor.instances) $\n",
    "\n",
    "Итого: $ (2 \\space слота \\space драйвера + 2 \\space слота \\space воркеров) \\times 1024 = 4096MB $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d4ed1e-472f-46c1-bb35-395dac695599",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "yarn node -all -list -showDetails 2>/dev/null | grep 'Allocated Resources'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eaf905-6523-4336-9209-4a2c6e0061e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a79d31-ae2d-4323-b31c-74ad8309adcb",
   "metadata": {},
   "source": [
    "Полученное значение совпадает с реальным значением."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da61aff-4f14-4cf2-9239-58b898d177ef",
   "metadata": {},
   "source": [
    "### Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9cee9a-d76c-429f-bc53-4dfe35e9a78d",
   "metadata": {},
   "source": [
    "1. Вычислить объем памяти для приложения с 3 воркерами.\n",
    "    - Убрать Off-Heap значение для драйвера,\n",
    "    - Установить 1GB в качестве Off-Heap значение для воркеров,\n",
    "    - Оставить остальные значения по умолчанию.\n",
    "1. Сравнить вычисленное значение с реальным значением.\n",
    "\n",
    "<details>\n",
    "    <summary>Нужна помощь?</summary>\n",
    "\n",
    "    Ответ на странице ниже.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831a992f-c0b3-49c5-9b7c-219ab40aea4c",
   "metadata": {},
   "source": [
    "## Изменить минимальный объем слота"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16f536c-1e40-4c42-a58e-c0db0c107cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b447fd-717b-4bbe-90eb-2daaf6f66d55",
   "metadata": {},
   "source": [
    "Создадим бэкап конфига:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae222c4-64ee-4666-ba71-3aef8b214311",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp -v $YARN_CONF_DIR/{,bkp_}yarn-site.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa7de78-633a-49a8-ba39-53416562b96d",
   "metadata": {},
   "source": [
    "Минимальный объем слота будет равняться `64MB`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15add820-1946-42b9-95ad-4fa2c595397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! sed -i '/yarn.scheduler.minimum-allocation-mb.value/s,1024,64,' $YARN_CONF_DIR/yarn-site.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce02bb85-2b5e-49d3-b750-9e81675361df",
   "metadata": {},
   "source": [
    "Необходимо перезапустить Hadoop для активации новой конфигурации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213bdcee-4242-46ea-904d-70fa5ee7c325",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose restart hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13644312-c2d7-4a46-932b-cc9112f95f28",
   "metadata": {},
   "source": [
    "Необходимо дождаться, когда Hadoop запустится: в колонке `STATUS` должно появиться значение `healthy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fc32dc-7cd5-4f5d-a16a-812c96a430be",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose ps hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2845919-6f67-42bb-a471-778d1d846a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"Yarn\")\n",
    "        .master(\"yarn\")\n",
    "        .config(\"spark.executor.instances\", 2)\n",
    "        .config(\"spark.yarn.am.memory\", \"512m\")\n",
    "        .config(\"spark.yarn.am.memoryOverhead\", \"448m\") # 512 - 64 = 448\n",
    "        .config(\"spark.executor.memory\", \"1g\")\n",
    "        .config(\"spark.executor.memoryOverhead\", \"512m\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f9a136-72f6-4c33-9a0e-881cde16d6a6",
   "metadata": {},
   "source": [
    "В запущенном приложении все числа подобраны таким образом, что они без остатка делятся на 64MB (минимальный размер слота после перезапуска). Следовательно, выделенная память будет суммой значений:\n",
    "\n",
    "$$\n",
    "    512MB (spark.yarn.am.memory) + 448 (spark.yarn.am.memoryOverhead) + 2 (spark.executor.instances) \\times (1024MB (spark.executor.memory) + 512MB (spark.executor.memoryOverhead)) = 4032MB\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72dbb20-ff0a-4602-9540-923352210cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "yarn node -all -list -showDetails 2>/dev/null | grep 'Allocated Resources'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539cb81b-1e8a-4dc6-badb-5ae82a5275ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432afca6-c119-4498-ab25-b7e76a67d940",
   "metadata": {},
   "source": [
    "Восстановление оригинальной конфигурации Yarn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ffd25b-ae7e-4edd-a721-0f32fbee8b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp -v $YARN_CONF_DIR/{bkp_,}yarn-site.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c59f64-3821-4095-bcc8-0816b3645d1f",
   "metadata": {},
   "source": [
    "Необходимо перезапустить Hadoop для активации настроек:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6023435e-bf09-415e-8618-a7a19e51f6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose restart hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56520242-ace9-4a91-b2d0-a5e086f56188",
   "metadata": {},
   "source": [
    "Необходимо дождаться, когда Hadoop запустится: в колонке `STATUS` должно появиться значение `healthy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375b70ec-fad3-4857-ba2e-4e0a013dd5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose ps hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc3214c-e4ee-47e9-8842-fb1bd4d9ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl -s http://${RESOURCEMANAGER_HOST}:8088/conf | grep 'yarn.scheduler.minimum-allocation-mb' | xmllint --format -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ac94bb-4518-4c0a-a850-bb88d1ca3760",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d991c7-2276-496d-9e60-26e1f3b37cab",
   "metadata": {},
   "source": [
    "## Выделение памяти больше допустимого"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ef53ce-5f15-4691-b9ea-23e9973403b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927bace9-be6f-4505-bb00-305b1389483d",
   "metadata": {},
   "source": [
    "Максимально можно выделить не больше 3GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6971cf-fa9d-4d74-9581-ed98b21da4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl -s http://${RESOURCEMANAGER_HOST}:8088/conf | grep 'yarn.scheduler.maximum-allocation-mb' | xmllint --format -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af45450-5a0f-468b-b515-08139b4c7a7a",
   "metadata": {},
   "source": [
    "Запустим приложение, в котором запрашиваемый размер памяти воркера 4GB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c51c740-3c6d-4ac0-80da-155fb3fa4364",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    spark = (\n",
    "        SparkSession\n",
    "            .builder\n",
    "            .appName(\"Yarn\")\n",
    "            .master(\"yarn\")\n",
    "            .config(\"spark.executor.instances\", 1)\n",
    "            .config(\"spark.executor.memory\", \"3g\")\n",
    "            .config(\"spark.executor.memoryOverhead\", \"512m\")\n",
    "            .getOrCreate()\n",
    "    )\n",
    "    sc = spark.sparkContext\n",
    "except Exception as e:\n",
    "    print(e, file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05fd0a9-4a2c-4b20-b820-b704e1ca9ed7",
   "metadata": {},
   "source": [
    "Ожидаемо, возникла ошибка, т.к. приложению необходимо было выделить 4ГБ на один воркер (почему 4ГБ?)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d0aa87-3220-4557-b703-3fab6c13aed2",
   "metadata": {},
   "source": [
    "Для решения этой проблемы необходимо увеличить значение `yarn.scheduler.maximum-allocation-mb`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c4953b-50d1-4b77-9625-f6d7ca41846a",
   "metadata": {},
   "source": [
    "Создадим бэкап конфигурации Yarn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33b0351-203d-44be-a4fa-87103ba754c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp -v $YARN_CONF_DIR/{,bkp_}yarn-site.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced20d7f-9469-4c9e-a4ca-ea31aa0d09b1",
   "metadata": {},
   "source": [
    "Установим максимальный объем памяти для разового выделения в `4096MB (4GB)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b08eb9-71c7-40ce-886c-6d989756ebc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! sed -i '/yarn.scheduler.maximum-allocation-mb.value/s,3072,4096,' $YARN_CONF_DIR/yarn-site.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3d0cff-e025-4d4c-8c22-83fe00371030",
   "metadata": {},
   "source": [
    "Перезапуск Hadoop для активации новой конфигурации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8619a6-bee9-4765-a0f0-cd76ca014ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose restart hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85921a00-97e2-4615-b635-e8b6b4ebdaf7",
   "metadata": {},
   "source": [
    "Необходимо дождаться, когда Hadoop запустится: в колонке `STATUS` должно появиться значение `healthy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20b2d40-9442-46ef-9ceb-7abf4139602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose ps hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25ff8a8-ce1b-4bf0-9b9c-abad73dc8076",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"Yarn\")\n",
    "        .master(\"yarn\")\n",
    "        .config(\"spark.executor.instances\", 1)\n",
    "        .config(\"spark.executor.memory\", \"3g\")\n",
    "        .config(\"spark.executor.memoryOverhead\", \"512m\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9fd38d-78f9-4765-ac0e-b47352db9372",
   "metadata": {},
   "source": [
    "Приложение запустилось. При этом несмотря на то, что максимально допустимый объем был установлен в значение `4096MB`, приложение получило `5120MB`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524b4e87-f74b-431b-93dc-c2582c41dc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "yarn node -all -list -showDetails 2>/dev/null | grep 'Allocated Resources'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f4d3bd-69e1-4d0b-9436-d7cba374024d",
   "metadata": {},
   "source": [
    "Связано это с тем, что ограчение устанавливается на единицу запроса, а всего приложение выполнило два запроса:\n",
    "\n",
    "1. Один запрос на выделение ресурсов драйверу,\n",
    "2. Один запрос на выделение ресурсов единственному воркеру (`spark.executor.instances`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea6b709-c73f-46dd-9541-3597235a0f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b831f55-b6a7-41fd-b3e1-2a82082e584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp -v $YARN_CONF_DIR/{bkp_,}yarn-site.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f4d776-c48e-468f-8991-52cb2e6d585e",
   "metadata": {},
   "source": [
    "Перезапуск Hadoop для активации новой конфигурации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f24b43-fcf9-48e6-aa05-fcaed727b5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose restart hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e87370-9912-4cbb-9361-653e7377c881",
   "metadata": {},
   "source": [
    "Необходимо дождаться, когда Hadoop запустится: в колонке `STATUS` должно появиться значение `healthy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9faf97-c25b-4e58-a8a1-12c8691c1149",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose ps hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00097965-cd5d-430c-b0b9-7caf9d4e1902",
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl -s http://${RESOURCEMANAGER_HOST}:8088/conf | grep 'yarn.scheduler.maximum-allocation-mb' | xmllint --format -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e1028d-0f43-4111-a181-b3547f6f4336",
   "metadata": {},
   "source": [
    "# Кластерный режим"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b4dd0a-7843-4105-8209-2da1c3ae25b6",
   "metadata": {},
   "source": [
    "При работе с Apache Spark через ноутбук автоматически выбирается **_клиентский режим_**: драйвер находится на локальном компьютере, а в облаке находится Application Master, необходимый для управления контейнерами Yarn для воркеров.\n",
    "\n",
    "Для запуска приложения Spark в **_кластерном режиме_** необходимо использовать `spark-submit`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb71f89-edc0-4bc0-b0b5-8a9ffde3cc25",
   "metadata": {},
   "source": [
    "Команда `spark-sumbit` запускает приложение в кластерном режиме, а значит будет использовать `spark.driver.memory` и `spark.driver.memoryOverhead` для запроса ресурсов.\n",
    "\n",
    "Для примера запустим приложение, указав сразу два набора параметров:\n",
    "\n",
    "- клиентский режим:\n",
    "    - `spark.yarn.am.memory=2g`,\n",
    "    - `spark.yarn.am.memoryOverhead=600m`.\n",
    "- кластерный режим:\n",
    "    - `--driver-memory 1g` (эта настройка аналогична `spark.driver.memory`),\n",
    "    - `spark.driver.memoryOverhead=500m`.\n",
    "\n",
    "В итоге должны примениться параметры кластерного режима:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0749e53f-48f8-4743-be06-570423901c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! /usr/local/spark/bin/spark-submit --class org.apache.spark.examples.SparkPi \\\n",
    "    --master yarn \\\n",
    "    --deploy-mode cluster \\\n",
    "    --driver-memory 1g \\\n",
    "    --conf spark.driver.memoryOverhead=500m \\\n",
    "    --conf spark.yarn.am.memory=2g \\\n",
    "    --conf spark.yarn.am.memoryOverhead=600m \\\n",
    "    --executor-memory 1g \\\n",
    "    --conf spark.executor.memoryOverhead=700m \\\n",
    "    --num-executors 2 \\\n",
    "    /usr/local/spark/examples/jars/spark-examples*.jar \\\n",
    "    10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7e3b88-1a5a-461a-852f-df5d708346b8",
   "metadata": {},
   "source": [
    "Результат вычисления печается в стандартный поток вывода:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1dcd42-cf14-4ebc-bf1b-d04b87a8b619",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && HOST=hadoop \\\n",
    "execute cat /opt/hadoop/logs/userlogs/$( \\\n",
    "    yarn app -list -appStates ALL |& awk '/org.apache.spark.examples.SparkPi/{print $1}' | sort -r | head -n 1 \\\n",
    ")/$( \\\n",
    "    yarn applicationattempt -list $( \\\n",
    "        yarn app -list -appStates ALL |& awk '/org.apache.spark.examples.SparkPi/{print $1}' | sort -r | head -n 1 \\\n",
    "    ) |& awk '/container_/{print $3}' \\\n",
    ")/stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89c8719-c350-46b2-b940-2b9c9b9feab9",
   "metadata": {},
   "source": [
    "В выводе команды выше можно увидеть, что приложение запросило `1524MB` для драйвера (Application Master): `Will allocate AM container, with 1524 MB memory including 500 MB overhead`, что соответствует теоретическим числам:\n",
    "\n",
    "$$\n",
    "1024MB (spark.driver.memory) + 500MB (spark.driver.memoryOverhead) = 1524MB\n",
    "$$\n",
    "\n",
    "Если бы приложение было запущено в клиентском режиме, то для Application Master контейнера было бы запрошено `2648MB`:\n",
    "\n",
    "$$\n",
    "2048MB (spark.yarn.am.memory) + 600MB (spark.yarn.am.memoryOverhead) = 2648MB\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fae0e4b-38df-4874-b092-94c07fef85dd",
   "metadata": {},
   "source": [
    "Для воркеров было запрошено 2 контейнера (`--num-executors`) по `1724MB`:\n",
    "\n",
    "$$\n",
    "1024MB (--executor-memory) + 700MB (spark.executor.memoryOverhead) = 1724MB\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316f42eb-13f1-4859-92eb-6bf3150baeba",
   "metadata": {},
   "source": [
    "Команда ниже показывает, что ожидаемое значение соответствует реальному:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab720a6-f606-4335-a74a-3b0309eeb1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && HOST=hadoop \\\n",
    "execute cat /opt/hadoop/logs/userlogs/$( \\\n",
    "    yarn app -list -appStates ALL |& awk '/org.apache.spark.examples.SparkPi/{print $1}' | sort -r | head -n 1 \\\n",
    ")/$( \\\n",
    "    yarn applicationattempt -list $( \\\n",
    "        yarn app -list -appStates ALL |& awk '/org.apache.spark.examples.SparkPi/{print $1}' | sort -r | head -n 1 \\\n",
    "    ) |& awk '/container_/{print $3}' \\\n",
    ")/stderr |& grep 'YarnAllocator: Will request'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ad41fa-e627-4849-b00a-79ac481c641f",
   "metadata": {},
   "source": [
    "В выводе можно увидеть:\n",
    "\n",
    "- запрошено 2 контейнера: `Will request 2 executor container(s) ...`,\n",
    "- на один контейнер `1724MB`: `Will request 2 executor container(s) ... each with 1 core(s) and 1724 MB memory`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456456ee-400d-4070-985a-19acd6f8f509",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a9581a-f396-4d13-acd0-b4bafc28f6f3",
   "metadata": {},
   "source": [
    "Очень важно понимать как режимы запуска приложения отличаются друг от друга и при каком режиме какие настройки используются. Разница в настройках заключатся только в том, какие настройки используются для запуска контейнера Application Master в кластере. В клиентском режиме драйвер находится на локальной машине программиста, а поэтому большой Application Master контейнер не нужен: его задача только следить за контейнерами воркеров и перезапускать их при необходимости. В кластерном режиме Application Master контейнер используется как для перезапуска контейнеров воркеров, так и для формирования планов запросов, а поэтому нужно больше ресурсов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8194a337-5f53-493d-bfc2-aa2ddb1b8a76",
   "metadata": {},
   "source": [
    "## Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a65e7b-c01b-4445-9ff8-9acfc9462ea9",
   "metadata": {},
   "source": [
    "1. Запустить приложение в кластерном режиме:\n",
    "    - Память для драйвера: 768MB,\n",
    "    - Off-Heap память для драйвера отсутствует,\n",
    "    - Память для воркеров: 512MB,\n",
    "    - Off-Heap память для воркеров: 200MB,\n",
    "    - Число воркеров: 2.\n",
    "1. Вычислить сколько памяти займет приложение с указанной конфигурацией;\n",
    "1. Убедиться, что реальное значение памяти совпдает с ожидаемым значением;\n",
    "\n",
    "<details>\n",
    "    <summary>Нужна помощь?</summary>\n",
    "\n",
    "    Ответы внизу страницы\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788d150f-c2f5-47d5-892a-15945e86f275",
   "metadata": {},
   "source": [
    "# Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3007a5-547b-428d-a506-e6f97b8eb9e6",
   "metadata": {},
   "source": [
    "Apache Spark стремится выполнять бОльшую часть работы в памяти, поэтому очень важно понимать, как управлять доступной памятью. Yarn предлагает простой подход к управлению ресурсами через слоты, но в свою очередь Spark может удивить неподготовленного программиста при выделении памяти сверх установленных значений, например, из-за настроек Off-Heap или разных режимов работы (client, cluster). К вопросу настройки памяти в каждом приложении стоит подходить индивидуально, следить за расходом памяти в реальной эксплуатации и подстраивать значения приложения в соответствии с полученными из реальной эксплуатации цифрами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3be919-69db-4a16-ad6f-dc0b6384176b",
   "metadata": {},
   "source": [
    "# Ответы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8aa7d3-37b6-4129-9024-0b56f7188c27",
   "metadata": {},
   "source": [
    "## Ответы на задания по созданию воркеров"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806d432f-8ecb-49df-95bb-6c9a9bd93425",
   "metadata": {},
   "source": [
    "1. Запустить Apache Spark приложение с настройками по умолчанию. Сколько контейнеров Yarn выделяет такому приложению?\n",
    "\n",
    "<details>\n",
    "    <summary>Ответ</summary>\n",
    "\n",
    "    Три контейнера: 1 для драйвера и 2 (почему?) для воркеров\n",
    "\n",
    "    Запустить приложение:\n",
    "```python\n",
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"Yarn Default\")\n",
    "        .master(\"yarn\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "```\n",
    "\n",
    "    Проверить контейнеры:\n",
    "```bash\n",
    "! source ~/.bash_aliases && \\\n",
    "yarn container -list $( \\\n",
    "    yarn applicationattempt -list $( \\\n",
    "        yarn application -appTypes SPARK -appStates RUNNING -list | awk '/application_/{print $1}' \\\n",
    "    ) | awk '/appattempt_/{print $1}' \\\n",
    ")\n",
    "```\n",
    "\n",
    "    Остановить приложение:\n",
    "```python\n",
    "spark.stop()\n",
    "```\n",
    "</details>\n",
    "\n",
    "2. Запустить Apache Spark приложение с динамическим выделением ресурсов в соответствии со следующими требованиями:\n",
    "    - в ждушем режиме не должно быть ниодного контейнера для воркеров,\n",
    "    - максимальное число контейнеров 3,\n",
    "    - время работы контейнера в ждущем режиме две минуты.\n",
    "\n",
    "<details>\n",
    "    <summary>Ответ</summary>\n",
    "\n",
    "    Запустить приложение:\n",
    "```python\n",
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"Yarn Dymanic Workers\")\n",
    "        .master(\"yarn\")\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\n",
    "        .config(\"spark.dynamicAllocation.minExecutors\", 0)\n",
    "        .config(\"spark.dynamicAllocation.maxExecutors\", 3)\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\", 120)\n",
    "        .getOrCreate()\n",
    ")\n",
    "```\n",
    "\n",
    "    Проверить контейнеры:\n",
    "\n",
    "```bash\n",
    "! source ~/.bash_aliases && \\\n",
    "yarn container -list $( \\\n",
    "    yarn applicationattempt -list $( \\\n",
    "        yarn application -appTypes SPARK -appStates RUNNING -list | awk '/application_/{print $1}' \\\n",
    "    ) | awk '/appattempt_/{print $1}' \\\n",
    ")\n",
    "```\n",
    "\n",
    "    Подождать 2 минуты и проверить контейнеры снова:\n",
    "\n",
    "```bash\n",
    "! source ~/.bash_aliases && sleep 120 && \\\n",
    "yarn container -list $( \\\n",
    "    yarn applicationattempt -list $( \\\n",
    "        yarn application -appTypes SPARK -appStates RUNNING -list | awk '/application_/{print $1}' \\\n",
    "    ) | awk '/appattempt_/{print $1}' \\\n",
    ")\n",
    "```\n",
    "\n",
    "    Остановить приложение\n",
    " \n",
    "```python\n",
    "spark.stop()\n",
    "```\n",
    "</details>\n",
    "\n",
    "3. Запустить приложение с динамическим выделением ресурсов из предыдущего шага. При этом время жизни воркеров в ждущем режиме с закешированными данными должно не превышать 2 минуты 30 секунд.\n",
    "\n",
    "<details>\n",
    "    <summary>Ответ</summary>\n",
    "\n",
    "    Запустить приложение:\n",
    "```python\n",
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"Yarn Dymanic Workers\")\n",
    "        .master(\"yarn\")\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\n",
    "        .config(\"spark.dynamicAllocation.minExecutors\", 0)\n",
    "        .config(\"spark.dynamicAllocation.maxExecutors\", 3)\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\", 120)\n",
    "        .config(\"spark.dynamicAllocation.cachedExecutorIdleTimeout\", 150)\n",
    "        .getOrCreate()\n",
    ")\n",
    "```\n",
    "\n",
    "    Проверить контейнеры:\n",
    "\n",
    "```bash\n",
    "! source ~/.bash_aliases && \\\n",
    "yarn container -list $( \\\n",
    "    yarn applicationattempt -list $( \\\n",
    "        yarn application -appTypes SPARK -appStates RUNNING -list | awk '/application_/{print $1}' \\\n",
    "    ) | awk '/appattempt_/{print $1}' \\\n",
    ")\n",
    "```\n",
    "\n",
    "    Закешировать данные:\n",
    "```python\n",
    "from pyspark import StorageLevel\n",
    "\n",
    "spark.range(1, 10000, 1, 1).toDF(\"id\").persist(StorageLevel.MEMORY_ONLY)\n",
    "```\n",
    "\n",
    "    Подождать 2 минуты и проверить контейнеры снова:\n",
    "\n",
    "```bash\n",
    "! source ~/.bash_aliases && sleep 120 && \\\n",
    "yarn container -list $( \\\n",
    "    yarn applicationattempt -list $( \\\n",
    "        yarn application -appTypes SPARK -appStates RUNNING -list | awk '/application_/{print $1}' \\\n",
    "    ) | awk '/appattempt_/{print $1}' \\\n",
    ")\n",
    "```\n",
    "    Подождать 30 секунд и проверить контейнеры снова (должно остаться два контейнера: воркер с кешем и драйвер):\n",
    "\n",
    "```bash\n",
    "! source ~/.bash_aliases && sleep 30 && \\\n",
    "yarn container -list $( \\\n",
    "    yarn applicationattempt -list $( \\\n",
    "        yarn application -appTypes SPARK -appStates RUNNING -list | awk '/application_/{print $1}' \\\n",
    "    ) | awk '/appattempt_/{print $1}' \\\n",
    ")\n",
    "```\n",
    "\n",
    "    Остановить приложение:\n",
    " \n",
    "```python\n",
    "spark.stop()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00901452-3bc6-4425-9e03-ae3bf2ad8562",
   "metadata": {},
   "source": [
    "## Ответы на задания по определению объема выделенной памяти"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b86bf7f-1e47-46cf-ba37-6758f1d057ff",
   "metadata": {},
   "source": [
    "1. Аналитически определить сколько памяти будет выделено на приложение с двумя воркерами.\n",
    "\n",
    "<details>\n",
    "    <summary>Ответ</summary>\n",
    "\n",
    "$ 1024MB (spark.driver.memory) + 2 \\space (spark.executor.instances) \\times 1024 (минимальный \\space размер \\space слота) \\times 2 (слота) = 5120MB $\n",
    "\n",
    "</details>\n",
    "\n",
    "2. Запустить приложение с двумя воркерами. Проверить, что теоретические и практические значения совпадают.\n",
    "\n",
    "<details>\n",
    "    <summary>Ответ</summary>\n",
    "\n",
    "    Запустить приложение:\n",
    "\n",
    "```python\n",
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"Yarn\")\n",
    "        .master(\"yarn\")\n",
    "        .config(\"spark.executor.instances\", 2)\n",
    "        .config(\"spark.yarn.am.memory\", \"512m\")\n",
    "        .config(\"spark.executor.memory\", \"1g\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext\n",
    "```\n",
    "\n",
    "    Проверить объем занимаемых ресуров:\n",
    "```bash\n",
    "! source ~/.bash_aliases && \\\n",
    "yarn node -all -list -showDetails 2>/dev/null | grep 'Allocated Resources'\n",
    "```\n",
    "    Остановить приложение:\n",
    "```python\n",
    "spark.stop()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28309b73-c6ad-4b6f-aadc-023ff3248f86",
   "metadata": {},
   "source": [
    "### Ответы на задание по определению объема памяти для приложения без Off-Heap памяти"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b0d721-83e8-490c-b175-6ead58f2217a",
   "metadata": {},
   "source": [
    "1. Аналитически вычислить объем оперативной памяти для приложения с двумя воркерами без Off-Heap памяти?\n",
    "2. Сравнить полученый ответ с реальными значениями.\n",
    "\n",
    "<details>\n",
    "    <summary>Ответ</summary>\n",
    "\n",
    "Минимальный размер слота: `1024MB`\n",
    "\n",
    "Для одного воркера будет выделен один слот, т.к. $1024MB (spark.executor.memory) + 0MB (spark.executor.memoryOverhead) = 1024MB == минимальный \\space размер \\space слота$\n",
    "\n",
    "Всего выделится 3 слота: один на драйвер, два на воркеры\n",
    "\n",
    "В итоге будет выделено: $ 3 \\space слота \\times 1024MB = 3072MB $\n",
    "\n",
    "    Запустить приложение без Off-Heap памяти:\n",
    "```python\n",
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"Yarn\")\n",
    "        .master(\"yarn\")\n",
    "        .config(\"spark.executor.instances\", 3)\n",
    "        .config(\"spark.yarn.am.memory\", \"512m\")\n",
    "        .config(\"spark.executor.memory\", \"1g\")\n",
    "        .config(\"spark.executor.memoryOverhead\", \"0\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "```\n",
    "    Проверить объем выделенной памяти\n",
    "```bash\n",
    "! source ~/.bash_aliases && \\\n",
    "yarn logs -am -1 -log_files stderr -applicationId $( \\\n",
    "    yarn application -appTypes SPARK -appStates RUNNING -list |& awk '/application_/{print $1}' \\\n",
    ") |& grep 'YarnAllocator: Will request'\n",
    "```\n",
    "\n",
    "```python\n",
    "spark.stop()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c77e9ed-349e-40a8-b826-c8f8d361c238",
   "metadata": {},
   "source": [
    "## Ответ на задание для определения памяти для драйвера без Off-Heap памяти"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2ebbf4-bfb8-4d79-926a-b3316e0eb536",
   "metadata": {},
   "source": [
    "1. Вычислить объем памяти для приложения с 3 воркерами.\n",
    "    - Убрать Off-Heap значение для драйвера,\n",
    "    - Установить 1GB в качестве Off-Heap значение для воркеров,\n",
    "    - Оставить остальные значения по умолчанию.\n",
    "1. Сравнить вычисленное значение с реальным значением.\n",
    "\n",
    "<details>\n",
    "    <summary>Ответ</summary>\n",
    "\n",
    "Минимальный размер слота: `1024MB`\n",
    "\n",
    "Для одного воркера будет выделено два слота, т.к. $1024MB (spark.executor.memory) + 1024MB (spark.executor.memoryOverhead) = 2048MB == 2 \\times минимальный \\space размер \\space слота$\n",
    "\n",
    "Для драйвера будет выделен один слот, т.к. $512MB (spark.yarn.am.memory) + 0MB (spark.yarn.am.memoryOverhead) = 512MB $, а Yarn может выделить за раз слот не меньше `1024MB`\n",
    "\n",
    "Всего выделится 7 слотов: один на драйвер, шесть на воркеры\n",
    "\n",
    "В итоге будет выделено: $ 7 \\space слотов \\times 1024MB = 7168MB $\n",
    "\n",
    "    Запустить приложение без Off-Heap памяти:\n",
    "```python\n",
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"Yarn\")\n",
    "        .master(\"yarn\")\n",
    "        .config(\"spark.executor.instances\", 3)\n",
    "        .config(\"spark.yarn.am.memoryOverhead\", \"0\")\n",
    "        .config(\"spark.executor.memoryOverhead\", \"1g\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "```\n",
    "    Проверить объем выделенной памяти\n",
    "```bash\n",
    "! source ~/.bash_aliases && \\\n",
    "yarn logs -am -1 -log_files stderr -applicationId $( \\\n",
    "    yarn application -appTypes SPARK -appStates RUNNING -list |& awk '/application_/{print $1}' \\\n",
    ") |& grep 'YarnAllocator: Will request'\n",
    "```\n",
    "\n",
    "```python\n",
    "spark.stop()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4ecd59-07ec-43c1-a58d-759fd9e9ca5c",
   "metadata": {},
   "source": [
    "## Ответ на задания по запуску приложения в кластерном режиме"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cdb990-de7f-40b1-8189-1995851ae577",
   "metadata": {},
   "source": [
    "1. Запустить приложение в кластерном режиме:\n",
    "    - Память для драйвера: 768MB,\n",
    "    - Off-Heap память для драйвера отсутствует,\n",
    "    - Память для воркеров: 512MB,\n",
    "    - Off-Heap память для воркеров: 200MB,\n",
    "    - Число воркеров: 2.\n",
    "1. Вычислить сколько памяти займет приложение с указанной конфигурацией;\n",
    "1. Убедиться, что реальное значение памяти совпдает с ожидаемым значением;\n",
    "\n",
    "<details>\n",
    "    <summary>Ответ</summary>\n",
    "\n",
    "Всего приложение займет 3 слота: один слот на драйвер и два слота на воркеры (почему?). Тогда всего будет выделено памяти: $ 3 * 1024MB (минимальный \\space размер \\space слота) = 3072MB $\n",
    "\n",
    "    Запуск приложения\n",
    "```bash\n",
    "! /usr/local/spark/bin/spark-submit --class org.apache.spark.examples.SparkPi \\\n",
    "    --master yarn \\\n",
    "    --deploy-mode cluster \\\n",
    "    --driver-memory 768m \\\n",
    "    --conf spark.driver.memoryOverhead=0 \\\n",
    "    --executor-memory 512m \\\n",
    "    --conf spark.executor.memoryOverhead=200m \\\n",
    "    --num-executors 2 \\\n",
    "    /usr/local/spark/examples/jars/spark-examples*.jar \\\n",
    "    10\n",
    "```\n",
    "\n",
    "В выводе можно обнаружить строку `Will allocate AM container, with 768 MB memory including 0 MB overhead`, т.е. на драйвер будет выделено `768MB`, что полностью умещается в один слот (`1024MB`)\n",
    "\n",
    "В логах приложения можно найти найти сколько контейнеров запрашивало приложение:\n",
    "\n",
    "```bash\n",
    "! source ~/.bash_aliases && HOST=hadoop \\\n",
    "execute cat /opt/hadoop/logs/userlogs/$( \\\n",
    "    yarn app -list -appStates ALL |& awk '/org.apache.spark.examples.SparkPi/{print $1}' | sort -r | head -n 1 \\\n",
    ")/$( \\\n",
    "    yarn applicationattempt -list $( \\\n",
    "        yarn app -list -appStates ALL |& awk '/org.apache.spark.examples.SparkPi/{print $1}' | sort -r | head -n 1 \\\n",
    "    ) |& awk '/container_/{print $3}' \\\n",
    ")/stderr |& grep 'YarnAllocator: Will request'\n",
    "```\n",
    "\n",
    "Контейнер Application Master запросил 2 контейнера по `712MB`: `Will request 2 executor container(s) for  ResourceProfile Id: 0, each with 1 core(s) and 712 MB memory`. Можно заключить:\n",
    "\n",
    "- приложение запросило на один контейнер значение `712MB`, которое состоит из:\n",
    "    - `--executor-memory 512m`\n",
    "    - `spark.executor.memoryOverhead=200m`\n",
    "- один контейнер полностью умещается в один слот (`1024MB`)\n",
    "- всего приложение (драйвер и 2 воркера) займет `3072MB`\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
