{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70023ab8-acb1-4cfa-b26c-f32086af657d",
   "metadata": {},
   "source": [
    "# Spark Advanced - Spills"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9a1a84-9fd1-4728-9cc0-d0141e65eacc",
   "metadata": {},
   "source": [
    "## Мотивация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0307db35-ff67-44d6-a50d-2304a6ee12f5",
   "metadata": {},
   "source": [
    "Apache Spark стремится выполнять всю работу в оперативной памяти, но её ресурс ограничен. Если Apache Spark пытается выделить участок памяти, а память уже заполнена, то у Apache Spark есть две стратегии:\n",
    "\n",
    "- выгрузить часть данных из памяти на диск,\n",
    "- упасть с `OutOfMemoryError`.\n",
    "\n",
    "Выгрузить на диск можно лишь закешированные партиции RDD. Дополнительные объекты, которые создаются во время выполнения сортировки, агрегации, перемешивания и т.д. не могут быть выгружены на диск.\n",
    "\n",
    "Выгрузка RDD на диск называется `spill`. В общении с колегами используют англицизмы: \"спил\", \"спилы\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9f710e-4caa-4572-8eef-15c2848b0369",
   "metadata": {},
   "source": [
    "## Устройство памяти воркера"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1d8a22-6a77-4e8e-b560-eec1451d8294",
   "metadata": {},
   "source": [
    "Вся доступная память разбивается на 4 раздела:\n",
    "\n",
    "- **зарезервировано**: область памяти, которая используется для внутренних нужд процессов воркера. Всегда равно 300 МБ, не может быть меньше или больше;\n",
    "- **исполнение (execution)**: область памяти для выполнения логики запросов - сортировка, агрегация, перемешивание и пр.;\n",
    "- **кеш (storage)**: область памяти доступная для хранения пользовательских объектов в кеше;\n",
    "- **пользовательские объекты**: область памяти для создания пользовательских объектов (`HashMap`, объекты в `UDF` и т.д).\n",
    "\n",
    "По умолчанию storage и execution делят пополам оставшуюся память после вычета 300 МБ из всего доступного объема.\n",
    "\n",
    "\n",
    "![](../imgs/spark-memory-layout.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27413d43-9c6f-4757-bbf3-ba648f08a15c",
   "metadata": {},
   "source": [
    "### Настройка памяти"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed68377-7f7e-4631-969d-f39360c31cf1",
   "metadata": {},
   "source": [
    "При настройке памяти обычно используют два параметра:\n",
    "\n",
    "- `spark.memory.fraction` указывает размер региона `M` (сумма регионов \"исполнение\" и \"кеш\") как процент от значения \"Вся_доступная_память - 300M\"\n",
    "  . Значение по умолчанию равно 0.6;\n",
    "- `spark.memory.storageFraction` указывает размер региона `R` - размер региона в процентах для кеша внутри региона `M`. Значение по умолчанию равно 0.5.\n",
    "\n",
    "Оставшаяся часть памяти используется:\n",
    "\n",
    "- для пользовательских объектов (например, переменных в UDF),\n",
    "- для метаданных Spark,\n",
    "- как защитный механизм против возникновения `OutOfMemoryError` при редких всплесках нагрузки.\n",
    "\n",
    "![](../imgs/spark-memory-configs.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7101fb6-c379-4d4c-aeb6-b452b512cd86",
   "metadata": {},
   "source": [
    "**Внимание**: указанные значения параметров по умолчанию гарантируют приемлимую производительность для большого числа приложений, но глубокий уровень понимания механики управления памятью позволяем получить больший контроль над процессом"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b9a143-0631-4d53-918a-302ada867d63",
   "metadata": {},
   "source": [
    "### Механизм использования памяти"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb25b0c4-410b-4bf3-a514-2c6e62b563b6",
   "metadata": {},
   "source": [
    "Границы регионов не являются строгими, Apache Spark может двигать их:\n",
    "\n",
    "- если приложение не использует кеш, то регион \"исполнение\" (execution) занимает весь регион `M` (исполнение + кеш);\n",
    "\n",
    "![](../imgs/spark-memory-no-cache.drawio.svg)\n",
    "- \"кеш\" (storage) регион может занять место в регионе \"исполнение\" (execution), но, если воркеру потребуется память для исполнения, то он начнёт выбрасывать данные из кеша:\n",
    "\n",
    "![](../imgs/spark-memory-large-cache.drawio.svg)\n",
    "\n",
    "Выброшенные данные из кеша сохранятся на диске. Этот процесс называется `spill` или спилом. Выгруженные на диск партиции так же иногда называют спилами (spills). Данные, которые хранятся внутри региона `R`, не могут быть выброшены.\n",
    "\n",
    "> Партиции внутри региона `R` защищены от спилов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad166544-5dcb-4cdb-9444-afd2f10d2667",
   "metadata": {},
   "source": [
    "#### Регион с пользовательскими объектами"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68869f74-eac7-449f-b561-d868e91fe3fb",
   "metadata": {},
   "source": [
    "Границы региона с пользовательскими объектами так же могут быть подвинуты исполнением. Это позволяет избежать `OutOfMemoryError`:\n",
    "\n",
    "![](../imgs/spark-memory-user-objects.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7af5031-74e3-4b41-8a7c-ab987debf747",
   "metadata": {},
   "source": [
    "Но, если необходимо создать пользовательские объекты, то Apache Spark запустит Garbage Collector, чтобы подвинуть границу региона исполнения обратно. Если освободить память будет невозможно, то произойдет `OutOfMemoryError`:\n",
    "\n",
    "![](../imgs/spark-memory-user-objects-oom.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f069df97-ef1b-4bea-a863-d8e5a8adc15c",
   "metadata": {},
   "source": [
    "## Запуск приложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad78f7c-69a4-44dd-a9df-0a127c8ce423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark import StorageLevel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4ac936-4498-41a3-b7ef-07283b6cd1e4",
   "metadata": {},
   "source": [
    "### Создание сессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad143f9f-f53e-4010-926a-21ef7e7ebfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"Spills\")\n",
    "        .master(\"local[4]\")\n",
    "        .config(\"spark.memory.fraction\", 0.6)\n",
    "        .config(\"spark.memory.storageFraction\", 0.5)\n",
    "        .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2c143f-a46d-4fb1-beae-3df5cbe8aeea",
   "metadata": {},
   "source": [
    "Spark UI доступен на порту [4040](http://localhost:4040)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742667e7-b3fe-438e-9ee8-9d0990f1b063",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a63198-3574-4503-a228-4a998bd93f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /tmp/taxi\n",
    "!unzip -o -d /tmp/taxi ./data/taxi.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8efb77-a358-4ecf-bde8-487775ac97d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setJobDescription(\"Разбить датафрейм на 4 партиции\")\n",
    "spark.read.parquet(\"/tmp/taxi\") \\\n",
    "    .repartition(4) \\\n",
    "    .write.mode(\"overwrite\").save(\"/tmp/taxi_many\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7c3725-7eeb-4769-90b4-4fdffe45ff9b",
   "metadata": {},
   "source": [
    "### Загрузка основного датафрейма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ebd7c3-3349-4a02-bafd-69af7994901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_taxi_df(sparkContext):\n",
    "    sparkContext.setJobDescription(\"Загрузить датафрейм с 4 партициями\")\n",
    "    return spark.read.parquet(\"/tmp/taxi_many\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0084b1-3f88-41d7-a8cf-cf38703bd639",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df = load_taxi_df(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d29b289-6b93-4671-bdf2-c5a7df91a6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317cdb5c-ccee-4a1a-81a0-30b0c8ac74f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3351b7-a8cc-4453-bad3-1202471088c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setJobDescription(\"Распределение данных по партициям\")\n",
    "taxi_df.groupby(F.spark_partition_id()).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8313d2c3-66df-4f88-b37f-4ebe5fd12766",
   "metadata": {},
   "source": [
    "### Доступные ресурсы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19593ef8-32e3-4abc-a0b8-ad74a2945453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "class MemoryDescription(NamedTuple):\n",
    "    total_memory: float = spark._jvm.java.lang.Runtime.getRuntime().maxMemory() / 1024 / 1024\n",
    "    reserved_memory: int = 300\n",
    "    available_memory: float = total_memory - reserved_memory\n",
    "\n",
    "    memoryFraction: float = float(spark.conf.get(\"spark.memory.fraction\"))\n",
    "    storageFraction: float = float(spark.conf.get(\"spark.memory.storageFraction\"))\n",
    "\n",
    "    user_objects: float = available_memory * (1 - memoryFraction)\n",
    "    \n",
    "    m_region: float = available_memory * memoryFraction\n",
    "    execution: float = m_region * (1 - storageFraction)\n",
    "    storage: float = m_region * storageFraction\n",
    "\n",
    "description = MemoryDescription()\n",
    "\n",
    "print(f\"Объем памяти воркера: {description.total_memory} MB\")\n",
    "print(f\"Объем зарезервированной памяти: 300 MB\")\n",
    "print(f\"Объем доступной памяти: {description.available_memory} MB\")\n",
    "print(f\"Объем пользовательских данных: {description.user_objects} MB\")\n",
    "print(f\"Объем региона M: {description.m_region} MB\")\n",
    "print(f\"Объем региона исполнения: {description.execution} MB\")\n",
    "print(f\"Объем региона кеширования `R`: {description.storage} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272f099e-6797-44c7-95b6-cffceb99397e",
   "metadata": {},
   "source": [
    "Объем доступной памяти можно посмотреть на Spark UI на вкладке [Executors](http://localhost:4040/executors/)\n",
    "\n",
    "![](../imgs/spark-available-memory.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0acbd4b-9177-4aa5-9599-69f712c564cb",
   "metadata": {},
   "source": [
    "## Исполнение вытесняет кеш"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9b8514-0f41-4191-83d9-583eac1a8c90",
   "metadata": {},
   "source": [
    "### Занять кеш"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b5dc24-5462-4dd2-843c-a94e036cbdf4",
   "metadata": {},
   "source": [
    "Регион `R`, в границах которого закешированные партиции невозможно вытеснить, имеет размер:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0af99c-d28a-406a-9958-02e3f154b183",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{MemoryDescription().storage}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cc7fed-2530-45a7-bdd5-5b592a49ab78",
   "metadata": {},
   "source": [
    "Но кеш в Apache Spark может занимать весь регион M, размер которого:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed1b8a9-3eab-4a9f-a50c-53bbfd699e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{MemoryDescription().m_region}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7a45e1-2303-461c-b5ef-35d69e5660b2",
   "metadata": {},
   "source": [
    "Следущий код демонстрирует факт, что объем закешированных данных может превышать границы региона `R`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56591943-9636-49ef-8850-49c6ee0dbb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_cache(taxi_df):\n",
    "    sc.setJobDescription(\"Занять кеш `0 == 0`\")\n",
    "\n",
    "    cached_taxi_df = taxi_df.where(\"0 == 0\").persist(StorageLevel.MEMORY_ONLY)\n",
    "    cached_taxi_df.count()\n",
    "\n",
    "    sc.setJobDescription(\"Занять кеш `1 == 1`\")\n",
    "    cached_taxi_11_df = taxi_df.where(\"1 == 1\").persist(StorageLevel.MEMORY_ONLY)\n",
    "    cached_taxi_11_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09c2288-6837-48be-819d-9bf3e048dd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_cache(taxi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f3bcc5-b429-47b6-9e7b-b24e4c362217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cache_size(spark_context):\n",
    "    return sum([x.memSize() for x in spark_context._jsc.sc().getRDDStorageInfo()]) / 1024 / 1024    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed31ed6-940d-4eb5-80fb-3b965238853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cache_occupied = calculate_cache_size(sc)\n",
    "print(f\"Объем кеша в памяти {total_cache_occupied:.2f}M, что превышает {MemoryDescription().storage}M - размер R региона\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8edc678-dcde-4836-b0ae-8c75ae4b98f2",
   "metadata": {},
   "source": [
    "Размер датафрейма так же можно увидеть и в [Spark UI](http://localhost:4040/storage/)\n",
    "\n",
    "![](../imgs/spark-full-taxi-df-cache.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf04780-6595-4af6-bec1-e3cb20aa4fb1",
   "metadata": {},
   "source": [
    "### Посчитать уникальные строки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67453a81-ad14-4972-8e46-6b0a31d49343",
   "metadata": {},
   "source": [
    "Подсчет уникальных строк потребует загрузки датафрейма в регион \"исполнение\" и создание дополнительных объектов (`HashMap`) для получения результата. При нехватке памяти:\n",
    "\n",
    "- часть партиций будет вытеснена из кеша,\n",
    "- также загруженные партиции из региона \"исполнение\" могут несколько раз выгрузиться из памяти на диск, а потом вернуться обратно в память,\n",
    "- только служебные структуры данных (`HashMap`) не могут быть выгружены на диск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13be5db5-87a4-4de8-b14d-4fbdafae9151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_rows_count(df):\n",
    "    sc.setJobDescription(\"Вычислить уникальное число строк\")\n",
    "    \n",
    "    return df.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dae4c3-bde5-461f-bc42-353043ffcd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_rows_count(taxi_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec3a9e2-2a09-495f-b7a5-a34628346b5d",
   "metadata": {},
   "source": [
    "В результате выполнения операции часть данных в кеше пропала из памяти:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e027f1-9293-4a80-98e7-50695c6a80e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cache_occupied = calculate_cache_size(sc)\n",
    "print(f\"Объем кеша в памяти {total_cache_occupied:.2f}M, а размер региона R {MemoryDescription().storage}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13d4422-ff80-4fa2-a576-2f4eb1e110c5",
   "metadata": {},
   "source": [
    "Объем данных в кеше уменьшился, одна партиция была выгружена из кеша:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aba44c1-0e97-4b1f-aafa-a69bff8283ea",
   "metadata": {},
   "source": [
    "![](../imgs/spark-cache_spills_05.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4793f3-229d-42a2-a947-fea3fdd246b9",
   "metadata": {},
   "source": [
    "Общий объем спилов (spills) можно посмотреть на странице стадии:\n",
    "\n",
    "\n",
    "![](../imgs/spark-stage-spill-header.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ecbbe9-a7f6-44e6-b0dd-f53a4c4d99b2",
   "metadata": {},
   "source": [
    "На картинке выше можно увидеть две новые метрики:\n",
    "\n",
    "- **Spill (Memory)** - объем данных, который был вытеснен из памяти,\n",
    "- **Spill (Disk)** - объем данных, который был сохранен на диске в сжатом виде.\n",
    "\n",
    "Можно отметить разницу в объеме одних и те же данных при хранении на диске и в памяти."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e255ef-781a-4a41-948b-aaef251ee148",
   "metadata": {},
   "source": [
    "Информация в заголовке показывает общие числа на все задания (tasks). На странице стадии так же можно найти статистику по спилам в виде гистограммы с персентилями:\n",
    "\n",
    "![](../imgs/spark-stage-spill-stat-05.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51330f7-be51-4785-8808-b82815d03e01",
   "metadata": {},
   "source": [
    "А так же информация по спилам по каждому заданию:\n",
    "\n",
    "![](../imgs/spark-stage-spill-tasks-05.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c8fb16-9892-48d0-a071-9c8e7d499ba1",
   "metadata": {},
   "source": [
    "Для сравнения необходимо изменить границу R региона, а для этого необходимо полностью остановить приложение и запустить его с новыми настройками границ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5919ac94-37e3-413d-bc25-f539b344bf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9230c6a-dc86-4c3b-a9d4-6bc3eda8f0d8",
   "metadata": {},
   "source": [
    "### Установка новой границы кеша"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8e6c15-9472-4404-8775-b44a1179eb36",
   "metadata": {},
   "source": [
    "В качестве новой границы региона кеша (`R`) выберем значение `0.1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b27dbc-9adb-4b64-9f42-96460419d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"Spills\")\n",
    "        .master(\"local[4]\")\n",
    "        .config(\"spark.memory.fraction\", 0.6)\n",
    "        .config(\"spark.memory.storageFraction\", 0.1) # новая грацниа кеша\n",
    "        .getOrCreate()\n",
    ")\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9e5858-2376-4dff-9583-9c9092305a4a",
   "metadata": {},
   "source": [
    "Необходимо явно запустить GC для очистки мусора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a243a5-cd84-43e1-941d-194ab125b212",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark._jvm.java.lang.System.gc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b2bc39-1512-4440-b17b-89afa9ba651c",
   "metadata": {},
   "source": [
    "### Загрузка основного датафрейма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2124964-44f3-4982-b552-8fe6e6360411",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df = load_taxi_df(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b716557-5c43-484e-b411-219de7983223",
   "metadata": {},
   "source": [
    "### Занять кеш"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c64cf7-af37-4fe7-ba4a-057d221ec35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Граница региона (`R`) кеша: {MemoryDescription().storage:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d836be7a-b0f5-4940-9352-b4bdf8a8341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_cache(taxi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661542f8-e0c0-4bb5-aca6-6bdcbae25b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cache_occupied = calculate_cache_size(sc)\n",
    "print(f\"Объем кеша в памяти {total_cache_occupied:.2f}M, что превышает {MemoryDescription().storage}M - размер R региона\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62fd130-77ad-4796-8638-4a2d91ffe904",
   "metadata": {},
   "source": [
    "Размер кешей так же можно увидеть и в [Spark UI](http://localhost:4040/storage/):\n",
    "- [Storage](http://localhost:4040/storage/)\n",
    "- [Executors](http://localhost:4040/executors/)\n",
    "\n",
    "![](../imgs/spark-full-taxi-df-cache.drawio.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab109c7-db00-4ab2-a51c-5f28a51ff3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_rows_count(taxi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94b9b02-930f-44d8-b5f3-8c3af0e7841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cache_occupied = calculate_cache_size(sc)\n",
    "print(f\"Объем кеша в памяти {total_cache_occupied:.2f}M из {MemoryDescription().storage}M доступных\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafec03a-3429-4e34-90c7-4f1276d8618b",
   "metadata": {},
   "source": [
    "Можно заметить, что в этот раз вытеснилось больше партиций из кеша:\n",
    "\n",
    "![](../imgs/spark-cache_spills_01.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048ab7c2-a101-4674-b9f7-887e3272ab20",
   "metadata": {},
   "source": [
    "А также можно увидеть, что больше спилов происходило во время работы задачи:\n",
    "\n",
    "![](../imgs/spark-stage-spill-header-01.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c58e493-0162-4422-8868-92c2b242fc4b",
   "metadata": {},
   "source": [
    "### Способы избежать спилы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b505b685-a45f-4cdd-8f06-fd365bca6b4b",
   "metadata": {},
   "source": [
    "1. добавить оперативной памяти на воркеры;\n",
    "1. из памяти могут вытесняться только партиции целиком, следовательно, вытеснение больших партиции освободит больше места, но иногда необходимо освободить немного места, поэтому предпочтительно работать с небольшими партициями. Настройка следующих опций позволит управлять размером партиций:\n",
    "    - `spark.sql.shuffle.partitions` - сколько партиций будет создаваться после shuffle. Выше значение - меньший размер партиций;\n",
    "    - `spark.sql.files.maxPartitionBytes` - сколько байт в одной партиции: даже если на диске ваши parquet файлы хранятся очень гранулировано, Spark будет объединять их, чтобы получить более крупные партиции. Много небольших партиций могут объединиться в одну большую, но по размеру не превышающую значение указанное в этой настройке.\n",
    "1. явный вызов [`DataFrame#repartition`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.repartition.html) для разбиения партиций на более мелкие."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d4fb89-d14e-41f0-9c7c-14c123f7dd17",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f057f1-5bd4-4d7d-b853-19ce925a6032",
   "metadata": {},
   "source": [
    "Apache Spark старается выполнять всю работу в памяти, но ее ресурс ограничен, поэтому существует механизм спилов: хранение части данных на диске. Спилами могут быть только партиции RDD. Учитывая повсеместное распространение SSD дисков, спилы могут и не быть на столько большой проблемой, какой она представлялась десять лет назад. Но не смотря на это, нужно учитывать, что случайное чтение с SSD диска всё еще в 170 раз медленее чтения из памяти, а поэтому для тонкой настройки нужно понимать почему спилы происходят и как бороться с ними. Понимание устройства памяти воркеров, и как она распределяется, позволит тонко настроить ее под любое приложение."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e6a806-5ab9-40fb-a28e-029ef0f96fbf",
   "metadata": {},
   "source": [
    "### Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0291cc3-b734-401d-9395-af0cebdaec21",
   "metadata": {},
   "source": [
    "1. Разбить `taxi_df` на 100 партиций и сохранить на диск в директорию `/tmp/taxi_100`;\n",
    "1. Загрузить новый датафрейм `taxi_100_df` из `/tmp/taxi_100`;\n",
    "1. Вызывать `fill_cache` для заполнения кеша;\n",
    "1. Сколько памяти занято кешем?\n",
    "1. Запустить `unique_rows_count(taxi_100_df)`, убедиться, что в работе участвуют 100 патиций\n",
    "<details>\n",
    "    <summary>Подсказка</summary>\n",
    "\n",
    "    Необходимо пограть с настройкой `spark.sql.files.maxPartitionBytes`\n",
    "</details>\n",
    "\n",
    "6. Установить границу `M` региона в значение `0.8`, запустить шаги 1-5 снова. Что произошло?\n",
    "<details>\n",
    "    <summary>Подсказка</summary>\n",
    "\n",
    "    Остановить Spark приложение и запустить снова с новыми границами. Не забудьте вызывать <code>spark._jvm.java.lang.System.gc()</code>\n",
    "</details>\n",
    "\n",
    "7. Установить границу `M` региона в значение `0.3`, запустить шаги 1-5 снова. Что произошло?\n",
    "<details>\n",
    "    <summary>Подсказка</summary>\n",
    "\n",
    "    Остановить Spark приложение и запустить снова с новыми границами. Не забудьте вызывать <code>spark._jvm.java.lang.System.gc()</code>\n",
    "</details>\n",
    "\n",
    "8. Установить границу `R` региона в значение `0.7`, запустить шаги 1-5 снова. Что произошло?\n",
    "<details>\n",
    "    <summary>Подсказка</summary>\n",
    "\n",
    "    Остановить Spark приложение и запустить снова с новыми границами. Не забудьте вызывать <code>spark._jvm.java.lang.System.gc()</code>\n",
    "</details>\n",
    "\n",
    "9. Какой вывод можно сделать относительно значениий для региона `M` по умолчанию?\n",
    "<details>\n",
    "    <summary>Подсказка</summary>\n",
    "\n",
    "    Значения по умолчанию на удивление позволяют работать без OOM\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29c3dfb-4608-4ca6-9934-9f440363c8f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
