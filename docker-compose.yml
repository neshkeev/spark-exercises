version: "3.8"
networks:
  spark_network:

x-check-ports: &check-ports ./bin/check-ports:/bin/check-ports
x-highlight: &highlight ./bin/hl:/bin/hl

x-service-template: &template
  restart: on-failure
  networks:
    - spark_network
  healthcheck: &hc
    interval: 5s
    timeout: 3s
    start_period: 10s
    retries: 20
  volumes:
    - *check-ports
    - *highlight

x-public-key: &pub >
  ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAILArDnLYVp+/JkcrJKHX5XDpFj2MdA6NmV09vh7DmVrD spark-exercises

x-private-key: &private |+
  -----BEGIN OPENSSH PRIVATE KEY-----
  b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAAAMwAAAAtzc2gtZW
  QyNTUxOQAAACCwKw5y2FafvyZHKySh1+Vw6RY9jHQOjZldPb4ew5lawwAAAJggO3ZdIDt2
  XQAAAAtzc2gtZWQyNTUxOQAAACCwKw5y2FafvyZHKySh1+Vw6RY9jHQOjZldPb4ew5laww
  AAAEA6oPfTO+faTshF1LXPJNKihyWNqL5QQejwBnFQ8UK4o7ArDnLYVp+/JkcrJKHX5XDp
  Fj2MdA6NmV09vh7DmVrDAAAAD3NwYXJrLWV4ZXJjaXNlcwECAwQFBg==
  -----END OPENSSH PRIVATE KEY-----

services:
  pyspark:
    <<: *template
      # CatBoost doesn't work with Apache Spark 3.5.0 yet
      # image: jupyter/pyspark-notebook:spark-3.5.0
    image: jupyter/pyspark-notebook:spark-3.4.1
    hostname: &name pyspark
    container_name: *name
    command: /usr/local/bin/entrypoint
    healthcheck:
      <<: *hc
      test: bash /bin/check-ports 8888
    depends_on:
      dind:
        condition: service_healthy
      hadoop:
        condition: service_healthy
      hive:
        condition: service_healthy
    ports:
      - "8888:8888"
      - "4040:4040"
    volumes:
      - *check-ports
      - *highlight
      - ./imgs:/home/jovyan/imgs
      - ./work/data:/home/jovyan/work/data
      - ./work/work.ipynb:/home/jovyan/work/work.ipynb
      - ./conf:/tmp/hadoop/conf
      - ./bin/pyspark-entrypoint:/usr/local/bin/entrypoint
      - ./bin/pyspark.bash_aliases:/home/jovyan/.bash_aliases
    environment:
      NOTEBOOK_ARGS: --NotebookApp.token='' --NotebookApp.password=''
      HADOOP_CONF_DIR: /tmp/hadoop/conf
      YARN_CONF_DIR: /tmp/hadoop/conf
      SPARK_LOG_DIR: /tmp/spark-logs
      PRIVATE_KEY: *private
      DIND_HOST: dind
      NAMENODE_HOST: hadoop
      RESOURCEMANAGER_HOST: hadoop

  hadoop:
    <<: *template
    image: neshkeev/hadoop
    hostname: &name hadoop
    container_name: *name
    healthcheck:
      <<: *hc
      test: bash /bin/check-ports 8042 8088 9000 9870 9864
    ports:
      - "8042:8042"
      - "8088:8088"
      - "9870:9870"
      - "9864:9864"
    volumes:
      - *highlight
      - ./conf/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ./conf/hdfs-site.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
      - ./conf/mapred-site.xml:/opt/hadoop/etc/hadoop/mapred-site.xml
      - ./conf/yarn-site.xml:/opt/hadoop/etc/hadoop/yarn-site.xml
      - ./bin/propagate-envs:/usr/bin/before_start
    environment:
      HADOOP_DATANODE_HOST: ${DATANODE_HOST:-localhost}
      HADOOP_NODEMANAGER_HOST: ${NODEMANAGER_HOST:-localhost}

  hive:
    <<: *template
    image: apachehudi/hudi-hadoop_3.1.0-hive_3.1.2-sparkworker_3.2.1
    container_name: &name hive
    hostname: *name
    entrypoint: bash /bin/entrypoint
    depends_on:
      hadoop:
        condition: service_healthy
    healthcheck:
      <<: *hc
      test: /bin/check-ports 9083
    volumes:
      - *check-ports
      - ./bin/hive-entrypoint:/bin/entrypoint
    environment:
      CORE_CONF_fs_defaultFS: hdfs://hadoop:9000

  dind:
    <<: *template
    build:
      context: .
      dockerfile: local/Dockerfile_dind
    hostname: &name dind
    container_name: *name
    healthcheck:
      <<: *hc
      test: sh /bin/check-ports 2222
    privileged: true
    volumes:
      - *check-ports
      - *highlight
      - .:/root/${CURRENT_DIR_NAME:-spark-exercises}
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      CURRENT_DIR_NAME: ${CURRENT_DIR_NAME:-spark-exercises}
      AUTHORIZED_KEYS: *pub

  postgres:
    <<: *template
    image: postgres:14.1
    container_name: &name postgres
    hostname: *name
    healthcheck:
      <<: *hc
      test: /bin/check-ports 5432
    volumes:
      - *check-ports
      - ./db:/docker-entrypoint-initdb.d/
    environment:
      POSTGRES_DB: postgres
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres

  superset:
    <<: *template
    image: apachesuperset.docker.scarf.sh/apache/superset
    container_name: &name superset
    hostname: *name
    depends_on:
      postgres:
        condition: service_healthy
      trino:
        condition: service_healthy
    healthcheck:
      <<: *hc
      test: bash /bin/check-ports 8088
    ports:
      - "18088:8088"
    env_file: conf/superset.env

  trino:
    <<: *template
    image: trinodb/trino
    container_name: &name trino
    hostname: *name
    depends_on:
      hive:
        condition: service_healthy
    healthcheck:
      <<: *hc
      test: bash /bin/check-ports 8080
    ports:
      - "8080:8080"
    volumes:
      - *check-ports
      - ./conf/trino_delta.properties:/etc/trino/catalog/delta_lake.properties
