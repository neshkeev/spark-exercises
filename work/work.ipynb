{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcbc891d-2239-4cc3-9f8a-813abd383ddb",
   "metadata": {},
   "source": [
    "# Шаблон архитектуры системы управления данными \"Lakehouse\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d180104-9226-4f59-aa20-af47553ee08e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Мотивация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5f88e6-b6fe-488c-b2bc-177b1c342baf",
   "metadata": {},
   "source": [
    "### Хранилища Данных - Data Warehouse, DWH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9646cdb3-9f48-4cde-a979-b4c17613c904",
   "metadata": {},
   "source": [
    "**Хранилища данных** (**Data Warehouse**) исторически были призваны решить задачу формирования аналитической картины для бизнеса на базе собираемой информации. Аналитика позволяет бинесу принимать взвешанные решения и формировать стратегию развития компании. Хранилища данных предъявляют требования к формату входящих данных, что позволяет пользователям хранилища данных работать с понятными данными. Характерной чертой традицонных хранилищ данных (**Data Warehouse**) является неразрывная связь между вычислительными ресурсами и ресурсами для хранения данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9f5fbe-5cec-459e-a39a-6caf4554fdfb",
   "metadata": {},
   "source": [
    "С увеличением объема поступающей информации традицонный подход к формированию хранилища данных столкнулись с большими проблемами: неразрывность слоёв хранения и обработки данных диктовала бизнесу вертикальное масштабирование. Бизнес был вынужен закупать железо, способное обслуживать пиковые нагрузки. Таким образом, бизнес тратил много денег, хотя пиковые нагрузки могут и не возникать часто."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9308cb93-4777-40a4-8716-998ea898c08e",
   "metadata": {},
   "source": [
    "В дополнение к увеличению объема обрабатываемой информации альтернативные форматы данных, которые не всегда имеют чёткую структуру (видео, музыка, текст и т.д.), также начали играть большую роль в построении аналитической картины. К неструктурированным данным **хранилища данных** были не готовы абсолютно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db966b72-514e-444d-9efa-9d3c28588802",
   "metadata": {},
   "source": [
    "### Озёра Данных - Data Lake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26a5913-a978-43d3-865a-24a22528b060",
   "metadata": {},
   "source": [
    "Для решения накопившихся проблем были разработаны платформы аналитики данных **второго поколения**.\n",
    "\n",
    "Основная идея заключается в том, что все поступающие данные начали складываться в **озёра данных** (**Data Lake**) - кластер из дешёвых жестких дисков. Данные в **озёре данных** хранятся открытых (open source) форматах, таких как Apache Parquet или ORC.\n",
    "\n",
    "Apache Hadoop с HDFS популяризровал подход с озером данных. От требования к формату входящих данных (`schema-on-write`) удалось перейти к `schema-on-read` - только конечный потребитель знает какие данные ему нужны, и он сам является ответственным за извлечение этих данных из озера данных. Таким образом, `ETL` (**Extract Transform Load**) был заменен на `ELT` (**Extract Load Transform**): бизнес смог собирать всю доступную информацию, которая потом анализировалась различными подходами.\n",
    "\n",
    "Архитектура **Озеро Данных + Хранилища Данных** является доминирующей в современном мире."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a98e987-e6a9-46d7-ae10-ef085f0bea5f",
   "metadata": {},
   "source": [
    "Отличительной особенностью озера данных является разделение слоёв хранения данных и обработки данных: бизнес может заказывать дополнительные процессорные мощности при необходимости."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007e53cb-da5e-492f-b5d3-767c3a5d3d71",
   "metadata": {},
   "source": [
    "### Ограничения современной архитектуры"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9be73d7-dc2e-4e37-85bd-a55982667d6e",
   "metadata": {},
   "source": [
    "В свою очередь озера данных (Data Lake) принесли свои проблемы связанные с качеством и управлением данных. При этом данные по прежнему необходимо доставлять в хранилища данных, к которым подключены витрины данных. Таким образом, все поступающие данные проходят два или три шага:\n",
    "\n",
    "- E**L**T для попадания в озеро данных (Data Lake),\n",
    "- ET**L** для попадания в хранилище данных (Warehouse),\n",
    "- (опиционально) ETL для машинного обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e15f49-e423-4f31-b84e-64873c4b8818",
   "metadata": {},
   "source": [
    "Современний бизнес также полагается на системы машинного обучения и искуственного интеллекта, для которых ни озёра данных (Data Lake), ни хранилища данных (Data Warehouse) не являются идеальным решением."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eb3dac-23b7-4734-b2d5-6b4d4fafa6c0",
   "metadata": {},
   "source": [
    "Среди проблем современной архитектуры организации данных (**Озеро Данных** + **Хранилища Данных**) можно выделить следующие категории:\n",
    "\n",
    "- **Надежность**,\n",
    "- **Свежесть данных**,\n",
    "- **Ограниченные возможности расширенной аналитики**,\n",
    "- **Итоговая стоимость владения данными**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acb4004-cf65-4f07-82fd-9788dae5aeae",
   "metadata": {},
   "source": [
    "#### Надежность"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5be3ad-0c53-4f06-b5fb-dc176eb95f16",
   "metadata": {},
   "source": [
    "Задача поддежрки озера данных и хранилища данных в консистентном состоянии является сложной и затратной. Перекачка данных из озера данных в хранилище данных несёт риски связанные со сбоем оборудования или ошибками программиста, что может выражаться в некоторой разнице между озером данных и хранилищем данных, а это ухудшает качество данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee2c22d-bb2d-497b-b29b-f1222de9be01",
   "metadata": {},
   "source": [
    "#### Свежесть данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746ed619-9977-4b59-aa18-141f40beff12",
   "metadata": {},
   "source": [
    "Самые новые данные всегда сначала в озеро данных, а уже потом в хранилище. Перекачка данных из озера данных в хранилище не может выполниться мнгновенно. Таким образом, современные аналитические системы уступают своим предшественникам (**Data Warehouse**) по качеству свежести данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d761aa-8069-4afc-89e7-93eb949e4833",
   "metadata": {},
   "source": [
    "#### Ограниченные возможности расширенной аналитики"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2eb8a9-0169-4795-8f60-1d98e2541007",
   "metadata": {},
   "source": [
    "Бизнес должен иметь возможность задавать вопросы относительно будущего на основании собранных данных (например, \"Кому эффективнее всего предоставить скидки?\").\n",
    "\n",
    "Современные фреймворки организации машинного обучения PyTorch, TensorFlow, XGBoost имеют ограниченные возможности работы на базе хранилища данных. В отличии от привычных хранилищам запросов BI характера, которые работают с небольшим объемом информации, фреймворки машинного обучения требуют обработки огромных объемов данных.\n",
    "\n",
    "Для подключения машинного обучения есть два варианта:\n",
    "\n",
    "- выгрузить данные из хранилища данных в файлы, которые можно использовать при работе с машинным обучением (третий ETL шаг),\n",
    "- работа с озером данных напрямую. Это отключает возможности хранилища данных по управлению данными:\n",
    "    - ACID транзакции,\n",
    "    - версионирование данных,\n",
    "    - индексирование."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c70a543-75cf-4c29-8aa3-0ba4e424d62f",
   "metadata": {},
   "source": [
    "#### Итоговая стоимость владения данными"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a26c6df-32a6-44e6-95c0-24a7ab3122c4",
   "metadata": {},
   "source": [
    "Одновременная поддержка озера данных и хранилища данных фактически увеличивает затраты на хранение данных вдвое: одни и те же данные лежат как в озере данных (\"грязные\"), так и в хранилище данных (\"чистые\"). При этом также в два раза увеличиваются риски утечки данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c63462-b743-4e14-b79f-1c6d4978e415",
   "metadata": {},
   "source": [
    "### Требования к организации системы управления данными"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7993d711-8b6e-44ca-b471-245bfdb85cde",
   "metadata": {},
   "source": [
    "Таким образом, необходимо организовать данные в озере данных, которое отвечает следующим требованиям:\n",
    "\n",
    "1. открытость форматов данных (Parquet, ORC) для хранения как защита от Vendor Lock-In,\n",
    "2. производительность сопоставимая с хранилищами данных,\n",
    "3. возможности управления атрибутами/признаками (feature) данных, сопоставимые с хранилищами данных,\n",
    "4. прямой `I/O` доступ к данным для расширенной аналитики."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf5e6fb-7ec3-43b4-bdd2-7d9594a56aa1",
   "metadata": {},
   "source": [
    "Шаблон архитектуры **Lakehouse** позволяет построить озеро данных, которое отвечает поставленным требованиям."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84dd136-94ce-45d1-a87a-05fa09d49eb3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Шаблон Lakehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b223ba-6ae8-4d60-ac4d-751e68d0b421",
   "metadata": {},
   "source": [
    "Lakehouse предлагает организовать систему управления данными на базе следующих концепций:\n",
    "\n",
    "- хранение данных в кластера из дешевых жестких дисков (HDFS, S3, GCS),\n",
    "- система демонстрирует функции аналитической СУБД:\n",
    "    - ACID транзакции,\n",
    "    - версионирование данных,\n",
    "    - аудит,\n",
    "    - индексы,\n",
    "    - кеширование,\n",
    "    - оптимизатор запросов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a05fa0-4812-4510-a55e-b4a55a025ebb",
   "metadata": {},
   "source": [
    "Таким образом, система построеная по шаблону Lakehouse заключает в себе комбинацию ключевых преимуществ озёр данных (Data Lake) и хранилищ данных (Data Warehouse):\n",
    "\n",
    "- низкая стоимость хранения данных,\n",
    "- открытые форматы данных (как в Data Lake),\n",
    "- мощные возможности управления данными и оптимизации запросов (как в Data Warehouse)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028fa49e-5c6f-4fbb-815b-223a61e73c13",
   "metadata": {},
   "source": [
    "### Концепции Lakehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1411d9-14a7-46cd-ad28-c65bb17589a4",
   "metadata": {},
   "source": [
    "Шаблон Lakehouse состоит из следующих концепций:\n",
    "\n",
    "- все данные хранятся в блочном хранилище вроде HDFS или S3;\n",
    "- все данные приводятся к стандартному формату, например, Parquet;\n",
    "- данные могут быть организованы в виде логических таблиц;\n",
    "- поверх слоя хранения данных реализован слой метаданных;\n",
    "- слой метаданных может содержать:\n",
    "    - статистику по файлам,\n",
    "    - список файлов, относящихся к текущей версии таблицы.\n",
    "- ACID транзакции, версионирование, индексация - манипуляции со слоем метаданных;\n",
    "- клиенты могут читать файлы из HDFS или S3 напрямую."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb8fe51-6970-45d5-bd2c-6ee602795ac3",
   "metadata": {},
   "source": [
    "### Реализация Lakehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dfa666-b19a-4d87-bb86-bf27d53a52c0",
   "metadata": {},
   "source": [
    "Форматы [Delta Lake](https://delta.io/) (Databricks), [Apache Iceberg](https://iceberg.apache.org/) (Netflix) и [Apache Hudi](https://hudi.apache.org/) (Uber) реализуют концепции похожие на Lakehouse схожим образом:\n",
    "\n",
    "- данные сохраняются в формате Parquet или ORC в блочное хранилище (HDFS, S3),\n",
    "- сохраненные файлы неизменны,\n",
    "- рядом с сохраненными данными создаеются файлы с метаданными,\n",
    "- при внесении изменений в файлы, создаются новые файлы,\n",
    "- метаданные отслеживают какие из имеющихся файлов относятся к текущей версии."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e18103-4859-41b2-b6c3-bb0c26eddb73",
   "metadata": {},
   "source": [
    "Формат Delta Lake был разработан в компании Databricks, которая развивает Apache Spark, поэтому построение системы управления данными на примере Lakehouse в практической части будет основываться на Delta Lake.\n",
    "\n",
    "> **Delta Lake - основной формат для построения Lakehouse!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8e4db5-c1ae-4708-bb12-700d5e54fda3",
   "metadata": {},
   "source": [
    "### Ограничения Delta Lake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a7b6c2-d3ac-471f-b2ff-eb16c595508c",
   "metadata": {},
   "source": [
    "Один файл с метаданными относится к одному Parquet файлу с данными, поэтому, к сожалению, невозможно получить ACID транзакции, включающие множество файлов. Эта проблема известна и находится на контроле ответственных организаций.\n",
    "\n",
    "Учитывая, что Databrics запускает примерно 50% (на 2021 год) всей нагрузки своих клиентов через Delta Lake, возможно отсутствие ACID транзакций на несколько файлов не является большой проблемой."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ffb3a9-d93c-449b-b0d2-f2607d07eaf5",
   "metadata": {},
   "source": [
    "### Особенности Delta Lake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a3d27d-2a97-4427-95ee-8461352a12af",
   "metadata": {},
   "source": [
    "Вне зависимости от используемого блочного хранилища Delta Lake эффективно реализует оптимизации:\n",
    "\n",
    "- пропуск файлов при сканировании,\n",
    "- кластеризация строк."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1d355b-e6bd-46eb-a859-cdaef81b230b",
   "metadata": {},
   "source": [
    "#### Анализ статистики для пропуска файлов при сканировании"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cbd093-6d4e-49b6-9790-e0242c9fc415",
   "metadata": {},
   "source": [
    "Вне зависимости от используемого блочного хранилища, файл с метаданными хранит информацию, которая может использоваться оптимизатором запросов. В метаданных хранится статистика о максимальных и минимальных значениях колонок для каждого файла, что позволяет исключать файлы из сканирования."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21afb68-98b8-40b6-94f1-d2d6dd12c2b9",
   "metadata": {},
   "source": [
    "#### Пропуска файлов при сканировании на базе Bloom фильтра"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae5e5c7-723a-49a2-9ada-0f5fa97ee09f",
   "metadata": {},
   "source": [
    "Для каждого parquet файла строится Bloom фильтр, который также позволяет эффективно пропускать файлы, в которых точно нет требуемых данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98df7446-2b93-4892-b1b2-af5dba36b220",
   "metadata": {},
   "source": [
    "#### Кластеризация строк"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f487480c-0601-4826-a53f-5d9094724518",
   "metadata": {},
   "source": [
    "Delta Lake использует продвинутые алгоритмы для определения наилучшей организации строки на диске, с учетом, что несколько строк будут наиболее часто считываться вместе."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e0f817-5fff-4c49-a98b-079431435c6e",
   "metadata": {},
   "source": [
    "# Запуск Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cb3c99-9639-4e4e-b33b-7201a882c53a",
   "metadata": {},
   "source": [
    "## Конфигурация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5805b5-7b5a-4a97-8cc4-b2ccaa0df103",
   "metadata": {},
   "source": [
    "Для работы с Delta Lake из Python необходимо установить пакет `delta-lake`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af3b680-5322-4a02-b327-4d03ad0575d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install delta-spark==3.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4afce41-c8ee-46a1-8f72-de89a3b23a82",
   "metadata": {},
   "source": [
    "### Запуск Apache Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad78f7c-69a4-44dd-a9df-0a127c8ce423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.dataframe import DataFrame\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e3166a-52d7-4854-bc57-ccb3f0139fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta import configure_spark_with_delta_pip\n",
    "from delta.tables import DeltaTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c21cf78-8466-4e14-93aa-da76889edeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"Delta Demo\")\n",
    "        .master(\"local[4]\")\n",
    "        # .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.1.0\")\n",
    "        .config(\"spark.sql.warehouse.dir\", \"data/spark-warehouse\")\n",
    "        .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "        .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82f62ea-2064-4163-b41c-34f64edfa6bd",
   "metadata": {},
   "source": [
    "Функция `configure_spark_with_delta_pip` активиурет возможности Delta Lake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa716c7-4110-42dc-9386-716ed689c081",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = configure_spark_with_delta_pip(builder) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f02dd9-f7b8-4994-9b00-0de9d49f1d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(configure_spark_with_delta_pip.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c178098a-8b29-4201-997a-71e920413714",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de13bb01-cde4-4a0d-a613-14ff424101dc",
   "metadata": {},
   "source": [
    "Распаковать подготовленные архивы с данными:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c38b26-7e76-45b0-8c38-cdbd1ec87be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd /tmp && rm -rf steam taxi.parquet && unzip -o ~/work/data/steam.zip && unzip -o ~/work/data/taxi.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dfa02b-e10f-456b-9b07-5f745f8aa5ce",
   "metadata": {},
   "source": [
    "Функция `dump_parquet` скроет подробности созхранения датафрейма на диск как parquet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d231e726-576d-4b1e-a5ab-a213999ff12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_parquet(df: DataFrame, num: int, loc: str):\n",
    "    (df\n",
    "        .repartition(num)\n",
    "        .write\n",
    "        .mode(\"overwrite\")\n",
    "        .parquet(loc)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2a8ed2-fc82-437a-a538-5c7cda15d9dd",
   "metadata": {},
   "source": [
    "Файлы будут располагаться в HDFS, поэтому необходимо очистить файловую систему:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660d52ac-6e87-408c-a8e8-a132a1fe9d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "hdfs dfs -rm -f -r /user/jovyan/data && \\\n",
    "hdfs dfs -mkdir -p /user/jovyan/data/stream && \\\n",
    "hdfs dfs -mkdir -p /user/jovyan/data/taxi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c119797-368e-4960-8dea-b90d088d46ce",
   "metadata": {},
   "source": [
    "Загрузить локальные файлы в Apache Spark, разбить их на 4 партиции и положить в HDFS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d79dd7-e423-4d6c-8b6f-dd00cc97b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setJobDescription(\"Разбить датафреймы steam на 4 партиции\")\n",
    "\n",
    "# dump_parquet(spark.read.parquet(\"file:///tmp/steam/details.parquet\"), 4, \"/user/jovyan/data/steam/details\")\n",
    "# dump_parquet(spark.read.parquet(\"file:///tmp/steam/tags.parquet\"), 4, \"/user/jovyan/data/steam/tags\")\n",
    "dump_parquet(spark.read.parquet(\"file:///tmp/steam/games.parquet\"), 4, \"/user/jovyan/data/steam/games\")\n",
    "# dump_parquet(spark.read.parquet(\"file:///tmp/taxi.parquet\"), 4, \"/user/jovyan/data/taxi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c334976-29ff-4550-abc0-a629b4689ec1",
   "metadata": {},
   "source": [
    "Файлы загружены в HDFS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8faae9-2978-4447-aca4-85ec9ef9802b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "hdfs dfs -find /user/jovyan/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39446b37-0b0c-425d-bbed-3cfc9c88cba9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Delta таблицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1d6c19-3bc4-44bc-8ec3-3df847491df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_first_table_path = 'data/my-first-delta-table'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93b60b4-3252-4675-9524-e697fa021ccd",
   "metadata": {},
   "source": [
    "### Создание Delta таблицы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9720cbf6-41d8-4816-a102-e4c0685dd0a5",
   "metadata": {},
   "source": [
    "Сохранение датафрейма в формате `delta` создает новую Delta таблицу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047a1de8-f9ee-4418-bb4b-eacc21d94d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.range(0, 5)\n",
    "(\n",
    "    data\n",
    "        .write\n",
    "        .format(\"delta\")\n",
    "        .save(my_first_table_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f52657-9af1-4983-b650-8f6713909bdf",
   "metadata": {},
   "source": [
    "### Загрузка Delta таблицы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c312081a-79c6-4d94-b9f8-64768b8c1324",
   "metadata": {},
   "source": [
    "Чтение данных в формате `delta` читает данные из таблицы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eedacb2-0ca5-4eb7-9883-cd48cf2e13e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark\n",
    "        .read\n",
    "        .format(\"delta\")\n",
    "        .load(my_first_table_path)\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea524151-c74a-40e6-b50f-05c05f1194b5",
   "metadata": {},
   "source": [
    "### Обновление Delta таблицы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f8a994-99df-466c-af01-a41c46be9170",
   "metadata": {},
   "source": [
    "Запись датафрейма в формате `delta` и в режиме `overwrite` обновляет данные в `delta` таблице:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dc47a8-f686-4b6e-9f06-ad01713dba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.range(5, 10)\n",
    "(\n",
    "    df\n",
    "        .write\n",
    "        .format(\"delta\")\n",
    "        .mode(\"overwrite\")\n",
    "        .save(my_first_table_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76ee5e0-8abf-4dc8-96f3-aa0dff4e37ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark\n",
    "        .read\n",
    "        .format(\"delta\")\n",
    "        .load(my_first_table_path)\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834dd577-1558-43af-a9d5-49d1a8c59fd0",
   "metadata": {},
   "source": [
    "### Частичное обновление Delta таблицы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d901c39a-8949-45e0-b386-363dfb8ed82c",
   "metadata": {},
   "source": [
    "Данные в таблице можно обновить по условию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ccc736-51c0-4965-8c3f-aa715c6734a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable = DeltaTable.forPath(spark, my_first_table_path)\n",
    "\n",
    "deltaTable.update(\n",
    "    condition = F.expr(\"id % 2 == 0\"),\n",
    "    set = { \"id\": F.expr(\"id + 100\") }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc124774-81e2-48bc-a056-1c8adec64b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark\n",
    "        .read\n",
    "        .format(\"delta\")\n",
    "        .load(my_first_table_path)\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b715e2-e393-4f24-ad0a-e9f11cf0ce09",
   "metadata": {},
   "source": [
    "### Удаление данных Delta таблицы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab32fc0b-bb4c-49ae-8431-7c2681803e41",
   "metadata": {},
   "source": [
    "Удалить данные в таблице можно можно обновить по условию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02d1f32-fd90-4493-be70-97fc14e1eea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable = DeltaTable.forPath(spark, my_first_table_path)\n",
    "deltaTable.delete(condition = F.expr(\"id % 2 == 0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06daaf71-7aa6-4154-82c0-d5bce1de2a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark\n",
    "        .read\n",
    "        .format(\"delta\")\n",
    "        .load(my_first_table_path)\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c479f17a-0462-472b-9ef5-2b4f82b6d26c",
   "metadata": {},
   "source": [
    "### Слияние данных - Merge, Upsert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed64e93-0465-425f-87c4-678c38795411",
   "metadata": {},
   "source": [
    "Данные могут быть записаны в таблицу по принципу слияния (merge, upsert), т.е. существующие данные заменяются, новые данные добавляются:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a6bc44-aa2e-4c8c-a123-e46a41156e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable = DeltaTable.forPath(spark, my_first_table_path)\n",
    "\n",
    "# Upsert (merge) new data\n",
    "newData = spark.range(0, 20).withColumnRenamed(\"id\", \"x\")\n",
    "\n",
    "deltaTable \\\n",
    "  .merge(newData, col(\"id\") == col(\"x\")) \\\n",
    "  .whenMatchedUpdate(set = { \"id\": col(\"x\") }) \\\n",
    "  .whenNotMatchedInsert(values = { \"id\": col(\"x\") }) \\\n",
    "  .execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3bd99d-7400-40bc-b24e-e1b854301bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark\n",
    "        .read\n",
    "        .format(\"delta\")\n",
    "        .load(my_first_table_path)\n",
    ")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e390053-de41-4553-8409-1feccc26dcc4",
   "metadata": {},
   "source": [
    "Обратите внимание, что операция `execute` выполняется немедленно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c4b916-f92b-4c30-b7e6-eae4ace84c8c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Машина времени"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a8e9e1-36c2-42a6-aa84-126dd7c2dd9a",
   "metadata": {},
   "source": [
    "Все файлы, загруженные в HDFS через Delta Lake, становятся неизменяемыми. Но как тогда выполняется обновление данных?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceccbca-1c77-4455-b6f1-9e35e8bef855",
   "metadata": {},
   "source": [
    "Delta создает новые файлы в директории таблицы и при помощи дополнительных файлов отслеживает, какие файлы составляют содержимое текущей версии таблицы.\n",
    "\n",
    "Delta поддерживает версионирование, а значит в любой момент можно вернуться к любой из предыдущих версий: файлы по прежнему находятся в директории таблицы. В качестве примера можно вернуться к самой первой версии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29555670-204c-4827-95f6-4029d8323e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark.read\n",
    "        .format(\"delta\")\n",
    "        .option(\"versionAsOf\", 0)\n",
    "        .load(my_first_table_path)\n",
    ")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb844711-3ffd-4273-8dd5-20daf10627f8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Конвертация Parquet в Delta Lake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cec34c-42de-4ec7-8575-0cd054789453",
   "metadata": {},
   "source": [
    "Delta Lake работает на базе Parquet, поэтому конвертация выполняется простым добавлением файлов с метаданными в директорию с Parquet файлами:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d554dc84-667b-46ec-89e3-f03200f2fd76",
   "metadata": {},
   "source": [
    "Состояние директории без файлов с метаданными Delta Lake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff4bddc-ddb0-4f24-ad74-9eb4fe3c4f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "hdfs dfs -find /user/jovyan/data/taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f17e38-7486-4d26-8e9d-dd4810b553cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_path = '/user/jovyan/data/taxi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2ac9ca-5f39-405f-bb04-2a0acea942c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable = DeltaTable.convertToDelta(spark, f\"parquet.`{taxi_path}`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bc7ab7-282e-4b93-9271-0921c4f8ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DeltaTable.convertToDelta.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fff1e5-8bbe-46bf-9699-0354f8290f2c",
   "metadata": {},
   "source": [
    "Состояние директории после конвертации в Delta Lake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d4631a-14f5-4471-b3d9-66f782a37ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "hdfs dfs -find /user/jovyan/data/taxi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3fe30f-fbf6-441d-87d6-8468c6f617bd",
   "metadata": {},
   "source": [
    "Директория `_delta_log` содержит метаданные, в частности, схему:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f57c32-ac23-470c-b81a-b34ec232735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "hdfs dfs -cat /user/jovyan/data/taxi/_delta_log/00000000000000000000.json | \\\n",
    "grep metaData | json_pp | \\\n",
    "grep schema | sed 's,\\s*\"schemaString\" : \",,;s,\"$,,;s,\\\\\",\",g' | json_pp > schema.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ca72e9-123f-4395-8d3f-138702416f1f",
   "metadata": {},
   "source": [
    "Вывод команды сохранен в [schema.json](schema.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b47c344-f688-4221-943e-b7a55f85a9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "hdfs dfs -cat /user/jovyan/data/taxi/_delta_log/00000000000000000000.json | \\\n",
    "grep add |& head -n 1 | json_pp | \\\n",
    "grep stats | sed 's,\\s*\"stats\" : \",,;s,\"$,,;s,\\\\\",\",g' | json_pp > stats.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd28fc40-cb69-430c-b31c-b5ea9978c140",
   "metadata": {},
   "source": [
    "Вывод команды сохранен в [stats.json](stats.json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed00a2c-5019-4348-b5e7-4b1dc826dcfd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Z-Order оптимизация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437b1eb0-dbce-4962-813f-c3bb31ca96f2",
   "metadata": {},
   "source": [
    "After you are done with the writes on the delta table, it might be useful to call optimize on it.\n",
    "\n",
    "- call [optimize](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.optimize)\n",
    "- use [z-order](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaOptimizeBuilder.executeZOrderBy) by the column user_id\n",
    "- check manually the files under the table to see that it was compacted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60f3a34-62d2-4a7b-bf29-ff8f274d8a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable = DeltaTable.forPath(spark, taxi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b77ccf-8f27-41b1-93f2-646db90af47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "hdfs dfs -find /user/jovyan/data/taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2209eb9e-65e4-4fa3-9a17-15af55d3e7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = deltaTable.optimize().executeZOrderBy(\"passenger_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab65af88-4082-435d-9f54-bfa6c5e441f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "hdfs dfs -find /user/jovyan/data/taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c111cc20-f4cc-4359-beda-7b5f6db8bf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfbea49-33e7-41b7-9b65-95c66422a21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"metrics.zOrderStats\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2d4e59-6dd3-4775-bbd3-1a7f96c43b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5838a817-4056-4efb-9a46-59127fa1e91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "deltaTable.history()\n",
    "    .select(\n",
    "        \"version\",\n",
    "        \"timestamp\",\n",
    "        \"operation\",\n",
    "        \"operationMetrics.numRemovedFiles\",\n",
    "        \"operationMetrics.numAddedFiles\",\n",
    "        \"operationMetrics.numConvertedFiles\")\n",
    "    .show(5, False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1718e07-1200-4e0f-bd9c-32d60ce584af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Вакуумная очистка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1c3889-ce0f-4ba0-b35d-d15525dd3419",
   "metadata": {},
   "source": [
    "Количество файлов таблицы может расти бесконтрольно, но не все из них нужны. Файлы, которые относятся к старым версиям можно удалять при помощи [`vacuum`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.vacuum):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1df825-6eb5-4696-9310-92f58820daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable = DeltaTable.forPath(spark, taxi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf197cc-9365-42dc-acb4-5bcee08d52f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "try:\n",
    "    deltaTable.vacuum(0)\n",
    "except Exception as e:\n",
    "    print(e, file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fc0deb-b9ad-42dd-a989-93e9be84d74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set('spark.databricks.delta.retentionDurationCheck.enabled', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7635ea2-c943-420a-83b8-5181a0aa96b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable.vacuum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d032bf9-2547-4189-ae89-762fd9d48b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "hdfs dfs -find /user/jovyan/data/taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73072b4-b67a-4893-a837-ab5fd1ca7202",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable.history().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8050fdd2-1f54-452b-b46b-476d2469e4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66afb57d-5b55-453f-a36e-651583e292a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "try:\n",
    "    (\n",
    "    spark.read\n",
    "        .format(\"delta\")\n",
    "        .option(\"versionAsOf\", 0)\n",
    "        .load(taxi_path)\n",
    "        .show()\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e.java_exception.getMessage(), file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0716dcaf-d824-4223-8612-c48ed2217e23",
   "metadata": {},
   "source": [
    "## Построение Lakehouse архитектуры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d63830-d63f-4f12-a0da-7a5a15941c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.dataframe import DataFrame\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381a1a25-8eef-4e8a-a6dc-c6b3f83830bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta import configure_spark_with_delta_pip\n",
    "from delta.tables import DeltaTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7069cf0f-94b3-4637-a12e-6d2bb17e3554",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeb77b0-5629-4dc6-9488-48be27ec8509",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"Delta Demo\")\n",
    "        .master(\"local[4]\")\n",
    "        .config(\"spark.sql.warehouse.dir\", \"data/spark-warehouse\")\n",
    "        .config(\"spark.driver.memory\", \"4g\")\n",
    "        .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "        .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "        .enableHiveSupport()\n",
    ")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dadb997-e0bb-42b1-aa43-b7d8e6685e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_path = \"data/steam/games\"\n",
    "games_delta = DeltaTable.convertToDelta(spark, f\"parquet.`{games_path}`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d85c087-9b2a-4dac-a4cd-5c5cb699fecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "\n",
    "ids = [ F.lit(x) for x in range(1, 10) ]\n",
    "\n",
    "reviews_metacritic = (games_delta.toDF()\n",
    "    .withColumn(\"id\", F.explode(F.array(ids)))\n",
    "    .select(\n",
    "        F.expr(\"app_id * 1000000 + id\").alias(\"id\"),\n",
    "        \"app_id\",\n",
    "        F.expr(\"STRING(DATE_ADD(date_release, CAST(floor(rand() * 500) AS INT)))\").alias(\"review_date\"),\n",
    "        col(\"title\").alias(\"review\"),\n",
    "        F.floor(F.rand() * 100).alias(\"rating\"),\n",
    "        F.floor(F.rand() * 100000).alias(\"user_id\"),\n",
    "    )\n",
    ")\n",
    "reviews_metacritic.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4478fe70-2d3b-4565-987a-4abaa3e481c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "reviews_metacritic\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .partitionBy(\"rating\")\n",
    "    .mode(\"overwrite\")\n",
    "    .saveAsTable(\"reviews_metacritic\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861ab902-809e-4a13-b140-54a351152c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "\n",
    "ids = [ F.lit(x) for x in range(1, 5) ]\n",
    "\n",
    "reviews_igromania = (games_delta.toDF()\n",
    "    .withColumn(\"id\", F.explode(F.array(ids)))\n",
    "    .select(\n",
    "        F.expr(\"app_id * 1000000 + id\").alias(\"id\"),\n",
    "        \"app_id\",\n",
    "        F.expr(\"unix_timestamp() + floor(rand() * 200)\").alias(\"review_date_unix\"),\n",
    "        col(\"title\").alias(\"review\"),\n",
    "        F.round(F.rand() * 10, 1).alias(\"rating\"),\n",
    "        F.floor(F.rand() * 100000).alias(\"user_id\"),\n",
    "    )\n",
    ")\n",
    "reviews_igromania.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0311c3a3-61c7-4614-9af8-a1f086cbfbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "reviews_igromania\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .partitionBy(\"rating\")\n",
    "    .mode(\"overwrite\")\n",
    "    .saveAsTable(\"reviews_igromania\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f19f85f-3b60-4ed2-bc4a-d0dd9ca59a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.table(\"reviews_igromania\").groupBy(\"id\").count().where(\"count > 1\").show()\n",
    "spark.table(\"reviews_metacritic\").groupBy(\"id\").count().where(\"count > 1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea44a3c7-934d-43dc-a9db-871445996e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = (\n",
    "    spark.range(100000)\n",
    "        .withColumn(\"user_id\", F.concat(F.lit(\"user\"), F.lit(\"_\"), col(\"id\")))\n",
    "        .withColumn(\"gender\", F.when(F.rand() > 0.6, \"M\").otherwise(\"F\"))\n",
    "        .withColumn(\"dob\", F.expr(\"ADD_MONTHS(current_date(), -CAST(floor(rand() * 25 * 12) AS INT) -10 * 12)\"))\n",
    ")\n",
    "users_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3836b6b6-7b57-43f0-9f51-1ce7ebbb864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "users_df\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .partitionBy(\"gender\")\n",
    "    .mode(\"overwrite\")\n",
    "    .saveAsTable(\"users\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3efe5fc-c3cf-4be9-9083-be75545b4e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeltaTable.forName(spark, \"reviews_igromania\").optimize().executeZOrderBy(\"app_id\")\n",
    "# DeltaTable.forName(spark, \"reviews_metacritic\").optimize().executeZOrderBy(\"app_id\")\n",
    "# DeltaTable.forPath(spark, \"data/steam/games\").optimize().executeZOrderBy(\"app_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d315b198-1b9d-49c2-92b4-3e620ad6c1c9",
   "metadata": {},
   "source": [
    "### Серебрянный слой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305cf547-66ed-40f7-a1be-2315f5f9bd4c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# spark.sql(\"\"\"\n",
    "# CREATE OR REPLACE TABLE reviews\n",
    "# USING DELTA\n",
    "# PARTITIONED BY (source, rating)\n",
    "# --ZORDER BY  app_id\n",
    "# AS (\n",
    "#   SELECT id\n",
    "#        , app_id\n",
    "#        , CAST(from_unixtime(review_date_unix) AS TIMESTAMP) review_date\n",
    "#        , review\n",
    "#        , ROUND(rating * 100, 0) rating\n",
    "#        , user_id\n",
    "#        , 'IGROMANIA' source\n",
    "#     FROM reviews_igromania\n",
    "#    WHERE 1 != 1\n",
    "\n",
    "#   UNION ALL\n",
    "\n",
    "#   SELECT id\n",
    "#        , app_id\n",
    "#        , to_timestamp(review_date) review_date\n",
    "#        , review\n",
    "#        , ROUND(rating, 0) rating\n",
    "#        , user_id\n",
    "#        , 'METACRITIC' source\n",
    "#     FROM reviews_metacritic\n",
    "#    WHERE 1 != 1\n",
    "# )\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5df4ad5-2da1-4529-ac50-778e0491b8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS reviews_silver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202e83b4-1489-482e-b3f0-cc4785dfc83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE reviews_silver (\n",
    "    id STRING NOT NULL,\n",
    "    app_id INT NOT NULL,\n",
    "    review_ts TIMESTAMP NOT NULL,\n",
    "    review STRING,\n",
    "    rating INT,\n",
    "    user_id INT NOT NULL,\n",
    "    source STRING NOT NULL\n",
    ")\n",
    "USING DELTA\n",
    "PARTITIONED BY (source, rating)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a25b827-5352-42a4-a6cd-9ff03c882d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"DESC EXTENDED reviews_silver\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016c71ba-a9e7-4cce-a27c-6c2738297e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_silver = DeltaTable.forName(spark, \"reviews_silver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d6d84e-db12-479c-bd60-9bdc72ab7df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_bronze_igromania = spark.table(\"reviews_igromania\").withColumn(\"id\", F.concat(F.lit(\"igromania_\"), col(\"id\")))\n",
    "# reviews_bronze_metacritic = spark.table(\"reviews_metacritic\").withColumn(\"id\", F.concat(F.lit(\"metacritic_\"), col(\"id\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dd3d73-0bf2-4916-96ba-cff3883fdab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_bronze_igromania = spark.sql(\"\"\"\n",
    "SELECT 'IGROMANIA' || id id\n",
    "     , app_id\n",
    "     , CAST(from_unixtime(review_date_unix) AS TIMESTAMP) review_ts\n",
    "     , review\n",
    "     , ROUND(rating * 10, 0) rating\n",
    "     , user_id\n",
    "     , 'IGROMANIA' source\n",
    "  FROM reviews_igromania\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6acbe9-5380-418b-878c-09323e91c3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_bronze_metacritic = spark.sql(\"\"\"\n",
    "SELECT 'METACRITIC' || id id\n",
    "     , app_id\n",
    "     , to_timestamp(review_date) review_ts\n",
    "     , review\n",
    "     , ROUND(rating, 0) rating\n",
    "     , user_id\n",
    "     , 'METACRITIC' source\n",
    "  FROM reviews_metacritic\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99897e2-20f9-4854-88ea-753df2c514bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "reviews_silver.alias(\"silver\")\n",
    "  .merge(reviews_bronze_igromania.alias(\"bronze\"), col(\"silver.id\") == col(\"bronze.id\"))\n",
    "  .whenMatchedUpdateAll()\n",
    "  .whenNotMatchedInsertAll()\n",
    "  .execute()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e3688b-1526-4a43-ac93-1df0eade88aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "reviews_silver.alias(\"silver\")\n",
    "  .merge(reviews_bronze_metacritic.alias(\"bronze\"), col(\"silver.id\") == col(\"bronze.id\"))\n",
    "  .whenMatchedUpdateAll()\n",
    "  .whenNotMatchedInsertAll()\n",
    "  .execute()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43700765-02ef-4440-a7fe-e717e273a844",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.table(\"reviews_silver\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94e5aaa-167e-49a0-ae62-b0ed161b9988",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.table(\"reviews_silver\").groupBy(\"id\").count().where(\"count > 1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d48338f-04cc-4c01-bedc-7c76b3171180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_silver.optimize().executeZOrderBy(\"app_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7396f00f-78ae-4093-8136-807dae6ea6e5",
   "metadata": {},
   "source": [
    "### Золотой слой - Golden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116ea957-c208-4acf-b6b9-6d42f07aaa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS game_review_facts_golden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5472f23-e5da-4649-ad49-9f307d8b63d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE game_review_facts_golden (\n",
    "    user_id INT NOT NULL,\n",
    "    app_id INT NOT NULL,\n",
    "    review_id STRING NOT NULL,\n",
    "    ts TIMESTAMP NOT NULL\n",
    ")\n",
    "USING DELTA\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19376ba-9bb6-4d05-93f3-37c5689c9b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "golden_facts_stream = (\n",
    "    spark.readStream\n",
    "        .format(\"delta\")\n",
    "        # .table(\"reviews_silver\")\n",
    "        .load(\"/user/jovyan/data/spark-warehouse/reviews_silver\")    \n",
    "        .writeStream\n",
    "        .format(\"console\")\n",
    ")\n",
    "golden_facts_stream.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0dd337-2e04-4c54-91fa-f5d37c06f495",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.range(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acec5c44-b32b-4c2c-8f7e-a2907801ba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "game_review_facts_golden.alias(\"gold\")\n",
    "  .merge(reviews_silver.alias(\"silver\"), col(\"gold.user_id\") == col(\"bronze.id\"))\n",
    "  .whenMatchedUpdateAll()\n",
    "  .whenNotMatchedInsertAll()\n",
    "  .execute()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1ed681-7c82-40a2-9e33-4d4976cd7830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266b9c3a-8633-4564-8c64-7e3dcb788cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60ccf2d-994a-4758-b449-7420cc743478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9528504c-47cd-4a56-b5c7-2b69a54c5da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df = spark.read.parquet(\"/user/jovyan/data/taxi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3b9f10-d7e9-43f5-9c6f-11ccda6e8503",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df = spark.read.parquet(\"/user/jovyan/data/taxi\")\n",
    "taxi = bucketing(taxi_df, \"taxi\", \"passenger_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2cb9b8-ea24-4647-abce-9b191987a787",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS taxi\n",
    "USING DELTA\n",
    "PARTITIONED BY (passenger_count)\n",
    "\"\"\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd1d4c8-47b7-4bf1-b845-94ea775f2a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad451ba-6b0a-4a0b-ad33-0e495f4a594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.listDatabases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78b03d9-27f4-40f3-b62a-975928bc973e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fd2377-1b15-468b-914c-90936feb2164",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS taxi\").collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
