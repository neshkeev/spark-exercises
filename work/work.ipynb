{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5e0f817-5fff-4c49-a98b-079431435c6e",
   "metadata": {},
   "source": [
    "# Spark Connect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3a9698-9da3-41f9-897d-bad821a25f63",
   "metadata": {},
   "source": [
    "## Мотивация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2322280-964f-4be2-9a1b-6f5943a598dc",
   "metadata": {},
   "source": [
    "В Apache Spark 3.4.0 появилась технология **Spark Connect**, которая позволяет разделить драйвер на две части: клиент и сервер. Общение между клиентом и сервером осуществляется при помощи [gRPC](https://ru.wikipedia.org/wiki/GRPC) запросов. На данный момент доступно лишь использование **DataFrame API**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85268101-736f-460f-b2d7-9b590b1cc67c",
   "metadata": {},
   "source": [
    "### Как это работает"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825decc5-007c-4aeb-b252-1a6e94741d8e",
   "metadata": {},
   "source": [
    "Обработка запроса в оптимизаторе **Catalyst** проходит четыре стадии:\n",
    "\n",
    "- Unresolved Logical Plan,\n",
    "- Logical Plan,\n",
    "- Optimized Logical Plan,\n",
    "- Physical Plan.\n",
    "\n",
    "Разбор запроса до стадии `Unresolved Logical Plan` можно выполнить на клиенте, а остальные стадии будет выполнять сервер. При этом клиент может использовать любой язык программирования, если он способен:\n",
    "\n",
    "- сформировать Unresolved Logical Plan,\n",
    "- отправить Unresoled Logical Plan серверу по протоколу [gRPC](https://ru.wikipedia.org/wiki/GRPC).\n",
    "\n",
    "Таким образом, экосистема **Spark** становится еще более доступной."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f900c6c-87e2-43ca-aa44-9ac3d98d9c44",
   "metadata": {},
   "source": [
    "Для работы с **Spark Connect** на клиенте необходимо установить библиотеки для работы с `gRPC`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d456964-7d8b-4280-9110-3393c2ab5c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install grpcio==1.59.0 grpcio-status==1.59.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b0a13a-af99-4622-b3d7-a1328c313cbe",
   "metadata": {},
   "source": [
    "## Запуск клиента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad78f7c-69a4-44dd-a9df-0a127c8ce423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e05735d-f375-4e4d-a7ee-4dafbfb2c454",
   "metadata": {},
   "source": [
    "**Spark Connect** нельзя запустить одновременно с приложением Spark запущенном в локальном режиме, поэтому необходимо проконтролировать, что локальной версии Spark нет.\n",
    "\n",
    "Следующая команда запустит Spark в локальном режиме или подключится к приложению Spark, запущенному в локальном режиме, и сразу остановит его:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa10bc25-af52-4bb6-adda-dc80d26666a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SparkSession.builder.master(\"local\").getOrCreate().stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca14b14-2817-462e-8694-ac41085558e8",
   "metadata": {},
   "source": [
    "Сейчас можно подключиться к запущенному приложению Spark на удаленном сервере:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06701567-b9d2-4ca3-86af-8b5803116b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .remote(\"sc://connect:15002\")\n",
    "        .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e100c7-e6d9-4455-b619-2384fc6f1880",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"select 'Hello, Spark Connect!' as message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2872838d-5a71-43d4-b6e4-5ce7d9aaaf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(1, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c71bf33-7e29-49e1-b389-a4099ddb7330",
   "metadata": {},
   "source": [
    "## Запуск сервера"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3990c9d7-5eb1-425e-905f-521b576ab539",
   "metadata": {},
   "source": [
    "Приложение Spark запущено на `yarn` в docker сервисе под названием `connect`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fdc38a-e8c0-4d09-aac2-3cd3a4fa3eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose ps connect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d790de-e7a0-4d62-a74d-a26306c14e31",
   "metadata": {},
   "source": [
    "Учитывая, что сервер запущен в сервисе `connect`, Spark UI также доступен в сервисе `connect`. Не смотря на эту особенность, порт 4040 прокинут на локальную машину и **Spark UI** доступен по адресу [localhost:4040](http://localhost:4040)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d99016-7e75-4101-8f40-6498c60b32cb",
   "metadata": {},
   "source": [
    "Для запуска **Spark Connect** сервера необходимо запустить `$SPARK_HOME/sbin/start-connect-server.sh`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536383b0-7d1f-43b9-918e-9477679641d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -l $SPARK_HOME/sbin/start-connect-server.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6841d7-9116-4c3b-ba3a-5b0b2bb11cc7",
   "metadata": {},
   "source": [
    "Сервис `connect` автоматически запускает **Spark Connect** при старте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f875e71-151c-48ba-a10d-5aa7fa4cfc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose top connect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db79bee1-6998-4fa7-894d-e46a24afbd1d",
   "metadata": {},
   "source": [
    "Входной точкой сервиса `connect` является файл `/usr/local/bin/entrypoint`, который активирует `start-connect-server.sh`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75edec7-59d6-452b-be47-0db05ba56309",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && HOST=connect execute \\\n",
    "grep 'start-connect-server.sh' /usr/local/bin/entrypoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da23c12-19c0-472e-80c5-a487bf0e19de",
   "metadata": {},
   "source": [
    "Параметры запуска приложения передаются через `$SPARK_HOME/conf/spark-defaults.conf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8eaec7-5648-4260-8ce2-7e0cd913528b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && HOST=connect execute \\\n",
    "cat $SPARK_HOME/conf/spark-defaults.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ca755f-025f-4c6b-b449-7c9653dc1054",
   "metadata": {},
   "source": [
    "## Остановка клиента"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49259df1-2133-419f-91d5-5cea0c622ed2",
   "metadata": {},
   "source": [
    "При вызове `SparkSession#stop` остановится только клиент, сервер продолжит обрабатывать запросы от других клиентов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dacd7db-28fc-4220-ab33-d00586529de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d8dc6b-c8e0-4d58-823d-6961fd6deb88",
   "metadata": {},
   "source": [
    "Доступность сервера можно проверить, если запустить нового клиента:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32877234-db05-4f66-82c8-fa776c3d3c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .remote(\"sc://connect:15002\")\n",
    "        .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedeb7f3-d8ca-469c-b222-586e0ada6670",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select 'Hello, Spark Connect!' as message\").show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985a35a8-85f7-411f-900a-5bf7b0c9c747",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8c0039-c9c6-418f-b3ae-daf5b082c8cd",
   "metadata": {},
   "source": [
    "Если открыть [Spark UI](http://localhost:4040), то можно увидеть список запросов от всех предыдущих приложений."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9590147b-4615-49b5-83fb-fdbaf2c855d5",
   "metadata": {},
   "source": [
    "## Остановка сервера"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db9152e-4d7e-4367-ae0a-d347eda87658",
   "metadata": {},
   "source": [
    "Остановка сервера осуществляется при помощи скрипта `$SPARK_HOME/sbin/stop-connect-server.sh`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f867f2b-3f89-40cd-aa03-ee4be98bfbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -l $SPARK_HOME/sbin/stop-connect-server.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57ae8c4-5270-4341-be36-5caf409f2d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && HOST=connect execute \\\n",
    "$SPARK_HOME/sbin/stop-connect-server.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cc420c-a3c6-4225-8278-00b6b09c9c61",
   "metadata": {},
   "source": [
    "После остановки сервера невозможно запустить нового клиента. Попробуйте запустить код (приложенение Spark просто повиснет):\n",
    "\n",
    "```python\n",
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .remote(\"sc://connect:15002\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf31b4e9-0e9c-4ff0-8345-9d2f91e9accf",
   "metadata": {},
   "source": [
    "Для восстановления сервера необходимо перезапустить сервис `connect`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440b51bd-36ef-44a2-add7-5290ef389afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose restart connect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b53f5d-55d3-4ed1-88d3-20586a1c7012",
   "metadata": {},
   "source": [
    "Необходимо дождаться пока в колонке **STATUS** появится значение `healthy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a0e77d-8567-469b-bdb6-c0910cbed928",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose ps connect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da680a25-7df6-453b-8d47-d86050e7cc8e",
   "metadata": {},
   "source": [
    "Spark Connect сервер также остановится, если просто остановить сервис `connect`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a815bf-f10c-4c4e-9d3b-336b4fa89b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose stop connect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a380a82-4ba3-4d42-be53-eea8d31da8e7",
   "metadata": {},
   "source": [
    "## Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc509e69-94e4-4189-8cbd-614e15f125f4",
   "metadata": {},
   "source": [
    "Архитектура **Catalyst** оказалась настолько удачной, что открыла дверь для **Spark Connect**. Теперь можно запустить драйвер на мощной машине в облаке, а программисты могут использовать менее производительное аппаратное обеспечение, не теряя при этом эффективности. Spark Connect достаточно молодая технология, поэтому не получила пока широкого распространения, но в недалеком будущем программисты смогут использовать любой язык для работы со Spark, т.к. для поддержки Spark Connect на клиенте необходимо разработать разбор запросов, а также реализовать несколько gRPC [контрактов](https://github.com/apache/spark/tree/c47a9205b2de1c0638e3824564f0d09bad3f4b24/connector/connect/common/src/main/protobuf/spark/connect)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a148e07-94fb-4fb7-8749-25bfb359a547",
   "metadata": {},
   "source": [
    "## Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c33c7c-1646-4436-84fb-545d19fb1d79",
   "metadata": {},
   "source": [
    "1. Запустить Spark Connect сервер со следующей конфигурацией:\n",
    "    - локальный режим на 4 потока,\n",
    "    - `1512MB` памяти,\n",
    "    - на порту [15020](https://spark.apache.org/docs/latest/configuration.html#spark-connect).\n",
    "2. Подключиться к Spark Connect серверу.\n",
    "3. Проверить настройки через Spark UI. Почему объем доступной памяти меньше `1512M`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a295cf08-89ba-4586-944f-62d366906ccb",
   "metadata": {},
   "source": [
    "### Ответы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7206131c-f347-4254-8381-002e1091eb7f",
   "metadata": {},
   "source": [
    "1. Запустить Spark Connect сервер со следующей конфигурацией:\n",
    "    - локальный режим на 4 потока,\n",
    "    - `1512MB` памяти,\n",
    "    - на порту [15020](https://spark.apache.org/docs/latest/configuration.html#spark-connect).\n",
    "\n",
    "<details>\n",
    "    <summary>Ответ</summary>\n",
    "\n",
    "1. Открыть файл `conf/spark-connect.conf` в проекте. Через текущий ноутбук будет сложно отредактировать этот файл.\n",
    "2. Добавить конфиги:\n",
    "\n",
    "```properties\n",
    "spark.driver.memory=1512m\n",
    "spark.connect.grpc.binding.port=15020\n",
    "```\n",
    "\n",
    "3. Открыть файл `bin/spark-connect-entrypoint` в проекте. Через текущий ноутбук будет сложно отредактировать этот файл.\n",
    "Заменить `yarn` на `local[4]`:\n",
    "\n",
    "```bash\n",
    "function start_spark_connect() {\n",
    "    $SPARK_HOME/sbin/start-connect-server.sh --packages org.apache.spark:spark-connect_2.12:3.5.0 --master local[4]\n",
    "    ...\n",
    "```\n",
    "\n",
    "4. Запустить сервис `connect`:\n",
    "\n",
    "```bash\n",
    "! source ~/.bash_aliases && \\\n",
    "docker compose start connect && \\\n",
    "```\n",
    "\n",
    "5. Команда `docker compose ps connect` ожидаемо покажет значение `unhealty`, т.к. docker ожидает, что **Spark Connect** запущен на порту `15002`\n",
    "\n",
    "```bash\n",
    "! source ~/.bash_aliases && \\\n",
    "docker compose start connect && \\\n",
    "docker compose ps connect\n",
    "```\n",
    "</details>\n",
    "\n",
    "2. Подключиться к Spark Connect серверу.\n",
    "\n",
    "<details>\n",
    "    <summary>Ответ</summary>\n",
    "\n",
    "Если команда ниже повиснет, то рекомендуется перезапустить ноутбук:\n",
    "- в главном меню выбрать пункт `Kernel`,\n",
    "- выбрать `Restart Kernel...`,\n",
    "- подтвердить перезапуск.\n",
    "\n",
    "```python\n",
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .remote(\"sc://connect:15020\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "```\n",
    "</details>\n",
    "\n",
    "3. Проверить настройки через Spark UI.\n",
    "\n",
    "<details>\n",
    "    <summary>Ответ</summary>\n",
    "\n",
    "1. Открыть http://localhost:4040/executors\n",
    "2. Всего доступно ядер (cores): 4\n",
    "3. Всего памяти доступно `727.2M`, но это всего лишь `60%` от всей памяти (M-регион), поэтому всего памяти выделено:\n",
    "\n",
    "$$\n",
    "\\frac{727.2MB} {0.6 (spark.memory.fraction)} + 300MB (зарезервировано) = 1512M\n",
    "$$\n",
    "\n",
    "Полученное значение соответствует запрошенному объему (значение `spark.driver.memory` в `conf/spark-connect.conf`).\n",
    "\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4ef485-a787-43b2-a2ab-836d6efee12b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
