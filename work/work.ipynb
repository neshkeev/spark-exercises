{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54eae27f-5220-454f-98cd-79309e38557a",
   "metadata": {},
   "source": [
    "# Мониторинг Spark приложений"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d267ed-b031-4926-8d51-dc8c18cdf50a",
   "metadata": {},
   "source": [
    "# Доступные сервисы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e7ba52-99a3-4e7a-8ec5-5049e2faa163",
   "metadata": {},
   "source": [
    "1. Демоны Hadoop:\n",
    "    - демон [NameNode](http://localhost:9870) запущен на `9870` порту,\n",
    "    - демон [DataNode](http://localhost:9864) запущен на `9864` порту,\n",
    "    - демон [ResourceManager](http://localhost:8088) запущен на `8088` порту порту,\n",
    "    - демон [NodeManager](http://localhost:8042) запущен на `8042` порту.\n",
    "2. Сервис [Prometheus](http://localhost:9090) запущен на `9090` порту,\n",
    "3. Сервис [Grafana](http://localhost:3000) запущен на `3000` порту,\n",
    "4. Сервис [Prometheus PushGateway](http://localhost:9091) запущен на `9091` порту."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3492d19-8cd1-4aea-9dd9-959b24fad371",
   "metadata": {},
   "source": [
    "# Мотивация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ab465f-4656-4ef0-958f-dcd72c4a5a94",
   "metadata": {},
   "source": [
    "Мониторинг приложения состоит из трех частей:\n",
    "\n",
    "- **логирование**: приложение на всем протяжении своей жизни пишет сообщения о происходящих действиях,\n",
    "- **трассировка**: важно иметь возможность отследить весь путь запроса назависимо является ли приложение частью большой системы или нет,\n",
    "- **сбор метрик**: приложение в процессе своей жизни использует какие-то ресурсы, поэтому очень важно следить за доступность ресурсов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4c43f6-6432-4ebb-87fe-69713fb1bdb6",
   "metadata": {},
   "source": [
    "Мониторинг является важным аспектом при разработке программного обеспечения, т.к. он позволяет получить ценные сведения о состоянии, производительности и поведения приложний и систем. Среди основных причин можно выделить:\n",
    "\n",
    "1. **поиск и решение проблем**: мониторинг позволяет отслеживать производительность приложения в реальном времени. Это позволяет отлавливать ошибки и ограничения производительности. Постоянный мониторинг системы ведет к быстрому обнаружению проблем и принятию необходимых действий по их предупреждению;\n",
    "2. **оптимизация производительности**: мониторинг позволяет анализировать использование ресурсов, время отклика и другие показатели. Это позволяет находить проблемные зоны приложения, которые необходимо оптимизировать для повышения эффективности. Через мониторинг можно как понять, как система ведет себя в различных сценариях, так и принять взвешенное решение об архитектуре системы для повышения производительности;\n",
    "3. **планирование ресурсов и масштабирование**: мониторинг предоставляет ценные данные относительно трендов использования ресурсов. Анализируя эти данные, можно предсказать потребности приложения в будущем, а также разработать стратегию масштабирования приложения и ресурсов. Такой подход позволяет быть уверенным, что приложение сможет эффективно справляться в будущем с более высокими нагрузками;\n",
    "4. **безопасность и надежность**: мониторинг позволяет отлавливать и предотвращать риски связанные с безопасностью. Мониторинг позволяет выделить аномальные паттерны поведения или сомнительные операции для проактивного принятия превентивных мер;\n",
    "5. **отладка**: подробное логирование позволяет записать события и действия, выполняемые в приложении. Логи позволяют воссоздать контекст проблемы ретроспективно, что дает программистам возможность сузить область поиска проблемы для эффективного ее решения.\n",
    "\n",
    "Мониторинг позвляет сформировать полное представление о работе приложения, что положительно сказывается на его поддержке, развитии и наждежности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f95f1b9-65f1-4e5e-9010-131b8ac06fc1",
   "metadata": {},
   "source": [
    "## Метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4895e669-f957-42cd-90bc-429892b9e83d",
   "metadata": {},
   "source": [
    "Apache Spark может предоставить метрики в нескольких форматах:\n",
    "\n",
    "- HTTP (Prometheus, Graphite),\n",
    "- JMX,\n",
    "- CSV.\n",
    "\n",
    "В современном мире для сбора метрик наиболее часто используется [Prometheus](https://prometheus.io/), а для визуализации используется [Grafana](https://grafana.com/), поэтому примеры будут приводиться на их основе."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb04b68-4e1a-4a99-9f68-06fdd20bddeb",
   "metadata": {},
   "source": [
    "Конфигурация метрик лежит в `$SPARK_HOME/conf/metrics.properties`. По умолчанию файл отсутствует или является пустым:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efdaed3-9597-45fe-9792-11b7c0482aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -l $SPARK_HOME/conf/metrics.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d99285-ee2c-4200-8d22-38995bf314b4",
   "metadata": {},
   "source": [
    "Включить поддержку метрик для экспорта в `Prometheus` можно например, таким образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adfb817-d9c9-4b55-bf98-54aa9830560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat /tmp/spark/metrics-prometheus-servlet.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5555354-5a1c-4008-8dee-ab1ffff86d64",
   "metadata": {},
   "source": [
    "## Логирование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e59837-209e-40d8-827a-485838dd5a00",
   "metadata": {},
   "source": [
    "В качестве библиотеки для логирования Apache Spark использует [log4j2](https://logging.apache.org/log4j/2.x/), а файл конфигурации доступен для редактирования, что позволяет настроить логирование в соответствии с любыми требованиями бизнеса. Файл конфигурации логера располагается по пути `$SPARK_HOME/conf/log4j2.properties`. По умолчанию файл отсутствует или пустой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcbb2ae-8276-41d1-83ae-69065af93d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -l $SPARK_HOME/conf/log4j2.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3769753-2525-4c5f-9b2a-7e76d5354d93",
   "metadata": {},
   "source": [
    "На примере ниже можно увидеть пример настройки консольного логера от уровня `WARN` и выше (~~`TRACE`~~, ~~`DEBUG`~~, ~~`INFO`~~, `WARN`, `ERROR`, `FATAL`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb1c0cc-dab2-425f-a732-90989df77677",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat /tmp/spark/log4j2-warn.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd84adf0-ded7-4bd5-a017-fd4655cd0177",
   "metadata": {},
   "source": [
    "Подробнее уровни логирования разбираются ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d5fabf-f816-4039-a58b-4ef62ddb11a5",
   "metadata": {},
   "source": [
    "### Mapped Diagnostic Context - MDC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3761400-c315-47f4-aba9-082b2660f874",
   "metadata": {},
   "source": [
    "Apache Spark позволяет добавить в логи информацию о метаданных задачи через `MDC` переменную(*) `taskName`. Так пользователь при описании формата вывода данных может использовать это значение как и все остальные `MDC` переменные: `%X{mdc.taskName}`\n",
    "\n",
    "(*) `MDC` переменные - это локальные переменные потока (Thread Local)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30c56e3-27c4-44ea-b97d-e4576f571eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "! grep --color taskName /tmp/spark/log4j2-warn.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a9f0cf-ce06-4e61-b202-e26a0232af78",
   "metadata": {},
   "source": [
    "Традиционно логи приложения отправлялись в [ElasticSearch](https://www.elastic.co) или [OpenSearch](https://opensearch.org/), но все больше приложений выбирают для логов [Loki](https://grafana.com/oss/loki/). Loki - это современный стек для работы с логами от компании, которая развивает Grafana, поэтому примеры работы с логами будут выполняться на основе Loki. При желании, можно использовать другие системы хранения логов: Flume, ElasticSearch, OpenSearch и другие, если сконфигурировать соответствующий логер в файле `$SPARK_HOME/conf/log4j2.properties`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e44bfc1-f48f-402e-9818-a957428a1b16",
   "metadata": {},
   "source": [
    "## Трассировка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416aee51-8d71-4eab-931b-5636c373fbcd",
   "metadata": {},
   "source": [
    "Apache Spark генерирует новый java код под каждый запрос, а значит большая часть кода является недоступной для анализа после завершения работы запроса, поэтому трассировка Apache Spark приложений не получила большого распространения. Apache Spark не предоставляет способов трассировки запросов, но можно воспользоваться [OpenTelemetry](https://opentelemetry.io/) для этих целей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012fbb8a-7269-411a-baa1-f277551a030d",
   "metadata": {},
   "source": [
    "## OpenTelemetry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20721dbf-40e8-4e0f-863a-1336f8a6cf79",
   "metadata": {},
   "source": [
    "Стандарт [OpenTelemetry](https://opentelemetry.io/) появился в 2021 году как результат слияния двух стандартов: [OpenTracing](https://opentracing.io/) и [OpenCensus](https://opencensus.io/).\n",
    "\n",
    "Философия OpenTelemetry заключается в унификации трех аспектов мониторинга: метрики, логи, трейсы под одним стандартом.\n",
    "\n",
    "Также важной частью OpenTelemetry является концепция **коллектора** (collector), который представляет собой прокси объект для обработки поступающей информации, преобразования ее и передачи ее дальше. Все исходящие из коллектора данные преобразуются к одному формату (**OTLP**, **OpenTelemetry Protocol**) и могут быть направлены для дальнейшей обработки нижележащим системам, способным обрабатывать данные в этом формате."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0ff501-95b1-494e-aad8-a28f1206db80",
   "metadata": {},
   "source": [
    "Для `JVM` приложений, коим является Apache Spark, имеется удобный `javaagent`, который инструментирует код, добавляя необходимую логику в рантайме. Так, приложение, в котором изначально не было возможностей для телеметрии, может получить их, если будет запущенно с OpenTelemetry Java агентом. OpenTelemetry Java агент знает о большом числе технологий (Log4j2, Kafka, Cassandra и т.д.) и знает как их инструментировать, т.е. добавлять новую логику для сбора логов, метрик и трейсов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b2fcc8-6a8d-4209-848a-e53cf97ad59a",
   "metadata": {},
   "source": [
    "### Конфигурация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515bea92-86c3-45be-bac1-36553ba76d06",
   "metadata": {},
   "source": [
    "Cтандартный способ [конфигурации OpenTelemetry Java Agent](https://github.com/open-telemetry/opentelemetry-java/blob/57d83344178f578eb5d2f043b0ffc5c42b6719a5/sdk-extensions/autoconfigure/README.md) заключается в установке значений в:\n",
    "- переменных окружения `OTEL_*`,\n",
    "- системных переменных `-Dotel.*`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b81bf0b-5648-4ec7-adf3-87776e7ea28e",
   "metadata": {},
   "source": [
    "OpenTelemetry Java агент не входит в стандартную поставку Apache Spark, поэтому необходимо скачать агента самостоятельно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eb7aac-3ecd-45bd-bdf2-f7ab40011b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl -L -o /tmp/opentelemetry-javaagent.jar \\\n",
    "    https://github.com/open-telemetry/opentelemetry-java-instrumentation/releases/latest/download/opentelemetry-javaagent.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef262f4-1ae1-4dea-9a58-ced6db7ae9ed",
   "metadata": {},
   "source": [
    "После загрузки необходимо указать агента при запуске Apache Spark. Дополнительную конфигурацию для старта `JVM` можно добавить:\n",
    "\n",
    "- через переменную окружения `PYSPARK_SUBMIT_ARGS`: `export PYSPARK_SUBMIT_ARGS='--driver-java-options \"-javaagent:/tmp/opentelemetry-javaagent.jar\" ...'`;\n",
    "- через параметр `spark.driver.defaultJavaOptions` при старте приложения Spark;\n",
    "- через параметр `spark.driver.extraJavaOptions` при старте приложения Spark.\n",
    "\n",
    "Разница между `spark.driver.defaultJavaOptions` и `spark.driver.extraJavaOptions` заключается в зоне ответственности:\n",
    "\n",
    "- параметр `spark.driver.defaultJavaOptions` устанавливается системным администратором в файле `$SPARK_HOME/conf/spark-defaults.conf`,\n",
    "- параметр `spark.driver.extraJavaOptions` устанавливается программистом во время старта приложения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a37d6b-4b05-422e-845a-aff77420483a",
   "metadata": {},
   "source": [
    "По умолчанию файл `$SPARK_HOME/conf/spark-defaults.conf` пуст или отсутствует:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f54f6a-b872-4ca1-8c39-d1342f9525e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -l $SPARK_HOME/conf/spark-defaults.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fe60e7-0375-4c25-96c7-a30619749841",
   "metadata": {},
   "source": [
    "Ниже приведен пример конфигурации `spark.driver.extraJavaOptions` через файл конфигурации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e939831-4367-484e-8059-9d227a53a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat /tmp/spark/spark-defaults.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b913ee-da12-4dbc-87d7-20674532e18d",
   "metadata": {},
   "source": [
    "В конфигурации можно заметить, что OpenTelemetry Java агент не будет экспортировать метрики (`-Dotel.metrics.exporter=none`), т.к. метрики будут экспортироваться стандартными средствами Apache Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df7f2cc-0ec6-4b4f-9bf3-d66dd519c5dd",
   "metadata": {},
   "source": [
    "Во время запуска конфигурация приложения строится на базе комбинации значений параметров `spark.driver.defaultJavaOptions` и `spark.driver.extraJavaOptions`, причем значения `spark.driver.extraJavaOptions` получают больший приоритет по сравнению с `spark.driver.defaultJavaOptions` при наличии одинаковых системных преременных. Наличие приоритета в применении настроек позволяет программисту переопределить значения, установленные системным администратором."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd11f358-5989-4570-b0d0-55f2ebc63ce0",
   "metadata": {},
   "source": [
    "В окружениях, где воркеры (executor) запускаются отдельным `JVM` процессом (`Yarn`, `k8s`), необоходимо настроить конфигурацию запуска `JVM` при помощи параметров:\n",
    "\n",
    "- `spark.executor.defaultJavaOptions`,\n",
    "- `spark.executor.extraJavaOptions`.\n",
    "\n",
    "Эти параметры аналогичны параметрам `spark.executor.defaultJavaOptions`, `spark.executor.extraJavaOptions`, и за установку каждого параметра отвечает отдельная команда."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5a86c5-6172-4bc1-beda-2386f0298413",
   "metadata": {},
   "source": [
    "Логи отправляются OpenTelemetry коллектору, который запущен в виде отдельного Docker сервиса `collector`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac52362a-d331-43c1-8280-f3bf2c1cb82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose ps collector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ef43a5-4e85-4707-92d7-ee9cad183357",
   "metadata": {},
   "source": [
    "Приложение Apache Spark знает о запущенном OpenTelemetry коллекторе через переменную окружения `OTEL_EXPORTER_OTLP_ENDPOINT`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48f37db-5de1-4800-92ce-51a23a96e92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.environ['OTEL_EXPORTER_OTLP_ENDPOINT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e0f817-5fff-4c49-a98b-079431435c6e",
   "metadata": {},
   "source": [
    "# Запуск Spark с OpenTelemetry Java Агентом"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce71b681-280c-4a14-b262-cd9c1c91592c",
   "metadata": {},
   "source": [
    "## Конфигурация приложения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c822754-60fd-4e45-82f0-8fbbeba4b0f9",
   "metadata": {},
   "source": [
    "Приложение Spark необходимо запустить с OpenTelemetry Java агентом. Конфигурация java агента является кандидатом на использование `spark.driver.defaultJavaOptions`, значение которой устанавливает системный администратор в файле `$SPARK_HOME/conf/spark-defaults.conf`. В данный момент этот файл недоступен для редактирования, поэтому необходимо воссоздать начальную конфигурацию приложения Spark в другом месте."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e44cf6-86ea-4d76-8fb9-9f856383dd3a",
   "metadata": {},
   "source": [
    "Скопируем все конфигурационные файлы на новое место:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c1a0be-83a6-4284-bd3d-9cd5fa10e126",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf /tmp/spark-conf && \\\n",
    "cp -v -R $SPARK_HOME/conf /tmp/spark-conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5bdc31-0e2e-4f8c-bb98-1fd790d959ad",
   "metadata": {},
   "source": [
    "Заменим содержимое `spark-defaults.conf` файла:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd5054c-80df-4aa9-b52e-c7c5f361b4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp /tmp/spark/spark-defaults.conf /tmp/spark-conf/spark-defaults.conf && \\\n",
    "cat /tmp/spark-conf/spark-defaults.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94844597-528c-4db5-a133-200a646fc1f8",
   "metadata": {},
   "source": [
    "Заменим содержимое `log4j2.properties` файла:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d683c59a-8e67-4071-834b-f4e5c619872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp /tmp/spark/log4j2-warn.properties /tmp/spark-conf/log4j2.properties && \\\n",
    "cat /tmp/spark-conf/log4j2.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b2152c-fcc6-4c01-968a-8da56a96977b",
   "metadata": {},
   "source": [
    "Заменим содержимое `metrics.properties` файла:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8845f01b-2cf8-4c3b-8bd9-b04dd50f9d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp /tmp/spark/metrics-prometheus-servlet.properties /tmp/spark-conf/metrics.properties && \\\n",
    "cat /tmp/spark-conf/metrics.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39f1786-bcfa-46a5-b8a0-7d248173eba7",
   "metadata": {},
   "source": [
    "Apache Spark должен знать, что актуальная конфигурация находится теперь располагается в `/tmp/spark-conf`, поэтому необходимо установить переменную окружения `SPARK_CONF_DIR`. Переменная окружения `SPARK_CONF_DIR` указывает Apache Spark на место хранения актуальной конфигурации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b4ca3d-62fc-44a6-a857-be7a6b3ffcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SPARK_CONF_DIR'] = '/tmp/spark-conf'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48e5ca8-f430-44eb-89fe-0e0bb521d7a6",
   "metadata": {},
   "source": [
    "Теперь все приложения, запускаемые на этой машине, будут использовать конфигурацию из директории, на которую указывает `SPARK_CONF_DIR` (`/tmp/spark-conf`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3519d54e-e57a-4364-9fe0-6681ee8329e6",
   "metadata": {},
   "source": [
    "## Запуск приложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad78f7c-69a4-44dd-a9df-0a127c8ce423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebf54f4-f583-4fc1-94f9-6de2511d9809",
   "metadata": {},
   "source": [
    "Особенность запуска Apache Spark приложения в текущем ноутбуке заключается в том, что метрики и логи должны иметь одинаковое значение имени приложения/сервиса для удобного анализа приложения через Grafana:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdbca4a-bfb8-4c85-849a-8caca69bb319",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_name = \"MonitoringLocal\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b42f088-8fe5-4971-a704-c5f7ebe41bd3",
   "metadata": {},
   "source": [
    "Метрики получают имя приложения через параметр `spark.app.name` (задается через [SparkSession.builder#appName](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.builder.appName.html)), а логи получают имя сервиса через системную переменную `-Dotel.service.name`, поэтому очень важно задать одинаковые значения для `spark.app.name` и `-Dotel.service.name`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa10bc25-af52-4bb6-adda-dc80d26666a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(service_name)\n",
    "        .master(\"local[4]\")\n",
    "        .config(\"spark.driver.extraJavaOptions\", f\"-Dotel.service.name={service_name}\")\n",
    "        .config(\"spark.executor.extraJavaOptions\", \"${spark.driver.extraJavaOptions}\")\n",
    "        .config(\"spark.ui.prometheus.enabled\", True)\n",
    "        .config(\"spark.executor.processTreeMetrics.enabled\", True)\n",
    "        .config(\"spark.metrics.namespace\", \"${spark.app.name}\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49742faa-05ca-4994-bdbb-567e04dafb66",
   "metadata": {},
   "source": [
    "Для демонстрации нагрузки запустим несколько задач на кластере:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e100c7-e6d9-4455-b619-2384fc6f1880",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    spark.sql(f\"select '{i}.Hello, Monitoring!' as message\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b223ca97-d755-4b96-9972-ac6e040fa47c",
   "metadata": {},
   "source": [
    "## Логирование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd4d938-8619-4a31-a107-0c6c000289c3",
   "metadata": {},
   "source": [
    "### Текущая конфигурация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4e6eb6-0f35-495c-821a-ab9766d71a53",
   "metadata": {},
   "source": [
    "Текущее Spark приложение сохраняет логи в Loki при помощи OpenTelemetry Java агента.\n",
    "\n",
    "Все логи сначала отправляются в Open Telemetry коллектор, который развернут в Docker сервисе `collector`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19a2c26-08ae-4b73-8350-3ffe7b54e15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose ps collector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39db52dd-0b75-416b-8528-184dd74fc369",
   "metadata": {},
   "source": [
    "А OpenTelemetry коллектор отправляет логи в Loki, который развернут в Docker сервисе loki:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59db68f-cec1-4dec-b183-465748c35c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose ps loki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1a4335-931c-4514-bac0-9948c44e5782",
   "metadata": {},
   "source": [
    "### Конфигурация коллектора"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21713cee-9eb3-46b4-9a7b-55b2b493c228",
   "metadata": {},
   "source": [
    "Коллектор выступает прокси сервером между приложением Spark и Loki. Конфигурация коллектора выглядит следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6553b711-1bb6-4304-8a37-8a8739365370",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && HOST=dind execute \\\n",
    "cat conf/otel/config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5f7a3e-a72b-4726-be34-3ea67c610792",
   "metadata": {},
   "source": [
    "Конфигурационный файл OpenTelemetry коллектора разделен на три секции:\n",
    "\n",
    "- `receivers` (источники) - какие форматы данных текущий коллектор готов принимать,\n",
    "- `exporters` (приемники) - в какие системы текущий коллектор готов отправлять данные,\n",
    "- `service` (логика) - описывает навигацию (ETL) данных между источниками и приемниками через pipeline. Число pipeline объектов в конфигурационном файле может быть больше одного.\n",
    "\n",
    "Подробно узнать про возможности коллектора и особенности его конфигурации можно в [документации](https://opentelemetry.io/docs/collector/configuration/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51878b80-6232-4f0c-99e7-1d8f07ffd1c8",
   "metadata": {},
   "source": [
    "### Создание логера"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab159c32-d4c5-4588-8da2-8a930455b9a3",
   "metadata": {},
   "source": [
    "Чтобы воспользоваться возможностями инструментированного логера, необходимо получить объект логера текущего Spark приложения из `JVM`. Функция `get_logger` позволяет получить ссылку на java-логер:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e83d746-8377-4a6e-a78c-230b65685b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logger(logger_name: str):\n",
    "    return spark._jvm.org.apache.log4j.LogManager.getLogger(logger_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1404e527-2f11-4975-9c9e-dc121bc93df1",
   "metadata": {},
   "source": [
    "Функция `get_logger` принимает _**произвольное**_ текстовое значение в качестве параметра, которое будет использоваться в как имя логгера:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847a674f-0801-4d6a-ae72-a0cbd124c497",
   "metadata": {},
   "source": [
    "### Использование Логеров"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f332a498-2190-4bf3-8271-089aecb51a66",
   "metadata": {},
   "source": [
    "Для создания логера необходимо вызывать функцию `get_logger`. Результирующий объект имеет методы для логирования на разном уровне:\n",
    "\n",
    "- `trace`,\n",
    "- `debug`,\n",
    "- `info`,\n",
    "- `warn`,\n",
    "- `error`,\n",
    "- `fatal`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95188a29-56a3-41b5-a444-6d1688938362",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_hello_world = get_logger(\"Hello World\")\n",
    "logger_hello_world.error(\"Log a ERROR level message\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006503ad-95f4-4be8-9422-a51b45a03445",
   "metadata": {},
   "source": [
    "Логи становятся доступны в трех местах:\n",
    "\n",
    "- стандартный поток вывода PySpark,\n",
    "- стандартный поток вывода OpenTelemetry Collector,\n",
    "- хранилище Loki."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d46db6-cda2-48e8-9a7d-6840dcb729c2",
   "metadata": {},
   "source": [
    "Cтандартный поток вывода PySpark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ae7121-a094-4104-85ed-af6940104590",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose logs pyspark --tail 100 | grep 'Log a ERROR level message'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ba71f6-aa81-4891-8289-ba44865bd9be",
   "metadata": {},
   "source": [
    "Стандартный поток вывода OpenTelemetry Collector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d01492e-ef5a-419c-a4d1-2435c7e075c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose logs collector --tail 100 | grep 'Log a ERROR level message'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658b9d4a-71dc-498f-83a4-3d415265f53b",
   "metadata": {},
   "source": [
    "Хранилище Loki:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61d8c41-702b-4b28-99de-10084e5509ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl -G -s \"http://loki:3100/loki/api/v1/query_range\" \\\n",
    "  --data-urlencode 'query={job=\"MonitoringLocal\", level=\"ERROR\"}' \\\n",
    "  --data-urlencode 'limit=1' | json_pp | grep body | sed 's,^\\s\\+\",,;s,\"$,,;s,\\\\\",\",g' | json_pp | grep '\"Log a ERROR level message\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ca6a8-4722-470b-81e1-e2dbbc0149a7",
   "metadata": {},
   "source": [
    "Можно залогировать сообщения с уровнем `WARN`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b802ae2-d90a-4cee-8574-ffe3d706f784",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_hello_world = get_logger(\"Hello World\")\n",
    "logger_hello_world.warn(\"Log a WARN level message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d7e80f-5df3-4062-a9d1-5c12a7177818",
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl -G -s \"http://loki:3100/loki/api/v1/query_range\" \\\n",
    "  --data-urlencode 'query={job=\"MonitoringLocal\", level=\"WARN\"}' \\\n",
    "  --data-urlencode 'limit=1' | json_pp | grep body | sed 's,^\\s\\+\",,;s,\"$,,;s,\\\\\",\",g' | json_pp | grep '\"Log a WARN level message\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffd4bea-3618-4199-a155-ca7aadc483ec",
   "metadata": {},
   "source": [
    "Можно залогировать сообщения с уровнем `INFO`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a78907e-5135-4cd6-8ae6-a369e894bd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_hello_world = get_logger(\"Hello World\")\n",
    "logger_hello_world.info(\"Log an INFO level message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14670b02-ddc8-48be-8ec6-16b9abbd11fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl -G -s \"http://loki:3100/loki/api/v1/query_range\" \\\n",
    "  --data-urlencode 'query={job=\"MonitoringLocal\", level=\"INFO\"}' \\\n",
    "  --data-urlencode 'limit=1' | json_pp | grep body | sed 's,^\\s\\+\",,;s,\"$,,;s,\\\\\",\",g' | json_pp |& grep '\"Log a INFO level message\"' 2> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588648ee-194b-4703-a82a-3c86bd0b0af5",
   "metadata": {},
   "source": [
    "### Уровни логирования"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a65806e-85b4-4630-93a6-ad72c9f51526",
   "metadata": {},
   "source": [
    "В реальном мире приложение может сообщать о разных событиях, каждое из которых может быть важным на разных этапах жизненного цикла приложения. Так, например, разработчикам нужна подробная информация о приложении во время разработки. Во время эксплуатации могут интересовать только ошибки и предупрежения. Библиотека `Log4j2` имеет шесть уровней логирования:\n",
    "\n",
    "1. `TRACE`,\n",
    "1. `DEBUG`,\n",
    "1. `INFO`,\n",
    "1. `WARN`,\n",
    "1. `ERROR`,\n",
    "1. `FATAL`.\n",
    "\n",
    "Уровни логирования имеют приоритет. Уровни логирования в списке выше перечислены от минимального приоритета к максимальному.\n",
    "\n",
    "Каждое сообщение в логе имеет свой уровень логирования. Во время запуска приложения можно указать требуемый уровень логирования. В логах появляются как сообщения, относящиеся указанному уровню логирования, так и все сообщения, относящиеся к уровням более высокого приоритета. Например, если при старте приложения указать уровень `INFO`, то в логах появятся сообщения, как относящиеся к `INFO`, так и к `WARN, ERROR, FATAL`.\n",
    "\n",
    "В дополнение к перечисленным выше уровням логирования `Log4j2` предлагает еще два уровня:\n",
    "\n",
    "- `ALL` показать все сообщения (аналогично `TRACE`),\n",
    "- `OFF` отключить логирование полностью."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c42d8da-a1a0-4d83-add9-6c114ca2a720",
   "metadata": {},
   "source": [
    "Как было отмечено выше, конфигурация логера выполняется через `$SPARK_HOME/conf/log4j2.properties` файл, **НО** текущее приложение запущено с конфигурацией в директории `$SPARK_CONF_DIR`, поэтому файл конфигурации логера находится в `$SPARK_CONF_DIR/log4j2.properties`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b96b7c-0f74-43d3-b6df-960f19719773",
   "metadata": {},
   "source": [
    "При отсутствии файлов `$SPARK_CONF_DIR/log4j2.properties` или `$SPARK_HOME/conf/log4j2.properties`:\n",
    "\n",
    "- значение уровня логера по умолчанию будет `WARN`;\n",
    "- файл `$SPARK_HOME/conf/log4j2.properties` можно создать самостоятельно. В качестве примера можно использовать `$SPARK_HOME/conf/log4j2.properties.template`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dca43a-abeb-4490-b4eb-6de7cd6971ed",
   "metadata": {},
   "source": [
    "Первая строчка в файле `$SPARK_HOME/conf/log4j2.properties` указывает уровень логирования. В данном случае указан уровень `WARN` (`rootLogger.level = WARN`). Поэтому логах появляются только сообщения, относящиеся к `WARN`, `ERROR`, `FATAL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef54c90e-3870-426e-83ff-adaa216b0c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat $SPARK_CONF_DIR/log4j2.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ee033a-eaec-47f6-a819-14891c75626a",
   "metadata": {},
   "source": [
    "Через конфиг `spark.log.level` Apache Spark позволяет переопределить уровень логирования, с которого сообщения необходимо выводить в лог. Если не указать никакой уровень, то значение по умолчанию - `WARN`.\n",
    "\n",
    "Таким образом, Spark выводит в лог сообщения, начиная с уровня `coalesce(spark.log.level, rootLogger.level, WARN)`, где `coalesce` - функция, которая возвращает первое непустое значение среди своих аргументов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d72970e-34b0-476c-94e7-edf33b4ed6a5",
   "metadata": {},
   "source": [
    "### Изменение уровня логирования"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215b2ce7-703d-47ab-accf-355105b16dab",
   "metadata": {},
   "source": [
    "Уровень логирования можно задать как при старте приложения, так и изменить уровень логирования запущенного приложения.\n",
    "\n",
    "У запущенного приложения простое изменения значения параметра `spark.log.level` не сработает:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2019ea-7d53-4734-b828-43518429ba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "try:\n",
    "    spark.conf.set(\"spark.log.level\", \"INFO\")\n",
    "except Exception as e:\n",
    "    print(e, file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f732fd5-2ae0-454c-89bc-4142d799354c",
   "metadata": {},
   "source": [
    "Изменение уровня логирования необходимо выполнить через [`SparkContext#setLogLevel`](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.SparkContext.setLogLevel.html). Функция `update_log_level` абстрагирует изменение уровня логирования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c666671-718a-4191-95bc-1a824bc6b8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_log_level(log_level: str):\n",
    "    spark.sparkContext.setLogLevel(log_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d62bb1-0856-40dd-9cca-6315bf35ac02",
   "metadata": {},
   "source": [
    "Функция `update_log_level` принимает уровень логирования в качестве параметра. Например, чтобы изменить уровень логирования на `INFO`, необходимо запустить:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fa0949-80c9-4405-a81d-0eec0909c0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_log_level(\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95c4645-1d8c-4c76-8d56-5a627233756c",
   "metadata": {},
   "source": [
    "После изменения уровня логирования, можно увидеть, что сообщения уровня `INFO` появляются в логах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69661fa1-21b2-4628-82e7-43595911e29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_hello_world = get_logger(\"Hello World\")\n",
    "logger_hello_world.info(\"Log an INFO level message. Once Again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599bd392-7232-4129-86d7-969c944d0d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl -G -s \"http://loki:3100/loki/api/v1/query_range\" \\\n",
    "  --data-urlencode 'query={job=\"MonitoringLocal\"}' \\\n",
    "  --data-urlencode 'limit=1' | json_pp | grep body | sed 's,^\\s\\+\",,;s,\"$,,;s,\\\\\",\",g' | json_pp | grep '\"Log an INFO level message. Once Again\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bddcbb9-29c0-4bd3-b5e5-9f1cacd1bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95e7ad8-4954-4ef8-8d1c-704d52e92e87",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55da6da-c3c1-46ed-a7c6-b8ce80ce3d33",
   "metadata": {},
   "source": [
    "Apache Spark использует библиотеку `log4j2`, что позволяет следовать принятым в индустрии практикам логирования сообщений. Разделение логируемых сообщений на уровни облегчает эксплуатацию приложений, т.к. можно эффективно ограничивать поток логируемых сообщений в зависимости от фазы жизненного цикла приложения. Гибкость `log4j2` позволяет реализовать требования к конфигурации любого рода, а использование OpenTelemetry Java агента позволяет без усилий подключить любые системы для сбора логов. В то же время необходимо учитывать, что логирование несколько снижает производительность приложения, поэтому очень важно выбирать наиболее подходящий к ситуации уровень логирования."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d6c9cb-0537-45dc-8d82-632e2b01f3d7",
   "metadata": {},
   "source": [
    "### Задания"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42867b69-5b2d-4595-87db-fae5c2054ee8",
   "metadata": {},
   "source": [
    "Для кода ниже ответье на вопросы\n",
    "```python\n",
    "logger = get_logger(\"Н. Н. Некрасов. Крестьянские дети\")\n",
    "\n",
    "logger.trace(\"Однажды, в студеную зимнюю пору,\")\n",
    "logger.debug(\"Я из лесу вышел; был сильный мороз.\")\n",
    "logger.info(\"Гляжу, поднимается медленно в гору\")\n",
    "logger.warn(\"Лошадка, везущая хворосту воз.\")\n",
    "logger.error(\"И, шествуя важно, в спокойствии чинном,\")\n",
    "logger.fatal(\"Лошадку ведет под уздцы мужичок.\")\n",
    "```\n",
    "\n",
    "1. Приложение запущено с настройками по умолчанию. Какие из сообщений ниже попадут в логи? Проверьте на практике.\n",
    "1. Настроить приложение так, чтобы были залогированы все сообщения.\n",
    "1. Настроить приложение так, чтобы ниодного сообщения не было залогировано.\n",
    "1. Настроить приложение так, чтобы было залогировано только одно (любое) сообщение.\n",
    "\n",
    "<details>\n",
    "    <summary>Нужна помощь?</summary>\n",
    "\n",
    "    Ответы внизу страницы\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ea3861-e4be-4679-b277-8f3eefcb766b",
   "metadata": {},
   "source": [
    "## Метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fd9cfc-8e99-48ae-b0f2-21ee6c13deeb",
   "metadata": {},
   "source": [
    "### Конфигурация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dcabff-5451-4139-915f-905820cccc99",
   "metadata": {},
   "source": [
    "Для активации экспорта метрик в Prometheus необходимо установить два параметра при старте приложения:\n",
    "\n",
    "- `spark.executor.processTreeMetrics.enabled` - нужно ли собирать метрики с виртуальной файловой системы `/proc`;\n",
    "- `spark.ui.prometheus.enabled` - делает доступными метрики воркеров на эндпоинте `/metrics/executors/prometheus`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ceb4fb-577a-426d-a718-9a33e8df98c2",
   "metadata": {},
   "source": [
    "Виртуальная файловая система `/proc` представляет информацию о текущем состоянии операционной системы, процессах, памяти и т.д. Например, можно получить информацию о процессорах, установленных на текущей машине:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cab01a-559b-4bc0-857a-25901fa0fcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! grep 'processor' -A 5 /proc/cpuinfo | head -n 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c921f64c-214b-43aa-baeb-1fd843347a99",
   "metadata": {},
   "source": [
    "Метрики приложения настраиваются при помощи файлов `$SPARK_CONF_DIR/metrics.properties` (если `SPARK_CONF_DIR` установлено) или `$SPARK_HOME/conf/metrics.properties`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22409bd-20ed-48a9-b2bb-5b66202cdbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat $SPARK_CONF_DIR/metrics.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6154bdcb-ca84-4dbd-a868-6f0ecc593e2b",
   "metadata": {},
   "source": [
    "На основании содержимого файла `$SPARK_CONF_DIR/metrics.properties` можно заключить, что метрики будут доступны в формате [Prometheus](https://prometheus.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c146bbc0-5c40-477c-b98f-6fd454f2f966",
   "metadata": {},
   "source": [
    "Если файл `$SPARK_CONF_DIR/metrics.properties` или `$SPARK_HOME/conf/metrics.properties` отсутствует, то можно создать `$SPARK_CONF_DIR/metrics.properties` (если `SPARK_CONF_DIR` установлена) или `$SPARK_HOME/conf/metrics.properties` самостоятельно. Для вдохновения можно обратить внимание на `$SPARK_HOME/conf/metrics.properties.template`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b95d7d4-4013-4503-886f-f97a4dc20d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "! tail $SPARK_HOME/conf/metrics.properties.template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12337d4f-e43a-423d-a570-9316fff05e93",
   "metadata": {},
   "source": [
    "Если выбрана конфигурация метрик для Prometheus, то вместе с приложением Spark стартует Prometheus сервлет рядом с **Spark Web UI** (порт [`4040`](http://localhost:4040/metrics/prometheus) по умолчанию). Prometheus должен забирать метрики с двух эндпоинтов:\n",
    "\n",
    "- [`/metrics/prometheus`](http://localhost:4040/metrics/prometheus) - метрики драйвера,\n",
    "- [`/metrics/executors/prometheus`](http://localhost:4040/metrics/executors/prometheus) - метрики воркеров."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8801757-c50d-441e-ab92-cee844c84d0c",
   "metadata": {},
   "source": [
    "### Запуск Yarn приложения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f75e94-aa66-4329-b879-75c14dfe2dab",
   "metadata": {},
   "source": [
    "Приложение Spark будет запущено в Yarn, поэтому необходимо обеспечить Docker сервис `hadoop`, на котором будут запущены Yarn контейнеры воркеров OpenTelemetry Java агентом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f20142-fc97-4cf7-b44b-c4af7907e5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && HOST=hadoop execute \\\n",
    "curl -L -o /tmp/opentelemetry-javaagent.jar \\\n",
    "    https://github.com/open-telemetry/opentelemetry-java-instrumentation/releases/latest/download/opentelemetry-javaagent.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d95e4a-e9f8-450c-81f1-712f8a56fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "service_name = \"MonitoringYarn\"\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(service_name)\n",
    "        .master(\"yarn\")\n",
    "        .config(\"spark.driver.extraJavaOptions\", f\"-Dotel.service.name={service_name}\")\n",
    "        .config(\"spark.executor.extraJavaOptions\", f\"${{spark.driver.extraJavaOptions}} -Dotel.exporter.otlp.endpoint={os.environ['OTEL_EXPORTER_OTLP_ENDPOINT']}\")\n",
    "        .config(\"spark.ui.prometheus.enabled\", True)\n",
    "        .config(\"spark.executor.processTreeMetrics.enabled\", True)\n",
    "        .config(\"spark.metrics.namespace\", \"${spark.app.name}\")\n",
    "        .config(\"spark.log.level\", \"ALL\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f9a351-fbf0-45b6-984c-47ccb4ed0aed",
   "metadata": {},
   "source": [
    "Запустим несколько задач для симуляции рабочей нагрузки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30274051-099a-45a3-9eac-568f9a84880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    spark.sql(f\"select '{i}.Hello, Yarn Monitoring!' as message\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7051856b-1e54-4806-a13c-a3e348f155b9",
   "metadata": {},
   "source": [
    "### Метрики драйвера"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc1a2d0-07ea-447d-a76f-95fdf3a713b7",
   "metadata": {},
   "source": [
    "При анализе метрик драйвера (управляющая программа) можно заметить интересную особенность:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776f27b9-6deb-4789-a071-974172050606",
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl -s -L http://localhost:4040/metrics/prometheus | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b44c29-8a59-47f6-ab3d-4cd21ebe979f",
   "metadata": {},
   "source": [
    "Кажая метрика начинается с префикса `metrics_MonitoringYarn`. Если обратить внимание на конфигурацию запуска приложения, то можно увидеть, что `MonitoringYarn` - это значение `spark.app.name`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a73da5f-919e-4767-a261-a9aeedb8db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spark.conf.get(\"spark.app.name\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbe0e91-11cd-41f6-bc5f-163db170f432",
   "metadata": {},
   "source": [
    "А также значение переменной `service_name`, которое было передано в [SparkSession.builder#appName](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.builder.appName.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95969683-fa11-4dd3-a6f3-f3c127145c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dbe143-cdd0-4139-9e7b-739c9d43b6a1",
   "metadata": {},
   "source": [
    "Но свой префикс метрики получают не от имени приложения, а через еще один параметр `spark.metrics.namespace`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1086fb-f088-4830-a54b-2e3cb0f0a618",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spark.conf.get(\"spark.metrics.namespace\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23a7b2a-9951-470e-af60-a20bebd06ad6",
   "metadata": {},
   "source": [
    "Apache Spark допускает ссылки на значения других параметров, поэтому `spark.metrics.namespace` становится равным `MonitoringYarn` (значение `spark.app.name`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555df713-4b39-4340-a784-e648832be713",
   "metadata": {},
   "source": [
    "Таким образом, **Apache Spark** выставляет метрики, названия которых зависят от значения параметра `spark.metrics.namespace`.\n",
    "\n",
    "> **Имена метрик зависят от `spark.metrics.namespace`!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4a963b-11df-4c1c-9268-f46ee54215bc",
   "metadata": {},
   "source": [
    "Но почему нельзя было использовать значение `spark.metrics.namespace` в виде метки (**label**) метрики?\n",
    "\n",
    "<details>\n",
    "    <summary>Гипотезы</summary>\n",
    "\n",
    "1. Более точная настройка метрик;\n",
    "1. В качестве меток (**label**) желательно использовать низкокардинальные признаки (число уникальных значений мало), а всевозможных значений `spark.metrics.namespace` может быть бесконечно.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24cd10c-9119-49d8-a117-25b78b926f90",
   "metadata": {},
   "source": [
    "Значения по умолчанию для `spark.metrics.namespace` нет, поэтому если запустить приложение без указания значения для `spark.metrics.namespace`, то Apache Spark будет использовать идентификатор приложения для генерации префикса. Таким образом префикс будет выглядит следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53f192e-efda-4609-b3ca-c9714d31c1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'metrics_{spark.conf.get(\"spark.app.id\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2fd5ee-fa82-45ee-a4ba-58c474020375",
   "metadata": {},
   "source": [
    "Идентификатор приложения меняется от запуска к запуску, поэтому при перезапуке приложения нельзя будет объединить значения старых метрик в Prometheus с новыми.\n",
    "\n",
    "> **Необходимо всегда определять значение `spark.metrics.namespace`!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53709b8-3404-4bc7-9677-cc09478568cf",
   "metadata": {},
   "source": [
    "### Метрики воркеров"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326358a6-7152-4b05-95d4-68858d852014",
   "metadata": {},
   "source": [
    "Метрики воркеров также доступны с хоста драйвера, что делает удобным сбор метрик:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a8f474-b2a9-4088-a871-2842f8996bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl -s -L http://localhost:4040/metrics/executors/prometheus | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5af94b-6db3-43d3-aa30-384461883dc0",
   "metadata": {},
   "source": [
    "В отличии от метрик драйвера, метрики воркеров связаны с приложением через метки (**label**):\n",
    "\n",
    "- `application_id`,\n",
    "- `application_name`.\n",
    "\n",
    "Такой подход позволяет использовать универсальные [`PromQL`](https://prometheus.io/docs/prometheus/latest/querying/basics/) (язык запросов Prometheus) запросы для получения результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03df8355-d827-437e-9d32-ce11c781d857",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5195d1db-74d0-4715-b54a-667d0551d45f",
   "metadata": {},
   "source": [
    "### Системы сбора и визуализации метрик"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac4982d-e78e-4f0d-b111-129eab19b510",
   "metadata": {},
   "source": [
    "Prometheus (сбор метрик) и Grafana (визуализация метрик) запущены в виде Docker сервисов и доступны через веб интерфейс:\n",
    "\n",
    "- сервис [Prometheus](http://localhost:9090) запущен на порту `9090`. Логин и пароль не требуются;\n",
    "- сервис [Grafana](http://localhost:3000) запущен на порту `3000`. Логин: `admin` , пароль: `admin`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4164bce-5931-4fed-83eb-21f0839ad931",
   "metadata": {},
   "source": [
    "### Генерация нагрузки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad6484f-8767-4eb0-b0d6-cebe51da756f",
   "metadata": {},
   "source": [
    "Для нагурзки будет использоваться алгоритм [PageRank](https://en.wikipedia.org/wiki/PageRank) на синтетическом графе."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3f15be-bdfe-45d1-a80b-8ec17be7eb78",
   "metadata": {},
   "source": [
    "#### Генерация синтетического графа"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bc4745-0588-4452-aec5-b6d72859956d",
   "metadata": {},
   "source": [
    "Генерация синтетического графа заключается в генерации рёбер графа:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a0ee49-a8cf-440c-b0b0-709300705d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! for i in {1..500}; do \\\n",
    "    for j in {1..100}; do \\\n",
    "        echo \"$i $j\"; \\\n",
    "    done ; \\\n",
    "done > /tmp/edges.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0aec14-0d5c-49f4-b6f5-d78149e112f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "! head /tmp/edges.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888e9c4e-1588-40d9-875f-6a0fc4d635d1",
   "metadata": {},
   "source": [
    "Полученный файл необходимо отрпавить в Docker сервис `hadoop`, с которого можно будет загрузить файл в **HDFS**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4d2607-a94a-4a46-a26e-b362bee6ffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose cp pyspark:/tmp/edges.log /tmp/edges.log && \\\n",
    "docker compose cp /tmp/edges.log hadoop:/tmp/edges.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b5d6dc-3249-43a6-941e-4a6cb5d5ebdc",
   "metadata": {},
   "source": [
    "Отправка файла в **HDFS**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b796b44a-7ade-41c8-b8ac-c01eccf49be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "hdfs dfs -mkdir -p /user/jovyan && \\\n",
    "hdfs dfs -put -f /tmp/edges.log /user/jovyan/edges.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c491a67-5b89-4d01-884a-a0a07c683e1b",
   "metadata": {},
   "source": [
    "Проверка наличия файла в **HDFS**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de39f34-7d78-43ef-b0e3-eb051720a1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "hdfs dfs -ls /user/jovyan/edges.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75ca5a9-dfde-483c-85f8-4f3725b8e574",
   "metadata": {},
   "source": [
    "#### Конфигурация нагрузки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0627f7-0d9c-4cb7-8af7-37ab92922714",
   "metadata": {},
   "source": [
    "Нагрузка будет выполняться для приложения запущенного в _клиентском_ режиме на Yarn. Следовательно, воркеры будут запущены в виде Yarn контейнеров, логи которых также представляют ценность. Значит необходимо запустить воркеры с OpenTelemetry Java агентом для отправки логов в OpenTelemetry коллектор."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12594864-64b7-44b7-879e-8747869688d6",
   "metadata": {},
   "source": [
    "Конфигурация процессов JVM для контейнеров осуществляется при помощи параметров:\n",
    "\n",
    "- `spark.executor.defaultJavaOptions` - параметры, устанавливаемые системным администратором в `$SPARK_CONF_DIR/spark-defaults.conf` или `$SPARK_HOME/conf/spark-defaults.conf`,\n",
    "- `spark.executor.extraJavaOptions` - параметры, устанавливаемые программистом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3809c2-599a-4de6-998e-9d1711b63410",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat $SPARK_CONF_DIR/spark-defaults.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877460de-13a1-4646-811f-d53d11d99fa0",
   "metadata": {},
   "source": [
    "Параметр `spark.log.level` не оказывает влияния на воркеры, которые запущены в виде отдельных JVM процессов, воркеры используют конфигурацию из файла `log4j2.properties`. Для воркеров будет установлен уровень `INFO`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bee5541-bc54-4604-b838-1a7f9adba3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "! sed -i '/WARN/s,WARN,INFO,' $SPARK_CONF_DIR/log4j2.properties && \\\n",
    "cat $SPARK_CONF_DIR/log4j2.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1706db-d3ad-4bc9-8a60-92c36802c7fd",
   "metadata": {},
   "source": [
    "#### Запуск нагрузки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c171cc43-764a-49c9-9ea3-95345a15a3fa",
   "metadata": {},
   "source": [
    "_(Во время тестирования приложение ниже запускалось только после перезапуска hadoop, поэтому перезапускаю его превентивно)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd09799e-45c2-4e2f-a90c-56f6db12d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose restart hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c08a31-235f-4b62-b566-52d2df223570",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose ps hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2734eb30-8e7f-4e7b-8226-98d6f6c68eb0",
   "metadata": {},
   "source": [
    "Приложение будет запущено в Yarn на двух воркерах в _клиентском_ режиме (`--deploy-mode client`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f604a92d-f8ab-46ed-b454-9f13b2128fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "! SPARK_CONF_DIR='/tmp/spark-conf' \\\n",
    "/usr/local/spark/bin/spark-submit --class org.apache.spark.examples.SparkPageRank \\\n",
    "    --master yarn \\\n",
    "    --deploy-mode client \\\n",
    "    --num-executors 2 \\\n",
    "    --conf spark.driver.extraJavaOptions=\"-Dotel.service.name=SparkPageRank\" \\\n",
    "    --conf spark.executor.extraJavaOptions=\"\\${spark.driver.extraJavaOptions} -Dotel.exporter.otlp.endpoint=${OTEL_EXPORTER_OTLP_ENDPOINT}\" \\\n",
    "    --conf spark.log.level=INFO \\\n",
    "    --conf spark.ui.prometheus.enabled=true \\\n",
    "    --conf spark.executor.processTreeMetrics.enabled=true \\\n",
    "    --conf spark.metrics.namespace='${spark.app.name}' \\\n",
    "    /usr/local/spark/examples/jars/spark-examples*.jar \\\n",
    "    /user/jovyan/edges.log 50 > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8c3954-20c2-4481-868c-c7866e35d469",
   "metadata": {},
   "source": [
    "Для анализа результатов необходимо открыть Grafana дашборд под названием [`Spark Applicaitons`](http://localhost:3000). Имя пользователя: `admin` и пароль: `admin`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7318727-0cf7-4cc6-be65-bef294ea1f47",
   "metadata": {},
   "source": [
    "### Пакетная нагрузка - Batch Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c279b3e-6405-4642-8d59-f3a392a80bc5",
   "metadata": {},
   "source": [
    "Пример выше был умышленно запущен в клиентском режиме. Клиентский режим имеет следующие особенности:\n",
    "\n",
    "- драйвер (управляющая программа) запущен на машине внешней по отношению к Yarn кластеру,\n",
    "- драйвер отделен от Application Master,\n",
    "- Application Master запущен в Yarn контейнере,\n",
    "- Application Master управляет контейнерами воркеров (executors)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f86d01-a047-4042-a58e-69d3aad53012",
   "metadata": {},
   "source": [
    "Запуск Spark в клиентском режиме типичен для целей аналитики, при этом стоит принять во внимание:\n",
    "\n",
    "- драйвер живет неограниченно долго,\n",
    "- IP адрес и доменное имя машины, на которой запущен драйвер, заранее известно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32253db4-b7db-41d1-80b6-cf832ad29478",
   "metadata": {},
   "source": [
    "Учитывая, что Prometheus использует pull-модель получения метрик, т.е. Prometheus сам обращается к машинам для получения метрик, запуск Apache Spark в клиентском режиме отлично подходит для Prometheus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e62130-77b9-4cf6-b5e2-f2a0a31d5972",
   "metadata": {},
   "source": [
    "Другим режимом работы Apache Spark является кластерный режим:\n",
    "\n",
    "- драйвер запускается в Yarn контейнере,\n",
    "- драйвер и Application Master объединены вместе,\n",
    "- Application Master управляет контейнерами воркеров (executors)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fad5565-c76d-4103-92b5-7491e4411104",
   "metadata": {},
   "source": [
    "Следующее приложение будет запущено в Yarn на двух воркерах в _кластерном_ режиме (`--deploy-mode cluster`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4916e85-dcd6-444d-bf1e-13506915f1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! SPARK_CONF_DIR='/tmp/spark-conf' \\\n",
    "/usr/local/spark/bin/spark-submit --class org.apache.spark.examples.SparkPageRank \\\n",
    "    --master yarn \\\n",
    "    --deploy-mode cluster \\\n",
    "    --num-executors 2 \\\n",
    "    --conf spark.driver.extraJavaOptions=\"-Dotel.service.name=SparkPageRank\" \\\n",
    "    --conf spark.executor.extraJavaOptions=\"\\${spark.driver.extraJavaOptions} -Dotel.exporter.otlp.endpoint=${OTEL_EXPORTER_OTLP_ENDPOINT}\" \\\n",
    "    --conf spark.log.level=INFO \\\n",
    "    --conf spark.ui.prometheus.enabled=true \\\n",
    "    --conf spark.executor.processTreeMetrics.enabled=true \\\n",
    "    --conf spark.metrics.namespace='${spark.app.name}' \\\n",
    "    /usr/local/spark/examples/jars/spark-examples*.jar \\\n",
    "    /user/jovyan/edges.log 50 > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81f481c-a43e-452f-8d25-1db6fedf1487",
   "metadata": {},
   "source": [
    "Драйвер запущен в виде Yarn контейнера, поэтому метрики теперь доступны по адресу: `http://localhost:8088/proxy/<YARN_APP_ID>/metrics/prometheus`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86621b29-da34-42e3-85c6-eae0f00d00ee",
   "metadata": {},
   "source": [
    "Кластерный режим работы практикуется при пакетной обработке (batch processing):\n",
    "\n",
    "- появились новые данные,\n",
    "- Apache AirFlow, Apache Oozie или любой другой планировщик запустил Spark приложение,\n",
    "- Spark приложение обработало новые данные,\n",
    "- Spark приложение отключилось."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76e3473-b698-4bce-a477-e90a87035d44",
   "metadata": {},
   "source": [
    "Небольшой вариацией вышеописанного сценария является стримовая обработка (streaming), в котором:\n",
    "\n",
    "- драйвер запущен постоянно,\n",
    "- размещение Yarn контейнера для драйвера определяется во время запуска,\n",
    "- расположение Yarn контейнера для драйвера неизвестно заранее."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a764a568-f963-4f6f-b6c4-393fd557f3e7",
   "metadata": {},
   "source": [
    "Особенностью кластерного режима можно считать:\n",
    "\n",
    "- неопределенное время жизни драйвера,\n",
    "- ни IP адрес, ни доменное имя машины драйвера неизвестно, т.к. yarn выделяет контейнеры для работы по ресурсам."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16102d6-a6a1-49b9-9803-b97c4113973c",
   "metadata": {},
   "source": [
    "Следовательно, для Spark приложений, запущенных в кластерном режиме, невозможно сконфигурировать Prometheus корректно, т.к. нет конкретного домена, который выставляет метрики.\n",
    "\n",
    "> **Кластерный режим Apache Spark не подходит для Prometheus!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750d6493-fe2d-498b-9050-7407317af377",
   "metadata": {},
   "source": [
    "### Prometheus PushGateway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd0bd5b-d251-40e4-bb33-95d6595c326e",
   "metadata": {},
   "source": [
    "Логичным решением сбора метрик для Spark приложений в кластерном режиме должен быть push метод:\n",
    "\n",
    "- приложения стартуют в любой момент,\n",
    "- приложения разворачиваются в любом месте,\n",
    "- приложения самостоятельно в комфортном для себя режиме отправляют собранные метрики на некоторый центральный сервер."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d6547d-bd99-4b55-a047-f02df5593c24",
   "metadata": {},
   "source": [
    "Команда Prometheus прекрасно осведомлена о проблемах со сбором метрик с приложений, которые не имеют ни фиксированного времени жизни, ни доменного имени. Чтобы не терять долю рынка, которая занята пакетной обработкой, был разработан [Prometheus PushGateway](https://prometheus.io/docs/practices/pushing/):\n",
    "\n",
    "- Prometheus PushGateway представляет собой веб-сервер,\n",
    "- команда приложения (Spark) разворачивает Prometheus PushGateway сервер в своем окружении,\n",
    "- у Prometheus PushGateway сервера появляется фиксированное доменное имя,\n",
    "- приложение (Spark) отправлет метрики на домен сервера Prometheus PushGateway,\n",
    "- Prometheus PushGateway выставляет полученные метрики в виде эндпонта,\n",
    "- Prometheus забирает метрики, выставленные Prometheus PushGateway сервером.\n",
    "\n",
    "Таким образом, Prometheus PushGateway выступает прокси-сервером между приложением (Spark) без фиксированного домена и Prometheus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cab8e6-c2de-4a92-bfd3-051f8aa2c2a7",
   "metadata": {},
   "source": [
    "Для решения проблемы сбора метрик с приложений Spark, запущенных в кластерном режиме, в текущем окружении поднят Prometheus PushGateway сервис в Docker сервисе `pushgateway`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a63789-026e-4d68-b7db-b1114e8b3801",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "docker compose ps pushgateway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ba1dc4-85c1-4c82-bc5e-00832ef49b82",
   "metadata": {},
   "source": [
    "Полученные метрики `pushgateway` доступны по адресу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953b03d5-cf1a-4b9b-95d8-a06b688ca9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl -s -k http://pushgateway:9091/metrics | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7ada61-eba1-443b-b80b-d0a89e8b2172",
   "metadata": {},
   "source": [
    "### Конфигурация Spark для Prometheus PushGateway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ed4b51-660f-4b90-97c3-fde58ee28688",
   "metadata": {},
   "source": [
    "Apache Spark не поддерживает Prometheus PushGateway по умолчанию, но компания BanzaiCloud любезно [открыла](https://github.com/banzaicloud/spark-metrics) доступ к своему модулю Apache Spark для Prometheus PushGateway."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b2b35d-c0dd-42b2-8ed6-a411ef948604",
   "metadata": {},
   "source": [
    "Для использования Prometheus PushGateway необхдимо выполнить дополнительную конфигурацию Spark:\n",
    "\n",
    "1. положить jar файл на `CLASSPATH` драйвера (управляющая программа) и воркеров (executors),\n",
    "2. добавить конфигурацию в `metrics.properties`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f82454-6dcf-4a6f-975e-740fcd89b06e",
   "metadata": {},
   "source": [
    "При старте текущего Docker compose сервисов необходимый `jar` файл попадает в директорию `$SPARK_HOME/jars`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99e2a04-aea6-4ad0-8645-a31c87e707a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -l $SPARK_HOME/jars/spark-metrics-assembly-3.2-1.0.0.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b742aa9-bc15-449f-9cc6-c4b0b21a501b",
   "metadata": {},
   "source": [
    "Файлы `*.jar` из `$SPARK_HOME/jars` формируют `CLASSPATH` приложения. Все jar файлы из `$SPARK_HOME/jars` автоматически копируются на все контейнеры воркеров и драйвера (если приложение запущено в кластерном режиме)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a4a98c-673c-45a2-b64e-9aac4734bf8d",
   "metadata": {},
   "source": [
    "Конфигурация для Prometheus PushGateway выполняется согласно [документации](https://github.com/banzaicloud/spark-metrics/blob/1f2147fac5103a34e68bbc74a9021a00d3b5ad37/PrometheusSink.md) в файле `$SPARK_CONF_DIF/metrics.properties` или `$SPARK_HOME/conf/metrics.properties`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714599a2-68af-4b99-9f75-3e54cb6bc8e0",
   "metadata": {},
   "source": [
    "Минимальная конфигураци включает в себя следующие пункты:\n",
    "\n",
    "- активация PrometheusSink,\n",
    "- указание домена Prometheus PushGateway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b90d33b-4884-42d3-9057-d20e2cdf6d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp /tmp/spark/metrics-prometheus-pushgateway.properties /tmp/spark-conf/metrics.properties && \\\n",
    "cat /tmp/spark-conf/metrics.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd1a4d8-a2ae-4d8e-8695-4604a01dc810",
   "metadata": {},
   "source": [
    "Теперь можно запускать Apache Spark приложения в кластерном режиме, и все метрики будут отправляться в Prometheus PushGateway."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ef1d59-6369-4899-b672-55e4b67c93e2",
   "metadata": {},
   "source": [
    "### Запуск Spark с Prometheus PushGateway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b96b59-192d-4d7e-a0af-547dcd7f9423",
   "metadata": {},
   "source": [
    "Все ноутбуки запускаются исключительно в клиентском режиме, поэтому для запуска приложения в кластерном режиме необходимо использовать `spark-submit`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17d113a-65dc-49f2-a0f0-21ba17726237",
   "metadata": {},
   "source": [
    "Для демонстрации будет запущен тот же самый PageRank пример в кластерном режиме (`--deploy-mode cluster`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b653e124-c790-495f-ae40-693c22fa3404",
   "metadata": {},
   "outputs": [],
   "source": [
    "! SPARK_CONF_DIR='/tmp/spark-conf' \\\n",
    "$SPARK_HOME/bin/spark-submit --class org.apache.spark.examples.SparkPageRank \\\n",
    "    --master yarn \\\n",
    "    --deploy-mode cluster \\\n",
    "    --num-executors 2 \\\n",
    "    --conf spark.driver.extraJavaOptions=\"-Dotel.service.name=SparkPageRank\" \\\n",
    "    --conf spark.executor.extraJavaOptions=\"\\${spark.driver.extraJavaOptions} -Dotel.exporter.otlp.endpoint=${OTEL_EXPORTER_OTLP_ENDPOINT}\" \\\n",
    "    --conf spark.log.level=INFO \\\n",
    "    --conf spark.ui.prometheus.enabled=true \\\n",
    "    --conf spark.executor.processTreeMetrics.enabled=true \\\n",
    "    --conf spark.metrics.namespace='${spark.app.name}' \\\n",
    "    $SPARK_HOME/examples/jars/spark-examples*.jar \\\n",
    "    /user/jovyan/edges.log 5 > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efe7b7a-ec27-42c6-a11e-fff8be768284",
   "metadata": {},
   "source": [
    "Для проверки доступности метрик как с драйвера, так и с воркеров, можно открыть PushGateway на порту [9091](http://localhost:9091) и убедиться в наличии метрик."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf0f9a5-8387-43a0-ba7e-c2b8f235939b",
   "metadata": {},
   "source": [
    "## Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e79a42-2019-4630-9a27-eb1e1b1bdff7",
   "metadata": {},
   "source": [
    "Все приложения нуждаются в оперативном реагировании на инциденты, а мониторинг позволяет их предупредить. Несмотря на достаточно слабые встроенные возможности мониторинга Spark приложений, современные технологии в лице OpenTelemetry протягивают руку помощи, что позволяет настроить информативный мониторинг. В свою очередь OpenTelemetry добавляет накладные расходы, что может снизить производительность Spark приложений, но за эту цену можно получить надежность приложения. В свою очередь программист также может повлиять на производительность приложений Spark, если хорошо понимает, какие возможности Apache Spark предлагает для настройки логирования и мониторинга."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937c3647-267b-4beb-8992-9961a433ce5a",
   "metadata": {},
   "source": [
    "## Задания"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b40c129-8551-43c9-bb39-b46e0b236894",
   "metadata": {},
   "source": [
    "1. Запустить `org.apache.spark.examples.SparkPi` из `$SPARK_HOME/examples/jars/spark-examples*.jar` при помощи `spark-submit`:\n",
    "    - в кластерном режиме,\n",
    "    - c уровнем логирования `OFF`,\n",
    "    - мониторингом на базе `Prometheus PushGateway`,\n",
    "    - проверить метрики.\n",
    "1. Запустить `org.apache.spark.examples.SparkPi` из `$SPARK_HOME/examples/jars/spark-examples*.jar` при помощи `spark-submit`:\n",
    "    - в клиентском режиме,\n",
    "    - c уровнём логирования `DEBUG`,\n",
    "    - c мониторингом на базе `PrometheusServlet`,\n",
    "    - проверить метрики.\n",
    "1. Запустить Spark приложение:\n",
    "    - через ноутбук, \n",
    "    - в локальном режиме,\n",
    "    - с уровнем логирования `ERROR`,\n",
    "    - c мониторингом на базе `Prometheus PushGateway`\n",
    "\n",
    "<details>\n",
    "    <summary>Нужна помощь?</summary>\n",
    "\n",
    "    Ответы внизу страницы.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf769af6-9b54-46b4-bd7c-a92bbaa2e2a1",
   "metadata": {},
   "source": [
    "## Метрики Apache Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1995a796-c980-42e0-a100-300d2cf2f928",
   "metadata": {},
   "source": [
    "Apache Hadoop выставляет свои метрики по эндпоинту `/prom`:\n",
    "\n",
    "- метрики [NameNode](http://localhost:9870/prom),\n",
    "- метрики [DataNode](http://localhost:9864/prom),\n",
    "- метрики [ResourceManager](http://localhost:8088/prom),\n",
    "- метрики [NodeManager](http://localhost:8042/prom)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f73482c-46df-4733-92ae-0703ca8ae744",
   "metadata": {},
   "source": [
    "Apache Hadoop выставляет свои метрики, только если параметр `hadoop.prometheus.endpoint.enabled` в `core-site.xml` установлен в `true`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ec341f-948d-4672-9f3a-6f446d59a219",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && HOST=dind execute \\\n",
    "cat conf/hadoop/core-site.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21310cf-314a-4691-9d08-0dab792fcb4c",
   "metadata": {},
   "source": [
    "# Ответы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafdbd70-d549-4d9f-aafc-6c1aa5fe95b1",
   "metadata": {},
   "source": [
    "## Ответы на задание про логирование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951e9daf-d2c2-4665-a9b4-a89581438005",
   "metadata": {},
   "source": [
    "Для кода ниже ответье на вопросы\n",
    "```python\n",
    "logger = get_logger(\"Н. Н. Некрасов. Крестьянские дети\")\n",
    "\n",
    "logger.trace(\"Однажды, в студеную зимнюю пору,\")\n",
    "logger.debug(\"Я из лесу вышел; был сильный мороз.\")\n",
    "logger.info(\"Гляжу, поднимается медленно в гору\")\n",
    "logger.warn(\"Лошадка, везущая хворосту воз.\")\n",
    "logger.error(\"И, шествуя важно, в спокойствии чинном,\")\n",
    "logger.fatal(\"Лошадку ведет под уздцы мужичок.\")\n",
    "```\n",
    "\n",
    "1. Приложение запущено с настройками по умолчанию. Какие из сообщений ниже попадут в логи? Проверьте на практике.\n",
    "\n",
    "<details>\n",
    "    <summary>Ответ</summary>\n",
    "\n",
    "1. По умолчанию:\n",
    "    - настройка `spark.log.level` отсутствует,\n",
    "    - файл `$SPARK_HOME/conf/log4j2.properties` отсутствует\n",
    "1. Итоговый уровень логгирования: `coalesce(spark.log.level (null), rootLogger.level (null), WARN) = WARN`;\n",
    "1. В результате будут залогированы сообщения уровней: `WARN`, `ERROR`, `FATAL`.\n",
    "\n",
    "**ОТВЕТ**: в лог попадут сообщения:\n",
    "```python\n",
    "logger.warn(\"Лошадка, везущая хворосту воз.\")\n",
    "logger.error(\"И, шествуя важно, в спокойствии чинном,\")\n",
    "logger.fatal(\"Лошадку ведет под уздцы мужичок.\")\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "2. Настроить приложение так, чтобы были залогированы все сообщения.\n",
    "\n",
    "<details>\n",
    "    <summary>Ответ</summary>\n",
    "\n",
    "1. Остановить текущее приложение: `spark.stop()`\n",
    "2. Запустить приложение с `spark.log.level=ALL`:\n",
    "```python\n",
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(service_name)\n",
    "        .master(\"local[4]\")\n",
    "        .config(\"spark.driver.extraJavaOptions\", f\"-Dotel.service.name={service_name}\")\n",
    "        .config(\"spark.log.level\", \"ALL\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "```\n",
    "3. залогировать сообщения для проверки\n",
    "```python\n",
    "logger = get_logger(\"Н. Н. Некрасов. Крестьянские дети\")\n",
    "\n",
    "logger.trace(\"Однажды, в студеную зимнюю пору,\")\n",
    "logger.debug(\"Я из лесу вышел; был сильный мороз.\")\n",
    "logger.info(\"Гляжу, поднимается медленно в гору\")\n",
    "logger.warn(\"Лошадка, везущая хворосту воз.\")\n",
    "logger.error(\"И, шествуя важно, в спокойствии чинном,\")\n",
    "logger.fatal(\"Лошадку ведет под уздцы мужичок.\")\n",
    "```\n",
    "\n",
    "4. Остановить приложение: `spark.stop()`\n",
    "\n",
    "</details>\n",
    "\n",
    "3. Настроить приложение так, чтобы ниодного сообщения не было залогировано.\n",
    "\n",
    "<details>\n",
    "    <summary>Ответ</summary>\n",
    "\n",
    "1. Остановить текущее приложение: `spark.stop()`\n",
    "2. Запустить приложение с `spark.log.level=OFF`:\n",
    "```python\n",
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(service_name)\n",
    "        .master(\"local[4]\")\n",
    "        .config(\"spark.driver.extraJavaOptions\", f\"-Dotel.service.name={service_name}\")\n",
    "        .config(\"spark.log.level\", \"OFF\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "```\n",
    "3. залогировать сообщения для проверки\n",
    "```python\n",
    "logger = get_logger(\"Н. Н. Некрасов. Крестьянские дети\")\n",
    "\n",
    "logger.trace(\"Однажды, в студеную зимнюю пору,\")\n",
    "logger.debug(\"Я из лесу вышел; был сильный мороз.\")\n",
    "logger.info(\"Гляжу, поднимается медленно в гору\")\n",
    "logger.warn(\"Лошадка, везущая хворосту воз.\")\n",
    "logger.error(\"И, шествуя важно, в спокойствии чинном,\")\n",
    "logger.fatal(\"Лошадку ведет под уздцы мужичок.\")\n",
    "```\n",
    "\n",
    "4. Остановить приложение: `spark.stop()`\n",
    "\n",
    "</details>\n",
    "\n",
    "4. Настроить приложение так, чтобы было залогировано только одно (любое) сообщение.\n",
    "\n",
    "<details>\n",
    "    <summary>Ответ</summary>\n",
    "\n",
    "    Идея в том, что нужно указать `spark.log.level=FATAL` при старте прилжения. Так будет залогировано единственное сообщение с этим уровнем.\n",
    "\n",
    "1. Остановить текущее приложение: `spark.stop()`\n",
    "2. Запустить приложение с `spark.log.level=FATAL`:\n",
    "```python\n",
    "spark = (\n",
    "    SparkSession}\n",
    "        .builder\n",
    "        .appName(service_name)\n",
    "        .master(\"local[4]\")\n",
    "        .config(\"spark.driver.extraJavaOptions\", f\"-Dotel.service.name={service_name}\")\n",
    "        .config(\"spark.log.level\", \"FATAL\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "```\n",
    "3. залогировать сообщения для проверки\n",
    "```python\n",
    "logger = get_logger(\"Н. Н. Некрасов. Крестьянские дети\")\n",
    "\n",
    "logger.trace(\"Однажды, в студеную зимнюю пору,\")\n",
    "logger.debug(\"Я из лесу вышел; был сильный мороз.\")\n",
    "logger.info(\"Гляжу, поднимается медленно в гору\")\n",
    "logger.warn(\"Лошадка, везущая хворосту воз.\")\n",
    "logger.error(\"И, шествуя важно, в спокойствии чинном,\")\n",
    "logger.fatal(\"Лошадку ведет под уздцы мужичок.\")\n",
    "```\n",
    "\n",
    "4. Остановить приложение: `spark.stop()`\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23dd5de-ab85-4e2a-a972-87d69967d9d1",
   "metadata": {},
   "source": [
    "## Ответы на задание про запуск приложений"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2a5b14-e1bc-4c42-932a-7fe3bf4e927b",
   "metadata": {},
   "source": [
    "1. Запустить `org.apache.spark.examples.SparkPi` из `$SPARK_HOME/examples/jars/spark-examples*.jar` при помощи `spark-submit`:\n",
    "    - в кластерном режиме,\n",
    "    - c уровнем логирования `OFF`,\n",
    "    - мониторингом на базе `Prometheus PushGateway`,\n",
    "    - проверить метрики.\n",
    "\n",
    "<details>\n",
    "    <summary>Ответ</summary>\n",
    "\n",
    "1. Настроить Prometheus:\n",
    "\n",
    "```bash\n",
    "! cp /tmp/spark/metrics-prometheus-pushgateway.properties /tmp/spark-conf/metrics.properties && \\\n",
    "cat /tmp/spark-conf/metrics.properties\n",
    "```\n",
    "\n",
    "2. Настроить логер (один из двух способов):\n",
    "\n",
    "    - через внешний редактор отредактировать в проекте `spark-exercises` файл `conf/spark/override/log4j2-warn.properties` и скопировать его: `cp /tmp/spark/log4j2-warn.properties /tmp/spark-conf/log4j.properties`\n",
    "    - через `sed`:\n",
    "\n",
    "```bash\n",
    "! sed -i '/rootLogger.level/s,.*,rootLogger.level=OFF,' /tmp/spark-conf/log4j2.properties && \\\n",
    "cat /tmp/spark-conf/log4j2.properties\n",
    "```\n",
    "\n",
    "3. запустить приложение:\n",
    "```bash\n",
    "! SPARK_CONF_DIR='/tmp/spark-conf' \\\n",
    "$SPARK_HOME/bin/spark-submit --class org.apache.spark.examples.SparkPi \\\n",
    "    --master yarn \\\n",
    "    --deploy-mode cluster \\\n",
    "    --num-executors 2 \\\n",
    "    --conf spark.driver.extraJavaOptions=\"-Dotel.service.name=SparkPi\" \\\n",
    "    --conf spark.executor.extraJavaOptions=\"\\${spark.driver.extraJavaOptions} -Dotel.exporter.otlp.endpoint=${OTEL_EXPORTER_OTLP_ENDPOINT}\" \\\n",
    "    --conf spark.log.level=OFF \\\n",
    "    $SPARK_HOME/examples/jars/spark-examples*.jar 10\n",
    "```\n",
    "\n",
    "Метрики будут доступны на PushGateway на порту [9091](http://localhost:9091)\n",
    "\n",
    "</details>\n",
    "\n",
    "2. Запустить `org.apache.spark.examples.SparkPi` из `$SPARK_HOME/examples/jars/spark-examples*.jar` при помощи `spark-submit`:\n",
    "    - в клиентском режиме,\n",
    "    - c уровнём логирования `DEBUG`,\n",
    "    - c мониторингом на базе `PrometheusServlet`,\n",
    "    - проверить метрики.\n",
    "\n",
    "<details>\n",
    "    <summary>Ответ</summary>\n",
    "\n",
    "1. Настроить Prometheus:\n",
    "\n",
    "```bash\n",
    "! cp /tmp/spark/metrics-prometheus-servlet.properties /tmp/spark-conf/metrics.properties && \\\n",
    "cat /tmp/spark-conf/metrics.properties\n",
    "```\n",
    "\n",
    "2. Настроить логер (один из двух способов):\n",
    "\n",
    "    - через внешний редактор отредактировать в проекте `spark-exercises` файл `conf/spark/override/log4j2-warn.properties` и скопировать его: `cp /tmp/spark/log4j2-warn.properties /tmp/spark-conf/log4j.properties`\n",
    "    - через `sed`:\n",
    "\n",
    "```bash\n",
    "! sed -i '/rootLogger.level/s,.*,rootLogger.level=DEBUG,' /tmp/spark-conf/log4j2.properties && \\\n",
    "cat /tmp/spark-conf/log4j2.properties\n",
    "```\n",
    "\n",
    "3. запустить приложение:\n",
    "```bash\n",
    "! SPARK_CONF_DIR='/tmp/spark-conf' \\\n",
    "$SPARK_HOME/bin/spark-submit --class org.apache.spark.examples.SparkPi \\\n",
    "    --master yarn \\\n",
    "    --deploy-mode cluster \\\n",
    "    --num-executors 2 \\\n",
    "    --conf spark.driver.extraJavaOptions=\"-Dotel.service.name=SparkPi\" \\\n",
    "    --conf spark.executor.extraJavaOptions=\"\\${spark.driver.extraJavaOptions} -Dotel.exporter.otlp.endpoint=${OTEL_EXPORTER_OTLP_ENDPOINT}\" \\\n",
    "    --conf spark.log.level=OFF \\\n",
    "    $SPARK_HOME/examples/jars/spark-examples*.jar 10\n",
    "```\n",
    "\n",
    "Метрики будут доступны на дашборде Spark Application в Grafana на порту [3000](http://localhost:9091)\n",
    "\n",
    "</details>\n",
    "\n",
    "3. Запустить Spark приложение:\n",
    "    - через ноутбук, \n",
    "    - в локальном режиме,\n",
    "    - с уровнем логирования `ERROR`,\n",
    "    - c мониторингом на базе `Prometheus PushGateway`\n",
    "\n",
    "<details>\n",
    "    <summary>Ответ</summary>\n",
    "\n",
    "1. Настроить Prometheus:\n",
    "\n",
    "```bash\n",
    "! cp /tmp/spark/metrics-prometheus-pushgateway.properties /tmp/spark-conf/metrics.properties && \\\n",
    "cat /tmp/spark-conf/metrics.properties\n",
    "```\n",
    "\n",
    "2. Запустить приложение (редактировать log4j2.properties не нужно, т.к. можно переопределить уровень логирования при помощи `spark.log.level`:\n",
    "\n",
    "```python\n",
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"HomeWork\")\n",
    "        .master(\"local[4]\")\n",
    "        .config(\"spark.log.level\", \"ERROR\")\n",
    "        .config(\"spark.driver.extraJavaOptions\", f\"-Dotel.service.name={service_name}\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "```\n",
    "\n",
    "3. Запустить нагрузку:\n",
    "\n",
    "```python\n",
    "for i in range(100):\n",
    "    spark.sql(f\"select '{i}.Hello, Monitoring!' as message\").collect()\n",
    "```\n",
    "\n",
    "Метрики будут доступны на PushGateway на порту [9091](http://localhost:9091)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe01d13-1a8f-49e5-92db-5ead1898198b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
