{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c56032e-3575-4582-8e50-05497f53dff5",
   "metadata": {},
   "source": [
    "# **Включите тёмную тему для корректного отображения рисунков: Settings -> Theme -> Jupyter Dark**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad78f7c-69a4-44dd-a9df-0a127c8ce423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark import StorageLevel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c013739-22ed-4fb8-90a5-3a8ad85ac5b4",
   "metadata": {},
   "source": [
    "# Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55f1357-824b-41c0-9b7f-48507b9cb8b8",
   "metadata": {},
   "source": [
    "## Spark Контекст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad143f9f-f53e-4010-926a-21ef7e7ebfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"execution-plan\")\n",
    "        .config(\"spark.scheduler.mode\", \"FIFO\")\n",
    "        .master(\"local[4]\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fee734a",
   "metadata": {},
   "source": [
    "После старта сессии `Spark UI` становится доступным на порту [`4040`](http://localhost:4040)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f99888-d40d-4b5d-a6ba-c2b7a4a97396",
   "metadata": {},
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238f28c2-3d1d-4d94-a411-cb0e57de6514",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /tmp/taxi\n",
    "!unzip -o -d /tmp/taxi ./data/taxi.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1afb10c-b3fb-4ef3-939f-88f1a1cfa70d",
   "metadata": {},
   "source": [
    "Файл `taxi.parquet` необходимо разбить на несколько частей, чтобы можно было обрабатывать каждую одновременно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c70e69f-40fe-4da3-b499-f24dbe55b91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.parquet(\"/tmp/taxi/taxi.parquet\").repartition(4).write.mode(\"overwrite\").parquet(\"/tmp/taxi_many\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fda029-0859-4d21-9379-44dfa36de96f",
   "metadata": {},
   "source": [
    "## Запросы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ddb947-f54a-4881-adcd-c15fcb3e36b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hello_world_df = spark.sql(\"select 'Hello, World!' as message\")\n",
    "hello_world_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0490bb0b-73c9-4760-9ebc-13f9aff1d912",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_single_partition_df = spark.read.parquet(\"/tmp/taxi/taxi.parquet\")\n",
    "taxi_single_partition_df.groupBy(\"passenger_count\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69ec9bc-e81b-43af-a554-3d7d138d5f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_many_partitions_df = spark.read.parquet(\"/tmp/taxi_many\")\n",
    "taxi_many_partitions_df.groupBy(\"passenger_count\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f1f8dc",
   "metadata": {},
   "source": [
    "# Spark UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc4c78c",
   "metadata": {},
   "source": [
    "## Заголовок"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee128be",
   "metadata": {},
   "source": [
    "![main menu](../imgs/spark-ui-header.drawio.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fc7b46",
   "metadata": {},
   "source": [
    "Заголовок разделен на 2 части:\n",
    "\n",
    "1. имя приложения: отображает значение, переданное в [`Builder#appName`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.builder.appName.html?highlight=appname#pyspark.sql.SparkSession.builder.appName);\n",
    "1. главное меню: позволяет переключаться между экранами:\n",
    "    - Jobs - список задач,\n",
    "    - Stages - список стадий, на которые разбиваются задачи,\n",
    "    - Storage - информация о кэше,\n",
    "    - Environment - итоговая конфигурация приложения,\n",
    "    - Executors - список воркеров в кластере Apache Spark,\n",
    "    - (Дополнительно) SQL/DataFrame - планы запущенных запросов,\n",
    "    - (Дополнительно) Structured Streaming - потоковая обработка Apache Kafka при помощи Apache Spark.\n",
    "\n",
    "Дополнительные пункты главного меню не видны сразу, они появляются, когда приложение обращается к DataFrame API или Structured Streaming API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97ba610",
   "metadata": {},
   "source": [
    "## Задачи - Spark Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb3ca3f",
   "metadata": {},
   "source": [
    "Первая страница Spark UI - это Spark Jobs. Все операции в Spark делятся на 2 типа:\n",
    "\n",
    "1. Трансформации (transformations) - операции, которые формируют план запроса (`select`, `where`, `groupBy`, и т.д.). Никакой реальной работы с данными не выполняется;\n",
    "1. Действия (actions) - операции, которые запускают исполнение сформированного плана (`show`, `count`, и т.д.).\n",
    "\n",
    "Экран Spark Jobs показывает запущенные действия (actions)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7838ce7-c37b-4756-8392-4a8257a3320e",
   "metadata": {},
   "source": [
    "Экран Spark Jobs логически разделен на 3 секции:\n",
    "\n",
    "1. Общая конфигурация,\n",
    "1. Event Timeline,\n",
    "1. Список задач (jobs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09828c3d-6780-4f76-bf9d-36d116ea8d78",
   "metadata": {},
   "source": [
    "### Общая конфигурация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d0c4e3",
   "metadata": {},
   "source": [
    "![jobs](../imgs/spark-ui-jobs-stat.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e25d11-2d0c-487e-8752-583eed67cf7f",
   "metadata": {},
   "source": [
    "Общая конфигурация показывает 3 настройки:\n",
    "\n",
    "1. Пользователь, от имени которого будет выполняться доступ к ресурсам,\n",
    "1. Общее время работы приложение: сколько времени прошло с момента старта приложения,\n",
    "1. Тип планировщика. Отображаемое значение соответствует значению конфига `spark.scheduler.mode`, которое было указано при старте приложения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a8bdaf-7f76-40d3-afc5-6630e964299e",
   "metadata": {},
   "source": [
    "#### Тип планировщика"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cd3b47-33d7-49ef-ad70-046ba3963d89",
   "metadata": {},
   "source": [
    "Планировщик является потокобезопасным, а значит в рамках одного Spark приложения/SparkContext могут быть запущены несколько задач (jobs) одновременно из разных потоков. Эта возможность позволяет обрабатывать параллельно обрабатывать запросы от разных клиентов.\n",
    "\n",
    "По умолчанию, Spark запускает задачи по очереди (`FIFO`), и задача в голове очереди получает приоритетный доступ ко всем ресурсам. Так одна большая задача может сильно снизить пропускную способность (throughput) и повысить среднюю задержку (latency).\n",
    "\n",
    "При помощи настройки `spark.scheduler.mode` можно организовать более справедливый доступ к ресурсам, если передать значение `FAIR`. Так Spark будет использовать алгоритм Round Robin при выделении ресурсов задачам, а значит все задачи будут получать примерно равное время.\n",
    "\n",
    "[Documentation](https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a64608-cf31-403a-8f96-1bf49681f6cb",
   "metadata": {},
   "source": [
    "### Event Timeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36415e02-a116-4576-b8d8-952f9195c920",
   "metadata": {},
   "source": [
    "Event Timeline показывает:\n",
    "\n",
    "1. задачи (job): когда задача была создана, и сколько времени заняла обработка этой задачи,\n",
    "1. воркеры (executors): появление новых и удаление имеющихся воркеров.\n",
    "\n",
    "![event timeline](../imgs/spark-ui-event-timeline.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827496c6-22d1-4ead-bb95-6dbe1a2eaa44",
   "metadata": {},
   "source": [
    "### Задачи (Jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306be460-50bf-411a-8b42-2e03e130030e",
   "metadata": {},
   "source": [
    "План запроса представляется в виде графа, который Spark делит на задачи во время обработки. Задача может быть активной или завершенной. Завершенные задачи отображаются в виде таблицы на странице Spark Jobs. Таблица имеет следующие колонки:\n",
    "\n",
    "1. **Job Id** - номер задачи,\n",
    "2. **Description** - имя функции, которая запустила задачу,\n",
    "3. **Submitted** - время создания задачи,\n",
    "4. **Duration** - общее время работы задачи,\n",
    "5. **Stages: Succeeded/Total** - количество стадий задачи (граница стадии - широкая операция),\n",
    "6. **Tasks: Succeeded/Total** - количество заданий (tasks).\n",
    "\n",
    "![Spark Jobs](../imgs/spark-ui-jobs.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5c3bcf-689e-46bd-a1c9-14c787d7cc66",
   "metadata": {},
   "source": [
    "### Детали задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c12a4d5-515f-4235-acd8-b2ed7998127f",
   "metadata": {},
   "source": [
    "Если нажать на задачу, откроется страница с деталями задачи. На странице можно увидеть следующую информацию:\n",
    "\n",
    "1. Статистика:\n",
    "    - **Status** - статус выполнения задачи,\n",
    "    - **Submitted** - время запуска,\n",
    "    - **Duration** - время работы как сумма времени работы каждой задачи,\n",
    "    - **Associated SQL Query** - ссылка на план запроса,\n",
    "    - **Completed Stages** - количество стадий в текущей задаче.\n",
    "1. Event Timeline - связанные с задачей события,\n",
    "2. DAG Visualization - граф вычислений текущей задачи,\n",
    "3. Информация по стадиям - детальная статистика по каждой стадии.\n",
    "\n",
    "![Job Details](../imgs/spark-ui-job-details.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9124261-92d2-4a2c-8292-e4c935ff44a8",
   "metadata": {},
   "source": [
    "## Стадии (Stages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637ca545-4ae9-4186-86f9-ea2c7260ddc8",
   "metadata": {},
   "source": [
    "Задачи (job) делятся на стадии (stage). **Стадия** - это множество узких операций (можно выполнить по очереди на одном воркере). Границей стадии является широкая операция (`join`, `sort`, `sum`, `avg`, и т.д.). Обычно на границе стадии находится операция `Exchange`, которая запускает перемешивание (shuffle) данных между воркерами.\n",
    "\n",
    "Каждая стадия имеет уникальный порядковый номер, который является сквозным среди всех задач. Перейти к списку стадий можно двумя способами:\n",
    "\n",
    "- Выбрать **Stages** в пункте главного меню,\n",
    "- Нажать на стадию на странице с деталями задачи.\n",
    "\n",
    "![Spark Stages](../imgs/spark-ui-stages-all.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b641c646-d627-4fde-a14c-3180ceb52e00",
   "metadata": {},
   "source": [
    "На странице со стадиями можно заметить разделение всех стадий на две части:\n",
    "\n",
    "- **Completed Stages** - стадии, в которых выполнялись вычисления,\n",
    "- **Skipped Stages** - стадии, которые не были запущены. Одной из причин является активное кэширование результатов, и если Spark видит, что результаты для стадии уже есть, то стадия помечается **skipped**, и вычисления не запускаются."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0db371-f45d-44a2-bf22-81f3afa0279d",
   "metadata": {},
   "source": [
    "### Завершенные стадии - Completed Stages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cde1966-9037-444b-89bf-46d9c89d3bed",
   "metadata": {},
   "source": [
    "Таблица с завершенными стадиями отображает статистику по запуску стадий. Особый интерес представляют колонки:\n",
    "\n",
    "- **Input** - объем данных, которые пришли на вход для исполнения стадии. Если стадия читает данные из файла, то его размер будет указан в этой колонке;\n",
    "- **Output** - объем данных, которые стадия записала куда-либо: файл, таблица, jdbc и т.д.;\n",
    "- **Shuffle Write** - объем данных, которые стадия отправила другой стадии в результате перемешивания;\n",
    "- **Shuffle Read** - объем данных, полученных стадией от другой стадии в результате перемешивания (shuffle/exchange)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b7c3e4-42f9-47ec-a157-dc400f69fc9d",
   "metadata": {},
   "source": [
    "Анализируя таблицу, можно заметить, как данные перемещались между стадиями в рамках одной задачи:\n",
    "\n",
    "![Stage Data Flow](../imgs/spark-ui-stages-data-flow.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e877b3-50ba-46e7-89a1-d3ac1fbb6a83",
   "metadata": {},
   "source": [
    "### Детали стадии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5094ab76-3e20-4d60-aa37-f3b0646c34e1",
   "metadata": {},
   "source": [
    "На странице стадии есть много полезной информации.\n",
    "\n",
    "В заголовке приводится краткая статистика:\n",
    "\n",
    "- Время работы стадии (Total Time Across All Tasks): суммарное время работы всех заданий в стадии. Задания могут выполняться параллельно, не смотря на это данное поле будет показывать общую сумму работы всех стадий;\n",
    "- Локальность данных (Locality Level): данные могут быть находиться в адресном пространстве процесса, на той же машине или на соседней машине. Spark проанализирует, с каким уровнем локальности данных работала каждая задача и покажет эту статистику в этом поле;\n",
    "- Входящий объем данных (Input Size/Records): сколько всего данных поступило на вход стадии в байтах и строках;\n",
    "- Исходящий объем данных (Shuffle Write Size / Records): сколько все данных в байтах и строках текущая стадия отправила (exchange/shuffle) другой стадии;\n",
    "- Идентификатор задачи (Associated Job Ids): идентификатор задачи, к котором относится текущая стадия.\n",
    "\n",
    "Следующий раздел на странице - это метрики в виде гистограммы. Она реализована в виде таблицы, в которой колонки являются значениями персентиля. Среди метрик можно найти следующие:\n",
    "\n",
    "- Длительность (Duration) показывает время работы заданий (tasks) по персентилям, а также минимальное и максимальное значение;\n",
    "- Время сборщика мусора (GC Time) показывает время работы сборщика мусора по персентилям, а также минимальное и максимальное значение;\n",
    "- Входящий объем (Input Size) показывает сколько данных обрабатывалось каждым заданием по персентилям, а также минимальное и максимальное значение;\n",
    "- Исходящий объем (Shuffle Write Size) показывает сколько данных каждое задание сформировало в результате с разбиением по персентилям, а также минимальное и максимальное значение;\n",
    "\n",
    "В самом низу перечислены все задания, которые выполнялись в рамках текущей стадии. Тут можно найти следующую информацию по каждому конкретному заданию:\n",
    "\n",
    "- уровень локальности данных,\n",
    "- время работы,\n",
    "- входящий объем данных,\n",
    "- исходящий объем данных,\n",
    "- и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e86677-7177-4e02-9f49-aa3e161084ff",
   "metadata": {},
   "source": [
    "На картике ниже можно проанализировать одну стадию. Какой вывод можно сделать о производительности? Эффективно ли загружен кластер?\n",
    "\n",
    "![Stage Details](../imgs/spark-ui-stage-details.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f09a7f-d2b7-48e7-8bd4-2545ebfc1cdc",
   "metadata": {},
   "source": [
    "#### Event Timeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67783a5f-57cb-4889-97e5-6f96cf4a9cb9",
   "metadata": {},
   "source": [
    "Event Timeline показывает время запуска заданий, а также дополнительные метрики:\n",
    "\n",
    "- ожидание запуска (Scheduler Delay) - синий: сколько времени прошло между созданием задания и постановкой его на обработку;\n",
    "- десериализация (Task Deserializaion Time) - красный: сколько времени заняла десериализация данных для;\n",
    "- время работы задания (Executor Computing Time) - зеленый: сколько процессорного времени воркера (executor) было затрачено на обработку задания. Нужно стремиться, чтобы это значение было как можно больше;\n",
    "- время на отправку результатов работы (Shuffle Write Time) - коричневый: сколько времени потребовалось на отправку результатов другим стадиям."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccdc56c-9294-4e6b-9d2a-63bb518faa9b",
   "metadata": {},
   "source": [
    "На картинке виден явный перекос (skew) времени работы. Нужно стремиться к тому, чтобы все задачи были примерно одинакового размера. Так кластер будет загружен равномерно.\n",
    "\n",
    "![Event Timeline](../imgs/spark-ui-stage-event-timeline.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9866c2f2-aa52-4dad-b8ae-b3491d35fd27",
   "metadata": {},
   "source": [
    "### Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb95ec7-7c71-4f67-8f99-f0d6f8f04373",
   "metadata": {},
   "source": [
    "Проанализировать стадию 10. Вопросы:\n",
    "\n",
    "1. Сколько байт и строк пришло на вход стадии 10?\n",
    "1. Сколько заданий (task) получили самое большое количество строк на обработку?\n",
    "1. Какой объем данных (байты и строки) записало задание (task), на вход которому пришло меньше всего строк?\n",
    "1. Сколько времени заняла обработка стадии 10?\n",
    "1. Эффективно ли стадия 10 обработала данные?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7991f043-5c17-4163-8400-67d656415f0b",
   "metadata": {},
   "source": [
    "## Кэширование (Storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205077a7-a74e-4f75-bc7c-062693087a64",
   "metadata": {},
   "source": [
    "Пункт \"Storage\" в главном меню покажет закешированные данные."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8146a0b-4d99-468f-9751-2423e638ec1d",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5238d8d2-cd19-4191-80f0-a17a93d393f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hello_world_df = hello_world_df.cache()\n",
    "hello_world_df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690c0b5a-e0b8-43c7-b9a3-988de684e70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_single_partition_df = taxi_single_partition_df.persist(StorageLevel.DISK_ONLY)\n",
    "taxi_single_partition_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83baa52-768d-4328-8430-d9307df58730",
   "metadata": {},
   "source": [
    "### Описание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e809cca-1ed9-4f63-9fbf-848c521715a4",
   "metadata": {},
   "source": [
    "Список закешированных объектов предстает в виде таблицы с колонками:\n",
    "\n",
    "- ID - идентификатор объекта в кэше;\n",
    "- RDD Name - имя закешированного объекта. DataFrame - это просто план запроса, а реальные объекты в Spark представляются в виде RDD, поэтому все закешированные объекты называются RDD;\n",
    "- Storage Level - где данные сохранены: диск или память;\n",
    "- Cached Partitons - сколько партиций RDD удалось закешировать;\n",
    "- Fraction Cached - какой процент RDD удалось закешировать;\n",
    "- Size in Memory - сколько закешированных данных находится в памяти;\n",
    "- Size on Disk - сколько закешированных данных находится на диске."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde602be-42c6-46cf-8db3-680ea43bea2d",
   "metadata": {},
   "source": [
    "![Storage](../imgs/spark-ui-storage-cache.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48f7a20-babd-41c3-81df-11ff0b72c72a",
   "metadata": {},
   "source": [
    "### Детали кэша"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d922a46-afba-418d-a01e-3d649ca64a1c",
   "metadata": {},
   "source": [
    "Если перейти на страницу одного из закешированных объектов, то можно получить более детальную информацию:\n",
    "\n",
    "- место хранения (Storage Level) - где размещаются закешированные данные,\n",
    "- закешированные партиции (Cached Partitions) - сколько партиций удалось закешировать,\n",
    "- общее число партиций (Total Partitions) - сколько партиций в RDD всего,\n",
    "- размер объекта в памяти (Memory Size) - сколько данных было закешировано в памяти,\n",
    "- размер объекта на диске (Disk Size) - сколько данных было закешировано на диске."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec877a3-3f6e-4918-b6b4-0e46f318629b",
   "metadata": {},
   "source": [
    "![Cache Details](../imgs/spark-ui-storage-cache-details.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b119eeaf-a81b-4046-b4d7-cc9540b61a53",
   "metadata": {},
   "source": [
    "После работы с кэшами обязательно убрать свои объекты из кеша:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c53361a-7303-4ae9-b964-cebb029c34ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "hello_world_df.unpersist()\n",
    "taxi_single_partition_df.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9adc0d3-7133-462e-8927-175ceefd1983",
   "metadata": {},
   "source": [
    "### Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7cb5cf-6123-44f1-98a7-6d8e0d2b67a2",
   "metadata": {},
   "source": [
    "Закешировать `taxi_many_partitions_df` с уровнем `StorageLevel.MEMORY_ONLY_2` и проанализировать закешированный объект:\n",
    "\n",
    "1. Какой процент датафрейма был закеширован?\n",
    "1. Сколько данных располагается на диске?\n",
    "1. Сколько данных располагается в памяти?\n",
    "1. Сколько места в памяти занимает одна партиция датафрейма `taxi_many_partitions_df`?\n",
    "1. Уберите объект из кэша и убедитесь, что он действительно пропал."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e655a55f-7c75-4108-b6ca-00c09c2e91a2",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eab318-c0d3-41b6-abe1-6973c583e340",
   "metadata": {},
   "source": [
    "Вкладка Environment позволяет посмотреть весь конфиг запущенного приложения, включая те опции, которые явно были указаны при старте:\n",
    "\n",
    "![Spark Environment](../imgs/spark-ui-env.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b99c159-9c77-488d-b665-9095bedf6dc4",
   "metadata": {},
   "source": [
    "## Воркеры (Executors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546f5fdc-15d2-47c6-8dfc-42ecdb65f765",
   "metadata": {},
   "source": [
    "Вкладка Executors показывает статистику по воркерам:\n",
    "\n",
    "- занятый объем памяти (Storage Memory) включает информацию по занятой памяти как для кэшей, так и для служебных целей;\n",
    "- занятый объем диска (Disk Used) показывает сколько данных записано на диск. Это может быть либо кэш, либо спилы (spills) необходимые для выполнения сортировки, агреации и др.;\n",
    "- ядра (Cores) сколько ядер доступно для работы. Одно ядро может обрабатывать одно задание (task);\n",
    "- задания (tasks) показывает сколько заданий с каким статусом было завершено;\n",
    "- время сборщика мусора в заданиях (Task Time (GC Time)) показывает сколько времени потребовалось на сборку мусора;\n",
    "- данные из внешних источников (Input) показывает сколько данных пришло из файлов, jdbc и т.д.;\n",
    "- входные данные задания (Shuffle Read) показывает объем данных полученных заданиями на входе;\n",
    "- выходные данные (Shuffle Write) показывает объем данных, которые были отправлены заданиями в результате.\n",
    "\n",
    "Статистика приводится как общая, так и с разбиением по воркерам."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f194097e-6a40-44ff-a5db-b8a258bbfe52",
   "metadata": {},
   "source": [
    "![Spark Executors](../imgs/spark-ui-executors.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bc34a1-1c48-410e-9c85-aa9960c99ff3",
   "metadata": {},
   "source": [
    "## SQL / DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f04424b-e029-4e73-be67-6b2e82ed15ea",
   "metadata": {},
   "source": [
    "Вкладка SQL / DataFrame показывает планы запросов и краткую статистику по ним.\n",
    "\n",
    "![imgs](../imgs/spark-ui-sql-dataframe.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc4f4f2-0938-4e7a-9262-f414e2009643",
   "metadata": {},
   "source": [
    "Каждый план запроса имеет порядковый номер, а также ссылку на задачи (job), которые были запущены для исполнения плана. Более детальную информацию о плане можно найти на странице плана, если нажать на поле \"Description\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0494f3ab-cafb-4bad-a820-f9262d104027",
   "metadata": {},
   "source": [
    "![Plan Details](../imgs/spark-ui-plan.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3bab1e-cbb0-4cf3-8335-16f606be518e",
   "metadata": {},
   "source": [
    "## Заключение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f59e2bb-f3e6-4502-9f7d-b4c661ffe96d",
   "metadata": {},
   "source": [
    "Apache Spark предлагает очень мощный интерфейс для анализа запущенных задач и поиска узких мест. Для эффективного использования Spark UI необходимо хорошо понимать основные концепции Apache Spark: запросы (query), задачи (job), стадии (stage), задания (task) и т.д., а так же понимать как они формируются."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085ab691-b57d-44cb-9ba8-26b4e1ec748a",
   "metadata": {},
   "source": [
    "## Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cb9274-7499-4662-b853-96ca529b77bf",
   "metadata": {},
   "source": [
    "1. Найти идентификатор самого длинного запроса;\n",
    "2. Найти объем данных, который первая стадия передала следующей стадии, в самом длинном запросе;\n",
    "3. Найти самый долгий шаг самого длинного плана запроса. Почему этот шаг такой длинный? Подсказка: нужно посмотреть на стадии и задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ef5c33-97de-40fa-a3b9-1fa3ffe6e666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
