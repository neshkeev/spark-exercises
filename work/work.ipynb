{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5e0f817-5fff-4c49-a98b-079431435c6e",
   "metadata": {},
   "source": [
    "# Запуск Spark на Yarn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad78f7c-69a4-44dd-a9df-0a127c8ce423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9330d150-536c-4213-95a3-cc87f97edfef",
   "metadata": {},
   "source": [
    "Apache Spark может быть запущен на Yarn. Воркеры будут запущены на узлах HDFS ближе к данных, что позволит достичь максимальной производительности в силу минимизации передачи данных по сети."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315c69ef-fd08-46db-b984-0fb823b5c8c5",
   "metadata": {},
   "source": [
    "Для запуска Apache Spark на Yarn необходимо:\n",
    "\n",
    "1. Выбрать [версию](https://spark.apache.org/downloads.html) Apache Spark, которая была собрана для вашей версии Hadoop;\n",
    "1. Указать расположение конфигов Hadoop при помощи переменных окружения: `HADOOP_CONF_DIR` и `YARN_CONF_DIR`;\n",
    "1. Указать `--master yarn` при старте приложения через `spark-submit` или [`master(\"yarn\")`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.builder.master.html) при старте через PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e0f4d3-0a5a-4146-b536-852368214a22",
   "metadata": {},
   "source": [
    "Spark по умолчанию запросит три контейнера:\n",
    "\n",
    "- один контейнер для Application Master (драйвер),\n",
    "- два контейнера для Воркеров.\n",
    "\n",
    "Число контейненров для воркеров можно настраивать через `spark.executor.instances`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa10bc25-af52-4bb6-adda-dc80d26666a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"Yarn\")\n",
    "        .master(\"yarn\")\n",
    "        .config(\"spark.executor.instances\", 3)\n",
    "        .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e100c7-e6d9-4455-b619-2384fc6f1880",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"select 'Hello, Yarn!' as message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2872838d-5a71-43d4-b6e4-5ce7d9aaaf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39931ce-9294-4b87-980a-91f9d5763e5b",
   "metadata": {},
   "source": [
    "# Проверка доступа к Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d857969-9ec1-4b2b-8429-f8528dcbfa92",
   "metadata": {},
   "source": [
    "Hadoop стартует в однонодовом режиме: все демоны на одном компьютере. Демоны Hadoop:\n",
    "\n",
    "- демон [NameNode](http://localhost:9870) запущен на `9870` порту,\n",
    "- демон [DataNode](http://localhost:9864) запущен на `9864` порту,\n",
    "- демон [ResourceManager](http://localhost:8088) запущен на `8088` порту порту,\n",
    "- демон [NodeManager](http://localhost:8042) запущен на `8042` порту,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce52f901-e726-43ed-8074-fc1653f255f7",
   "metadata": {},
   "source": [
    "Для удобства текущий ноутбук сконфигурирован таким образом, что можно напрямую вызывать команды для работы с HDFS и Yarn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820123ed-01a1-418b-ae1c-f31294ad8f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0def2d47-2c25-498c-ad59-881bc34fa242",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "yarn application -list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dacd7db-28fc-4220-ab33-d00586529de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553d631d-3f46-44c8-9afa-7cafd3bd213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "yarn application -list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7beaaf2d-7646-41ba-a991-8df16cbfb4eb",
   "metadata": {},
   "source": [
    "## Конфигурация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3dc03c-f7ff-42e8-9844-f97e06a7f9ac",
   "metadata": {},
   "source": [
    "Для запуска Apache Spark в Yarn необходимо положить `hdfs-site.xml` и `yarn-site.xml` в директории `$HADOOP_CONF_DIR` и `$YARN_CONF_DIR` соответственно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761a186b-cf96-4539-a451-092116c311d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat $HADOOP_CONF_DIR/hdfs-site.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d9764d-d83e-4866-a616-1bf3f2027b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat $YARN_CONF_DIR/yarn-site.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a6998f-04f7-4d07-9517-54912a27c315",
   "metadata": {},
   "source": [
    "В то же время обе переменные могут указывать на одну и ту же директорию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eef8b31-9681-414d-bade-24cb5de270a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo \"HADOOP_CONF_DIR: $HADOOP_CONF_DIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad69c78-6d87-4c3d-8b9d-a8d7bb9f8cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo \"YARN_CONF_DIR: $YARN_CONF_DIR\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d33d7b6-4a2e-40d0-8fed-acdb8a606fa0",
   "metadata": {},
   "source": [
    "## Чтение и запись данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba6da22-71c8-4520-95cb-431e1aaeb883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "namenode = os.environ['NAMENODE_HOST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a1f803-8ea4-4cc4-a56b-88874b3f8494",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"Yarn\")\n",
    "        .master(\"yarn\")\n",
    "        .config(\"spark.sql.warehouse.dir\", \"/tmp/spark-warehouse\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628f079c-b513-4d4e-b4c0-5e511721dd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "hdfs dfs -mkdir -p /user/jovyan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5487a8c6-49ad-4abe-aacf-dd20588e6438",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "spark.range(0, 1000, 1, 10)\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .save(f\"hdfs://{namenode}:9000/user/jovyan/range\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151d8b3e-5cd4-42f2-a7ad-04324bf06b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "hdfs dfs -find /user/jovyan/range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94b5a70-18b5-4d85-afc7-f33b70ab6b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "spark.read\n",
    "    .parquet(f\"hdfs://{namenode}:9000/user/jovyan/range\")\n",
    "    .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f379b3e8-d690-4260-9277-70f2daf43144",
   "metadata": {},
   "source": [
    "После запуска в Yarn приложение Spark будет по умолчанию будет искать данные в HDFS.\n",
    "\n",
    "Можно указывать как полный путь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c60ec5-e8af-423b-a84b-47d026092584",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "spark.read\n",
    "    .parquet(\"/user/jovyan/range\")\n",
    "    .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e6c28a-6102-45f9-8710-43ba01e5f5ab",
   "metadata": {},
   "source": [
    "Также можно указать путь относительно домашней директории:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eb92d8-7357-42f6-949c-78b94f0e93c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "spark.read\n",
    "    .parquet(\"range\")\n",
    "    .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3d1934-adb9-4d82-96b0-8d749a1dc0f5",
   "metadata": {},
   "source": [
    "## Spark Warehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68375aa-c2ce-4e83-98fc-c3a5b033fe8b",
   "metadata": {},
   "source": [
    "При этом Spark Warehouse также окажется в HDFS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd17b31d-cd56-462b-9276-81f21b35fb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "spark.range(0, 1000, 1, 10)\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .saveAsTable(\"range_table\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3eca31-75a2-4563-b4ad-3595eca253af",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select count(*) from range_table\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14ae1c5-e353-4f71-8328-f70a60c6f23b",
   "metadata": {},
   "source": [
    "Spark автоматически развернул путь до Spark Warehouse в полную ссылку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7278ee3-ad87-43ef-afcd-d3c394fed226",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Spark Warehouse Location: {spark.conf.get('spark.sql.warehouse.dir')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b792edd-ade6-4ef2-9c8b-f9421bdf341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "hdfs dfs -find /tmp/spark-warehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d3bed1-a067-43ce-a549-4a254a2606b9",
   "metadata": {},
   "source": [
    "**Примечание:** `hdfs://hadoop:9000` - это адрес NameNode, который указывается в параметре `fs.defaultFS` через `core-site.xml`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a6ad6e-4b47-45b1-8fa0-d4df45dd7d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat $HADOOP_CONF_DIR/core-site.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56c52de-e745-406c-b603-79778f99321a",
   "metadata": {},
   "source": [
    "## Spark Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba3ebd3-f6f8-47ef-a9a3-c80198dca5d7",
   "metadata": {},
   "source": [
    "Spark Catalog содержит список созданных таблиц, UDF функций и пр.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841b902b-cb38-4dff-8571-64cca65e8422",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c257cf-6de9-4c02-96c0-c850a01870db",
   "metadata": {},
   "source": [
    "Spark Catalog желательно сохранять в какое-нибудь постоянное хранилище, т.к. после перезапуска приложения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354de9a9-e776-4bf9-a480-a8d3e38c22fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfd6104-3582-4e87-a8ee-ef699845ce86",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"Yarn\")\n",
    "        .master(\"yarn\")\n",
    "        .config(\"spark.sql.warehouse.dir\", \"/tmp/spark-warehouse\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a18937-5c9e-4096-b1eb-75e4eae31073",
   "metadata": {},
   "source": [
    "все данные из каталога пропадут, а значит нельзя будет выполнять запросы к созданным таблицам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6964b0ca-7e75-4e0a-9f7f-2bfd5bc0a62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "try:\n",
    "    spark.sql(\"select count(*) from range_table\").show()\n",
    "except Exception as e:\n",
    "    print(e, file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88753e0-a4f9-4176-95fe-ea877c371161",
   "metadata": {},
   "source": [
    "Spark Catalog пуст:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dfcd0f-7c40-4e07-9fd4-628e9d164d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a6904d-5080-4966-89fa-5dbb96064fd0",
   "metadata": {},
   "source": [
    "При этом файлы таблицы `range_table` по прежнему находятся в HDFS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d95acd2-6af6-4ce6-97f0-85cab64881c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bash_aliases && \\\n",
    "hdfs dfs -find /tmp/spark-warehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf43a1c-311c-4a16-8e71-d0322bdd4bea",
   "metadata": {},
   "source": [
    "Таким образом, можно заключить, что Spark Catalog по умолчанию демонстрирует признаки временного хранилища."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7637a58b-b733-468c-a4fd-5066163301cf",
   "metadata": {},
   "source": [
    "Все так и есть: если никак не конфигурировать Spark Catalog, то каталог будет храниться в памяти и исчезать, после того, как приложение завершает свою работу\n",
    "\n",
    "> **Spark Catalog по умолчанию хранится в памяти!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3889aa67-3ec4-4a06-9bd7-11fa67488084",
   "metadata": {},
   "source": [
    "### Постоянное хранение Spark Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19b3084-a802-4da8-882b-317d1a9c5370",
   "metadata": {},
   "source": [
    "Самая простая настройка - это использование метода [`SparkSession.builder#enableHiveSupport`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.builder.enableHiveSupport.html) во время создания сессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd87d0f-cb8e-4f06-8c50-f915cc9559ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7beb95-c1b7-4b52-ad37-8a542cbefb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"Yarn\")\n",
    "        .master(\"yarn\")\n",
    "        .config(\"spark.sql.warehouse.dir\", \"/tmp/spark-warehouse\")\n",
    "        .enableHiveSupport()\n",
    "        .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1122df-c1bb-427c-89c6-bb644b3f9c1c",
   "metadata": {},
   "source": [
    "Если никак больше не конфигурировать Spark, то Spark Catalog будет сохраняться во встраиваемую базу данных [Apache Derby](https://db.apache.org/derby/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5296a7d4-f09f-4088-9be4-8c274382e1cb",
   "metadata": {},
   "source": [
    "Теперь если создать новую таблицу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ae6449-1f2a-4f5d-b61f-1ed151bc3bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "spark.range(0, 1000, 1, 10)\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .saveAsTable(\"range_table_with_hive_support\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dc46d6-2bf6-41fa-90f9-10c1345f4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select count(*) from range_table_with_hive_support\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcb10db-9792-481e-9d76-acbeb053c1dd",
   "metadata": {},
   "source": [
    "То в текущей директории появится 2 объекта:\n",
    "\n",
    "- `derby.log` - логи работы встраиваемой базы данных Derby,\n",
    "- `metastore_db` - файлы базы данных Derby, в которой сохраняется Spark Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9708cc5e-0fd8-42ac-95fe-74fecb4414de",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b37330-002a-4900-8527-33ee2f8220aa",
   "metadata": {},
   "source": [
    "Каталог будет храниться в базе данных, и между перезапусками приложения можно будет обращаться ко всем объектам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad0d2c3-caa8-479c-86dd-42f9fa0b5a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0882f52-2d29-40d4-b87d-9bc426b6fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"Yarn\")\n",
    "        .master(\"yarn\")\n",
    "        .config(\"spark.sql.warehouse.dir\", \"/tmp/spark-warehouse\")\n",
    "        .enableHiveSupport()\n",
    "        .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb11ace0-960d-481a-9153-d27e7eb8f9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select count(*) from range_table_with_hive_support\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c2ae26-e950-4392-8a03-2c01c50b5d53",
   "metadata": {},
   "source": [
    "Запрос отработал успешно, т.к. каталог в текущем Spark приложении непустой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49575a2e-d954-4bd3-8899-f50aa5c88d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdb5f16-5493-4ca4-8682-fe33410df7cd",
   "metadata": {},
   "source": [
    "Локальное расположение Derby невозможно изменить, поэтому файл derby.log и директория `metastore_db` всегда будет сохраняться в текущей директории.\n",
    "\n",
    "> **Невозможно изменить место хранения Derby на локальном жестком диске**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faf5549-fff4-473b-9710-49a50f5a6c3d",
   "metadata": {},
   "source": [
    "### Надежное хранение Spark Catalog в Hive MetaStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33516e99-04ba-40c3-bfaf-91361625893a",
   "metadata": {},
   "source": [
    "Дополнительно можно добавить файл `hive-site.xml` в `$HADOOP_CONF_DIR`, в котором описаны параметры Hive, и тогда Spark вместо хранения данных в локальной Derby базе будет хранить каталог в Hive MetaStore.\n",
    "\n",
    "Кроме `enableHiveSupport()` ничего другого не потребуется."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f578897-0eb2-4182-9cdb-7540c557d881",
   "metadata": {},
   "source": [
    "В текущем окружении отсутствует Hive, поэтому нет возможности продемонстирировать этот пример на практике."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b62325-601e-4a4e-bfb4-05e65e525cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740b5470-1d48-4858-b48e-e03b5d4f7b55",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57032f6a-9f05-4930-8396-d69d61e9ee00",
   "metadata": {},
   "source": [
    "Поддержка планировщика Yarn появилась в Apache Spark в версии `0.6`, и с того времени Yarn получил наибольшее внимание от разработчиков Apache Spark, что делает его самым надежным способом запуска задач Spark на кластере. В то же время Yarn является одним из двух основных компонентов поставки Hadoop (второй - это HDFS), и поэтому он очень тесно интегрирован с HDFS. Такая тесая связь очень сильно повышает уровень локальности данных: задачи запускаются на тех машинах, на которых хранятся данные, реализуя концепцию перемешения кода поближе к данным.\n",
    "\n",
    "Задачи Spark, запущенные на Yarn, значительно превосходят по скорости исполнения другие планировщики, а поэтому проекты, которым нужна надежность и скорость еще долгое время будут выбирать связку Spark + Yarn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be30cd04-e497-4eaf-802f-88b8ebae8626",
   "metadata": {},
   "source": [
    "## Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a04755-7944-4c83-8585-b624d9c6479a",
   "metadata": {},
   "source": [
    "1. Сохранить в HDFS последовательность из десяти чисел Фиббоначчи:\n",
    "    - в виде таблицы\n",
    "    - в формате json\n",
    "    - с двумя колонками:\n",
    "        - номер числа,\n",
    "        - значение числа фиббоначчи по этому номеру.\n",
    "1. Убедиться, что таблица остается доступной между перезапусками.\n",
    "1. Что произойдет, если удалить `derby.log`? Провести эксперименты.\n",
    "1. Что произойдет, если удалить `metastore_db`? Провести эксперименты."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dff948c-d025-4930-97df-e28d0d4aa74b",
   "metadata": {},
   "source": [
    "### Ответы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cca76f-1a5f-4df6-8c41-09105a8f16ed",
   "metadata": {},
   "source": [
    "1. Сохранить в HDFS последовательность из десяти квадратов чисел:\n",
    "    - в виде таблицы\n",
    "    - в формате json\n",
    "    - в одной партиции\n",
    "    - с двумя колонками:\n",
    "        - значение числа,\n",
    "        - квадрат числа.\n",
    "\n",
    "<details>\n",
    "    <summary>Ответ</summary>\n",
    "\n",
    "1. Сохранить файл:\n",
    "```python\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# запустить приложение\n",
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"Yarn\")\n",
    "        .master(\"yarn\")\n",
    "        .config(\"spark.sql.warehouse.dir\", \"/tmp/spark-warehouse\")\n",
    "        .enableHiveSupport()\n",
    "        .getOrCreate()\n",
    ")\n",
    "\n",
    "# сгенерировать датафрейм\n",
    "df = spark.range(0, 10).withColumn(\"square\", F.expr(\"id * id\"))\n",
    "# сохранить как таблицу\n",
    "df.repartition(1).write.mode(\"overwrite\").format(\"json\").saveAsTable(\"squares\")\n",
    "\n",
    "```\n",
    "\n",
    "2. Проверить файлы в HDFS:\n",
    "```bash\n",
    "! source ~/.bash_aliases && \\\n",
    "hdfs dfs -cat /tmp/spark-warehouse/squares/*.json\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "2. Убедиться, что таблица остается доступной между перезапусками.\n",
    "\n",
    "<details>\n",
    "    <summary>Ответ</summary>\n",
    "\n",
    "```python\n",
    "# остановить приложение\n",
    "spark.stop()\n",
    "\n",
    "# запустить приложение снова\n",
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"Yarn\")\n",
    "        .master(\"yarn\")\n",
    "        .config(\"spark.sql.warehouse.dir\", \"/tmp/spark-warehouse\")\n",
    "        .enableHiveSupport()\n",
    "        .getOrCreate()\n",
    ")\n",
    "\n",
    "# таблица доступна для запросов\n",
    "spark.sql(\"select * from squares\").show()\n",
    "# таблица находится в каталоге\n",
    "spark.catalog.listTables()\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "3. Что произойдет, если удалить `derby.log`?\n",
    "\n",
    "<details>\n",
    "    <summary>Ответ</summary>\n",
    "\n",
    "Ошибок не будет, приложение продолжит ответчать на запросы к таблице.\n",
    "\n",
    "Для экспериментов может потребоваться перезапуск kernel через главное меню:\n",
    "\n",
    "    Kernel -> Restart Kernel -> Restart\n",
    "\n",
    "</details>\n",
    "\n",
    "4. Что произойдет, если удалить `metastore_db`?\n",
    "\n",
    "<details>\n",
    "    <summary>Ответ</summary>\n",
    "\n",
    "Работоспособность запросов нарушится в текущей сессии, но таблицы будут недоступны для запросов после перезапуска.\n",
    "\n",
    "Для экспериментов может потребоваться перезапуск kernel через главное меню:\n",
    "\n",
    "    Kernel -> Restart Kernel -> Restart\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9262aa4-d8fe-4b05-b45e-d45fd3fc4868",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
