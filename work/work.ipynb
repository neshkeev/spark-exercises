{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71c25f47-b707-421a-98be-1dceb9fc62eb",
   "metadata": {},
   "source": [
    "# Мотивация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0565fa-6629-4c22-95cc-ebdf682103d4",
   "metadata": {},
   "source": [
    "Ключом производительности Apache Spark является оптимизатор Catalyst, который умеет находить наиболее оптимальные стратегии исполнения запросов на кластере. Глубокое понимание принципов работы оптимизатора лучше анализировать план запроса, а также понимать почему план так выглядит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad78f7c-69a4-44dd-a9df-0a127c8ce423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c013739-22ed-4fb8-90a5-3a8ad85ac5b4",
   "metadata": {},
   "source": [
    "# Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55f1357-824b-41c0-9b7f-48507b9cb8b8",
   "metadata": {},
   "source": [
    "## Spark Контекст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad143f9f-f53e-4010-926a-21ef7e7ebfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"catalyst\")\n",
    "        .master(\"local[4]\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fee734a",
   "metadata": {},
   "source": [
    "После старта сессии `Spark UI` становится доступным на порту [`4040`](http://localhost:4040)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f99888-d40d-4b5d-a6ba-c2b7a4a97396",
   "metadata": {},
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238f28c2-3d1d-4d94-a411-cb0e57de6514",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /tmp/taxi\n",
    "!unzip -o -d /tmp/taxi ./data/taxi.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1afb10c-b3fb-4ef3-939f-88f1a1cfa70d",
   "metadata": {},
   "source": [
    "Файл `taxi.parquet` необходимо разбить на несколько частей, чтобы можно было обрабатывать каждую одновременно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c70e69f-40fe-4da3-b499-f24dbe55b91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.parquet(\"/tmp/taxi/taxi.parquet\").repartition(4).write.mode(\"overwrite\").parquet(\"/tmp/taxi_many\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f1f8dc",
   "metadata": {},
   "source": [
    "# Оптимизатор - Catalyst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941b2216-19d0-4ab5-85e7-4f7e506325c3",
   "metadata": {},
   "source": [
    "Стартовой точкой для запуска вычислений на Apache Spark является запрос (Spark SQL или DataFrame API). Исполнение запроса разбивается на три стадии:\n",
    "\n",
    "- разбор,\n",
    "- оптимизация,\n",
    "- исполнение."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4037850-4426-47b8-9497-34e3d705f648",
   "metadata": {},
   "source": [
    "## Разбор запроса"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c8134c-3a8d-4a6b-a2fb-c9fbe64b475f",
   "metadata": {},
   "source": [
    "Разбор запроса выполняется в две стадии:\n",
    "\n",
    "- создание AST - Абстрактного Синтаксического Дерева (Abstract Syntax Tree),\n",
    "- конвертация AST в реляционное дерево."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c368eea2-1f4e-4a1a-b3ed-1808205ba24f",
   "metadata": {},
   "source": [
    "![Query to AST](../imgs/catalyst-Query-AST.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618656a7-8ca3-4303-9b40-ce6cdd74bf9b",
   "metadata": {},
   "source": [
    "### Абстрактное синтаксическое дерево - AST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb5795e-5089-45dc-94f7-b4c6f797c2ab",
   "metadata": {},
   "source": [
    "Абстрактное синтаксическое дерево (AST) позволяет представить текст запроса или порядок вызова методов DataFrame API в виде дерево для удобства анализа программными средствами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e70a1a-018e-493e-9083-55fdc3f13838",
   "metadata": {},
   "source": [
    "### Реляционное дерево"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167b9f4e-6cea-4e0a-8371-c9c3d76500a8",
   "metadata": {},
   "source": [
    "Реляционное дерево (relational algebra tree) - это способ визуального представления алгебраических выражений в реляционной алгебре. Основные строительные элементы реляционного дерева:\n",
    "\n",
    "- узлы для обозначения операций (выборки, проекции и т.д);\n",
    "- ребра для изображения потоков данных между операциями.\n",
    "\n",
    "Структура реляционного дерева облегчает анализ и понимание последовательности операций над данными. Трансформация реляционного дерева на базе математических свойств реляционных операций является _**оптимизацией**_ запроса.\n",
    "\n",
    "> План запроса == реляционное дерево запроса"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23364893-8e0e-47e3-8222-35e07995943b",
   "metadata": {},
   "source": [
    "### Основные понятия реляционной алгебры"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b469581-b096-4f36-8cd2-aa0c533f38e9",
   "metadata": {},
   "source": [
    "Перед продолжением обсуждения оптимизатора и оптимизации запросов необходимо вспомнить основные концепции реляцонной алгебры.\n",
    "\n",
    "Базовый набор понятий реляционной алгебры включает в себя следующие:\n",
    "\n",
    "| Название | Обозначение | Описание | Смысл |\n",
    "|----------|-------------|----------|---------|\n",
    "| Аттрибут (attribute) | текст  | Единица данных | Колонка в таблице |\n",
    "| Кортеж (tuple) | N/A | Группа аттрибутов | Строка в таблице |\n",
    "| Отношение (relation) | Прямоугольник | Коллекция кортежей (строчек) с атрибутами (колонками) | Таблица |\n",
    "| Проекция (projection) | `π` (пи) | Операция выбора подмножества из множества атрибутов кортежа | Список колонок, которые будут выбраны из таблицы |\n",
    "| Выборка (selection) | `σ` (сигма) | Операция выбора подмножества кортежей, атрибуты которого попадают по условию _выборки_ | `WHERE` или `HAVING` |\n",
    "| Объединение (union) | `∪` | Операция, которая на вход получает два отношения и возвращает новое отношение, в котором есть все кортежи исходных отношений. Операция _объединение_ заимствована из теории множеств, а поэтому ожидается, что дубликаты кортежей невозможны в итоговом отношении | `UNION` или `UNION ALL` |\n",
    "| Пересечение (intersection) | `∩` | Операция, которая на вход получает два отношения и возвращает новое отношение, в котором присутствуют только те кортежи, которые есть в обоих исходных отношениях. Операция _пересечение_ заимствована из теории множеств, а поэтому ожидается, что дубликаты кортежей невозможны в итоговом отношении | `INTERSECT` |\n",
    "| Разница (difference) | `-` | Операция, которая на вход получает два отношения и возвращает новое отношение, в котором присутствуют только те кортежи первого отношения, которых нет во втором отношении | `EXCEPT` (PostgreSQL) или `MINUS` (Oracle) |\n",
    "| Соединение (join) | `⨝`, `⟕`, `⟖`, `⟗` | Операция, которая на вход принимает два отношения и двуместный предикат (условие соединения). Результирующее отношение составляет подмножество декартового произведения исходных отношений, для кортежей которых предикат возвращает истинное значение | `JOIN ... ON (...)` |\n",
    "| Декартово произведение (cartesian product) | `×` | Операция, которая принимает на вход два отношения, а на выходе получается отношение, в котором каждому кортежу из одного исходного отношения ставятся в соответствие все кортежи в другом исходном отношении. Количество кортежей результирующего отношения будет равно произведению количества кортежей в первом и втором исходном отношении | Соединение таблиц без условия |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f880a723-160b-4bd0-a2b2-89b2a7c838e3",
   "metadata": {},
   "source": [
    "На практике к результирующему множеству строк могут применяться дополнительные требования. Для этих целей реляционную алгебру расширяют дополнительными операциями:\n",
    "\n",
    "| Название | Обозначение | Описание | Примеры |\n",
    "|----------|-------------|----------|---------|\n",
    "| Cортировка (sorting) | `τ` (тау) | Операция для сортировки множества | `ORDER BY` |\n",
    "| Переименование (rename) | `ρ` (ро) | Операция замены имени колонки или таблицы | `AS` |\n",
    "| Аггрегация (aggregation) | `γ` (гамма) | Операция вычисления значения на базе нескольких значений одного столбца | `min`, `max`, `agg`, `sum` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798e66c7-a206-453f-ae28-dc72e951134b",
   "metadata": {},
   "source": [
    "## Оптимизация запроса"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536eab6e-967e-450b-9608-92511d69f91b",
   "metadata": {},
   "source": [
    "Оптимизация запроса в Apache Spark выполняется при помощи оптимизатора Catalyst. Catalyst включает в себя 4 стадии:\n",
    "\n",
    "- **Unresolved Logical Plan** - разобранный запрос в виде дерева;\n",
    "- **Logical Plan** - разобранный запрос, в котором известно на какие объекты из каталога ссылается запрос;\n",
    "- **Optimized Logical Plan** - запрос, к которому были применены все возможные правила оптимизации;\n",
    "- **Physical Plan** - запрос в виде RDD DAG для выполнения на кластере Apache Spark.\n",
    "\n",
    "Объект \"Каталог\" (Catalog) хранит метаданные о текущем кластере: имена таблиц, UDF и др."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f74e3bd-10c1-42bf-abd9-efe7bb3b973d",
   "metadata": {},
   "source": [
    "![Catalyst](../imgs/catalyst-stages.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8effb85-6906-45c5-aa8d-f8b59f3ed402",
   "metadata": {},
   "source": [
    "### Правила оптимизации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121d8321-3ada-4b6d-ae05-96447a8fd69d",
   "metadata": {},
   "source": [
    "Для трансформации дерева запроса применяеются заранее подготовленные правила. Условие применения правила основывается на Pattern Matching: оптимизатор обходит дерево и в каждом узле пытается применить подходящие правила.\n",
    "\n",
    "Набор правил может выглядеть следующим образом:\n",
    "\n",
    "    1. Lit(x) * Lit(y) = Lit(y) * Lit(x) = Lit(x * y)\n",
    "    2. Lit(x) + Lit(y) =  Lit(y) + Lit(x) = Lit(x + y)\n",
    "    3. Lit(x) / Lit(y) = Lit(x / y)\n",
    "    4. x * Lit(0) = Lit(0) * x = Lit(0)\n",
    "    5. x + Lit(0) = Lit(0) + x = x\n",
    "    6. x * Lit(1) = Lit(1) * x = x\n",
    "    7. x / Lit(1) = x\n",
    "    8. x / Lit(0) = Lit(INF)\n",
    "\n",
    "Результат применения правил может выглядеть следующим образом:\n",
    "\n",
    "![Catalyst Rules](../imgs/catalyst-rules.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914b4e78-8b44-4feb-ba0d-7413ca6308e9",
   "metadata": {},
   "source": [
    "Правила могут применяться по цепочке:\n",
    "\n",
    "![Catalyst Rules Chain](../imgs/catalyst-rules-chain.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7be705d-8d1d-45f7-98b9-75fd63cc898a",
   "metadata": {},
   "source": [
    "Но как оптимизатор понимает, когда нужно остановиться? Есть несколько вариантов:\n",
    "\n",
    "1. оптимизатор имеет ограничение по времени: не важно сколько правил удалось применить, процесс останавливается через определенный промежуток времени;\n",
    "2. оптимизатор имеет ограничение на количество примененных правил: оптимизатор должен применить определенное количество правил и не важно сколько времени это займет;\n",
    "3. снижение стоимости плана не превышает некоторую малую величину $\\epsilon$ (эпсилон)\n",
    "4. ни одно правило больше нельзя применить: функция оптимизатора нашла неподвижную точку."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b564859-d25e-4af3-a0c7-c34cbc6a1c48",
   "metadata": {},
   "source": [
    "#### Неподвижная точка - Fixed Point, Fixpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2d5331-d0e7-4128-b0d5-c80be2e50ed1",
   "metadata": {},
   "source": [
    "**Неподвижной точкой** функции в математике называется такое значение аргумента, при котором значение функции равно значению аргумента. Примеры:\n",
    "\n",
    "1. для функции `f(x) = x` любое значение аргумента является неподвижной точкой: `f(1) = 1`, `f(2) = 2`, и т.д.;\n",
    "2. функция `f(x) = x * x` (парабола) имеет две неподвижной точки: 0 (`f(0) = 0 * 0 = 1`) и 1 (`f(1) = 1 * 1 = 1`);\n",
    "3. для функции `f(x) = x * x - 3 * x + 4` (парабола) неподвижной точкой является значение аргумента равное 2: `f(2) = 2 * 2 - 3 * 2 + 4 = 2`.\n",
    "\n",
    "Неподвижные точки также называют **инвариантами функции**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1158429d-b8a5-4f7e-9ae6-9184ebad4703",
   "metadata": {},
   "source": [
    "Если рассматривать оптимизатор как функцию `optimize` над множеством деревьев (AST, relational), которая, применяя правила оптимизации, преобразовывает входное дерево и возвращает новое дерево в качестве результата, то можно использовать неподвижную для остановки оптимизатора:\n",
    "\n",
    "    optimize: tree -> tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048a4c8e-3df6-4b29-a26a-ad715555a762",
   "metadata": {},
   "source": [
    "Ниже приведен пример остановки оптимизатора по достижению неподвижной точки (fixpoint). Деревья изображены в виде геометрических фигур для демонстрации того факта, что форма дерева изменяется после запуска функции `optimize`:\n",
    "\n",
    "![Fixed Point Optimizator](../imgs/catalyst-fixed-point.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9085bf-bfbd-41e7-909c-d825c182e801",
   "metadata": {},
   "source": [
    "Ниже приведен пример остановки оптимизации AST при помощи неподвижной точки:\n",
    "\n",
    "![AST Optimizer Stop](../imgs/catalyst-ast-fixpoint.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6e9e7f-d4aa-4ca1-927a-d58cbc91d25b",
   "metadata": {},
   "source": [
    "### Оптимизированный логический план - Optimized Logical Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47beb49e-4f91-4219-9a13-2cdfdd947701",
   "metadata": {},
   "source": [
    "За один обход дерева можно применить несколько правил оптимизации. Как решить какое из них выбрать? Apache Spark применяет каждое подходящее правило, а в результате появляется несколько деревьев. На следующем шаге уже к каждому новому дереву можно применить другие правила оптимизатора, таким образом количество полученных деревьев растет экспоненциально, и в конечном итоге получается несколько оптимизированных деревьев, которые представляют собой оптимизированный план исполнения запроса.\n",
    "\n",
    "Ниже на картике можно увидеть процесс оптимизации:\n",
    "\n",
    "- кружки означают дервья,\n",
    "- стрелки означают применение одного из правил оптимизации к дереву,\n",
    "- в самом конце остается список оптимизированных планов.\n",
    "\n",
    "![Optimized Trees](../imgs/catalyst-optimized-plan.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9155b372-1da2-4cdb-8b5c-3c5b29cc2108",
   "metadata": {},
   "source": [
    "### Физический план - Physical Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73351ac0-3a5f-49b9-8ac0-d26e9ff1f7f9",
   "metadata": {},
   "source": [
    "Логические планы оперируют понятиями реляционной алгебры, но у каждого шага логического плана есть физический смысл:\n",
    "\n",
    "- Relation (отношение, таблица) == FileScan (сканирование файла);\n",
    "- Projection (проекция, колонка) == Push-down projection (ограничение сканирования файла);\n",
    "- Aggregate (агрегация) == HashAggregate;\n",
    "- и т.д.\n",
    "\n",
    "После получения логических планов, каждому из них сопоставляется физический план, который работает с конкретными реализациями алгоритмов и структур данных и готов для запуска на кластере. В силу того, что Apache Spark кластер может работать только с RDD, получается, что физический план - это RDD. Прямое использование RDD API лишает преимуществ оптимизации, которую дает Catalyst.\n",
    "\n",
    "> Работа с RDD API напрямую отключает Catalyst и всю оптимизацию в целом!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96161d85-97cb-4bc9-80b7-bcd154d4af5c",
   "metadata": {},
   "source": [
    "### Стоимостная модель - Cost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3275cf-d1ae-4f66-b2b4-b577f52df31b",
   "metadata": {},
   "source": [
    "Оптимизатор может сгенерировать несколько планов, из которых нужно выбрать наиболее быстрый. Для поиска наиболее быстрого плана используется стоимостная модель (cost model).\n",
    "\n",
    "Стоимостная модель позволяет оценить на сколько быстро запрос может отработать по указанному плану. Стоимостная модель опирается на статистику. Источником статистики может служить сканируемый файл. Например, `parquet` файл имеет раздел с метаданными из которого можно понять сколько строк хранится в файле, какие есть row groups, размеры страниц и многое другое. Статистику также можно собрать заранее, но использовать ее можно будет только при использовании Spark SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42857602-5d0e-4f60-985f-12ce6cd4e2ee",
   "metadata": {},
   "source": [
    "## Анализ плана запроса"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4920b4-b4a9-4559-bbbd-090182acb965",
   "metadata": {},
   "source": [
    "### Получение плана запроса"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7f0d4f-0475-4970-9d35-3653236a6693",
   "metadata": {},
   "source": [
    "План запроса можно посмотреть двумя способами:\n",
    "\n",
    "1. DataFrame API,\n",
    "2. Spark UI.\n",
    "\n",
    "При этом необходимо использовать оба способа совместно, т.к. каждый из них может предоставить дополнительную информацию, которой нет в другом способе."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a8f129-0171-4e63-8c41-7c1a096df18b",
   "metadata": {},
   "source": [
    "### DataFrame API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70eb1f7-b2e9-4fd3-a1ed-2ef3185b2c0e",
   "metadata": {},
   "source": [
    "Для получения плана запроса через DataFrame API необходимо вызвать функцию [DataFrame#explain](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.explain.html) на объекте `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c176cd7a-2e0c-4259-9679-e243450eb240",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_many_part_df = spark.read.parquet(\"/tmp/taxi_many\")\n",
    "taxi_many_part_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f0a41a-75e2-4c29-adb1-3c6c9fe4e666",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_many_part_df \\\n",
    "    .select(F.count(F.lit(1))) \\\n",
    "    .explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20196d4-d68d-4686-a772-34bf06ec2afc",
   "metadata": {},
   "source": [
    "Вызов метода [DataFrame#explain](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.explain.html) без параметров показывает только физический план, в котором находятся конкретные операции уровня исполнения: сканирование файлов, конкретные реализации функций для агрегатов, сортировки и т.д. Указав дополнительные параметры, можно получить больше информации:\n",
    "\n",
    "1. `extended` (`False` по умолчанию). Если указать `True`, то можно получить план запроса с каждого шага оптимизатора Catalyst:\n",
    "    - Unresolved Logical Plan,\n",
    "    - Resolved Logical Plan,\n",
    "    - Optimized Logical Plan,\n",
    "    - Physical Logical Plan.\n",
    "1. `mode` (`simple` по умолчанию) - указать формат плана запроса:\n",
    "    - `simple` - напечатать только физический план запроса;\n",
    "    - `extended` - аналогично `explain(extended=True)`;\n",
    "    - `codegen` - напечатать `java` код, который будет выполняться, если присутствует стадия `WholeStageCodeGen`;\n",
    "    - `cost` - показать статистику, если доступно;\n",
    "    - `formatted` - показать физический план в формате аналогичном Spark UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a4f582-8e87-4d48-b55e-c93e459fe000",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_many_part_df \\\n",
    "    .select(F.count(F.lit(1))) \\\n",
    "    .explain(mode=\"cost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa0187c-5326-48c3-9681-e58cd54c454c",
   "metadata": {},
   "source": [
    "#### Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95444a5e-c2cf-44b9-ad98-2d2ff1752b6a",
   "metadata": {},
   "source": [
    "Получить план запроса со статистикой для количества строк с непустым значением `passenger_count`. Сравнить цифры с предыдущим запроса (предыдущая клетка/cell в текщем ноутбуке)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca91165d-ec97-44b6-ada4-46a3c364013e",
   "metadata": {},
   "source": [
    "#### Особенности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40adc317-fa51-4175-860e-30adb96fb12e",
   "metadata": {},
   "source": [
    "При помощи DataFrame API можно получить план запроса без запуска самого запроса на исполнение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d8b331-4ec9-4bc2-bba5-717e915e0826",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT 'Hello, World!' as greet\").explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd38d158-c2b2-4953-857b-7399c9b9c89f",
   "metadata": {},
   "source": [
    "Такая особенность может быть полезной, когда нет желания выполнять большой запрос, чтобы просто посмотреть план запроса. С другой стороны через DataFrame API нельзя получить план запроса для конструкции вида:\n",
    "\n",
    "    total_rows = taxi_many_part_df.count()\n",
    "\n",
    "Здесь `taxi_many_part_df` является датафреймом на базе паркетного файла, но при этом [`DataFrame#count`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.count.html) является операцией-действием (action) и немедленно запускает DAG на исполнение. Получить план такого запроса можно только через Spark UI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150c5adb-b209-4a30-b9df-cf0347770c2c",
   "metadata": {},
   "source": [
    "### Spark UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e20a356-39f8-4a42-8af1-67f4f1cea2e9",
   "metadata": {},
   "source": [
    "Spark UI позволяет посмотреть план запроса в виде графа, а также подробную статистику по каждой операции. Эта информация может быть полезной при анализе исполнения запроса и поиска традиционных проблем с производительностью, связанных с перекосом (skew) данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a5aee5-ff84-44b5-973b-ceb14b95365c",
   "metadata": {},
   "source": [
    "Недостатком Spark UI является тот факт, что граф запроса может не помещаться на страницу, но план запроса - это SVG картинка, которая может изменять масштаб без потери качества.\n",
    "\n",
    "Совет:\n",
    "\n",
    "> Если план запроса очень большой, то рекомендуется уменьшить масштаб страницы до такой степени, чтобы весь план запроса помещался.\n",
    "\n",
    "Уменьшение масштаба позволяет визуально оценить весь план и заметить некоторые закономерности, повторяющиеся части и т.д. Высокоуровневое понимание запроса позволит эффективнее анализировать запрос по частям в дальнейшем"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4145ad9b-f474-44ae-848d-21640544b62c",
   "metadata": {},
   "source": [
    "## Примеры оптимизаций"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beba2820-2159-4541-a6bf-8224c54bf564",
   "metadata": {},
   "source": [
    "Примеры оптимизаций будут рассматриваться на базе следующего запроса:\n",
    "\n",
    "![Relational Tree](../imgs/rel-tree.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e784b7f5-6362-4efc-993e-03b477607f68",
   "metadata": {},
   "source": [
    "### Pushed Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a498621-f866-4f7e-955d-59b24a686336",
   "metadata": {},
   "source": [
    "Самым простым, но в то же время исключительно эффективным правилом оптимизации является **Pushed Filter**. Это правило переносит узел `Selection` или `Filter` реляционного дерева на уровень сканирования файла, что позволяет сканировать меньше данных на диске, повышая общую производительность запроса:\n",
    "\n",
    "![Pushed Filters](../imgs/catalyst-pushed-filters.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3845a9ed-2ed1-4d1f-8ac7-6b689f5d48a1",
   "metadata": {},
   "source": [
    "#### Эффективность"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5a00bf-02b5-4409-bd97-731e677a9586",
   "metadata": {},
   "source": [
    "Дано: В таблице `emps` 1M строк, 20% (200 000) из которых имеют значение `salary` больше `1000`. В таблице `depts` 500 строк.\n",
    "\n",
    "Было: В соединении `emps` и `depts` участвовало 1 000 000 * 500 = 500 000 000 строк\n",
    "\n",
    "Стало: Перед соединением с файловой системы сканируется 200 000 строк, тогда в соединении `emps` и `depts` участвует 200 000 * 500 = 100 000 000 строк. Ускорение в 5 раз!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba58b93-ad76-462a-acea-97ee0cdf5c0e",
   "metadata": {},
   "source": [
    "### Pushed Projections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841bdaed-6e14-4199-ad60-12e318b5a1a2",
   "metadata": {},
   "source": [
    "Подобно сокращению числа сканируемых строк при помощи фильтрации, правило Pushed Projections позволяет сократить количество сканируемых столбцов:\n",
    "\n",
    "![Pushed Projections](../imgs/catalyst-pushed-projections.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bfa08d-671f-4181-9474-6881fc182e54",
   "metadata": {},
   "source": [
    "#### Эффективность"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff4069c-60aa-4358-b706-1c725f7ca69a",
   "metadata": {},
   "source": [
    "Дано: В таблица `emps` состоит из 1M строк из 50 колонок по 30 байт на значение в среднем, 20% (200 000) из которых имеют значение `salary` больше `1000`. В таблице `depts` 500 строк и 10 колонок по 30 байт на значение в среднем.\n",
    "\n",
    "**Было**: В соединении `emps` и `depts` участвовало:\n",
    "\n",
    "    - со стороны `emps` 200 000 строк по 50 колонок по 30 байт на колонку => 200 000 * 50 * 30 = 300 000 000 байт = 300 МБ;\n",
    "    - со стороны `depts` 500 строк по 10 колонок по 30 байт на колонку => 500 * 10 * 30 = 150 000 байт = 150 КБ.\n",
    "\n",
    "**Стало**: Перед соединением `emps` и `depts` сканируется:\n",
    "\n",
    "    - со стороны `emps` 200 000 строк по 3 колонки по 30 байт на колонку => 200 000 * 3 * 30 = 18 000 000 байт = 18 МБ => Снижение трафика в 16 раз (300 / 18);\n",
    "    - со стороны `depts` 500 строк по 2 колонки по 30 байт на колонку => 500 * 2 * 30 = 30 000 байт = 30 КБ => Снижение трафика в 5 раз."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d0aa20-1ff1-45bc-958c-3f85cbd1ff3f",
   "metadata": {},
   "source": [
    "### Демонстрация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fa07ac-59ac-4497-9c67-50e667e6dea4",
   "metadata": {},
   "source": [
    "Подготовить датафрейм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd8d0bc-41bf-470d-ad63-00ecc5ebed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_many_part_df = spark.read.parquet(\"/tmp/taxi_many\")\n",
    "taxi_many_part_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4604fbb4-00ff-4ca6-8e16-b35310654dba",
   "metadata": {},
   "source": [
    "На базе низкокардинальной колонки `PULocationID` создается новый датафрейм для местоположений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5387a98-ac7f-4395-9677-6c14560b96b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_df = (\n",
    "    taxi_many_part_df\n",
    "        .select(col(\"PULocationID\").alias(\"id\"))\n",
    "        .distinct()\n",
    "        .withColumn(\"name\", F.rand())\n",
    ")\n",
    "\n",
    "locations_df.write.mode(\"overwrite\").parquet(\"/tmp/locations\")\n",
    "\n",
    "locations_df = spark.read.parquet(\"/tmp/locations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516f6622-7eda-4610-8ef4-64fec96b192d",
   "metadata": {},
   "source": [
    "Соединение датафреймов `taxi_many_part_df` и `locations_df` демонстрирует применение правил **Pushed filters** и **Pushed Projections**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d8f6b2-1e93-44d3-81f5-9537e56bd515",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)\n",
    "\n",
    "result_df = (\n",
    "    taxi_many_part_df\n",
    "        .join(locations_df, col(\"PULocationID\") == col(\"id\"))\n",
    "        .where(\"passenger_count > 5\")\n",
    "        .orderBy(\"name\")\n",
    "        .select(\"VendorID\", \"trip_distance\", \"name\")\n",
    ")\n",
    "result_df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45495e1-15dc-4177-8c44-0a52616705b4",
   "metadata": {},
   "source": [
    "На плане видно, что выполнились оба правила оптимизации: Pushed Filters и Pushed Projections. Дополнительно была использована цветовая индикация для подсветки колонок: одна колонка == один цвет\n",
    "\n",
    "![Catalyst Rules Demo](../imgs/catalyst-rules-demo.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e41ef14-eec4-4f5f-b42e-5b1b55366de6",
   "metadata": {},
   "source": [
    "## Адаптивный оптимизатор запросов - Adaptive Query Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d19a63a-c8e3-41b2-b0c1-7d2bee9abfc7",
   "metadata": {},
   "source": [
    "Адаптивный оптимизатор запросов (Adaptive Query Execution, AQE) собирает статистику во время выполнения запроса и может изменять его план, если, согласно статистике, найден более эффективный способ исполнения запроса.\n",
    "\n",
    "Адаптивный оптимизатор запросов появился в Apache Spark 3.0 и активирован по умолчанию. Чтобы проверить, что AQE включен, необходимо проверить значение опции `spark.sql.adaptive.enabled`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f36355-5b31-4fc4-b3e7-dd87768f118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "active = \"Включен\" if spark.conf.get(\"spark.sql.adaptive.enabled\") == \"true\" else \"Выключен\"\n",
    "\n",
    "print(f\"Адаптивный оптимизатор запросов: {active}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc5c091-8093-4509-acc6-d89f1daab568",
   "metadata": {},
   "source": [
    "В AQE входят три оптимизации:\n",
    "\n",
    "- замена стратегии соединений таблиц (join) на Broadcast JOIN (Converting sort-merge join to broadcast join),\n",
    "- разбиение перекошенных (skew) партиций (Optimizing Skew Join),\n",
    "- объединение партиций небольшого размера (Coalescing Post Shuffle Partitions).\n",
    "\n",
    "Настройка `spark.sql.adaptive.enabled` является \"зонтиком\" над этими тремя оптимизациями. Если `spark.sql.adaptive.enabled` отключена, то ни одна оптимизация AQE не будет доступна."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cf02a2-e3ad-48fc-bf66-6b2294dfd888",
   "metadata": {},
   "source": [
    "### Замена стратегии соединения таблиц на Broadcast JOIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977b6126-5424-497d-860b-006b76af767b",
   "metadata": {},
   "source": [
    "Apache Spark по умолчанию выбирает Sort Merge Join в качестве стратегии соединения (join) таблиц по умолчанию, т.к. Sort Merge Join позволяет гарантировано обработать данные любого размера. Sort Merge Join не может похвастаться высокой производительностью. Стратегия Broadcast Join является самой быстрой стратегией соединения таблиц, но при этом она более требовательна к оперативной памяти: необходимо один из датафреймов полностью скопировать в память каждого воркера."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36675fea-a170-4884-a36f-be872cef36db",
   "metadata": {},
   "source": [
    "#### Условия активации Broadcast JOIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8a599e-74ff-4763-91bd-35406f336882",
   "metadata": {},
   "source": [
    "Для активации Broadcast JOIN необходимо указать пороговое значение в байтах через настройку `spark.sql.autoBroadcastJoinThreshold`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d6efc3-2547-4c7b-86b2-cfcd0f4caadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", 10 * 1024 * 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89deb36-1f89-4c93-b086-9535b980b62c",
   "metadata": {},
   "source": [
    "Значением по умолчанию является 10МБ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc78f8d-3937-436f-979f-b9ed63194587",
   "metadata": {},
   "source": [
    "### Разбиение перекошенных партиций"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e734e36-51f8-4727-9a15-b5dced5c9f0d",
   "metadata": {},
   "source": [
    "Неравномерное распределение данных по партициям является одной из самых больших проблем при работе с Apache Spark. Ниже приведен пример датафрейма, в котором одна из партиций на много больше остальных:\n",
    "\n",
    "![](../imgs/catalyst-skewed-partitions.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4390597-14c0-4cbf-ba68-4b3c186edb45",
   "metadata": {},
   "source": [
    "Обработка подобного датафрейма будет тормозить процесс, потому что стадия (stage) не может завершиться, пока не завершены все задания (task) в стадии. Ниже приведен пример обработки датафрейма с перекосом данных по партициям:\n",
    "\n",
    "![](../imgs/catalyst-skewed-partitions-processing.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ed1da2-e479-42d6-b91f-f3ae38604fa2",
   "metadata": {},
   "source": [
    "Из картики видно, что два воркера простаивали большую часть времени, т.к. необходимо было дождаться завершения обработки задачи по партиции `P1`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaf906e-e03e-464e-bfa3-2a539f336c65",
   "metadata": {},
   "source": [
    "AQE Optimizing Skew Join оптимизация может автоматически разбить большие партиции на партиции меньшего размера, увеличивая таким образом скорость обработки запроса:\n",
    "\n",
    "![](../imgs/catalyst-aqe-skew-partitions.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bb7115-e508-4027-84af-270ee1ad7fb3",
   "metadata": {},
   "source": [
    "Но работать эта оптимизация будет только во время соединений таблиц (JOIN): AQE Skew Join не используется, если в запросе нет JOIN\n",
    "\n",
    "> **AQE Skewed join работает только с JOIN запросами**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5c39ae-3c28-4025-beb2-bc3504c8c93d",
   "metadata": {},
   "source": [
    "#### Условия активации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059c7db5-5583-4468-9f91-a19f3ae223a4",
   "metadata": {},
   "source": [
    "По умолчанию AQE Optimizing Skew Join оптимизация включена. Дополнительно можно проверить значение настройки `spark.sql.adaptive.skewJoin.enabled`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a09d300-56f3-421a-ac92-1a8cd325336a",
   "metadata": {},
   "outputs": [],
   "source": [
    "active = \"Включен\" if spark.conf.get(\"spark.sql.adaptive.skewJoin.enabled\") == \"true\" else \"Выключен\"\n",
    "\n",
    "print(f\"AQE Optimizing Skew Join: {active}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db7f068-34f7-4046-b95b-84e40ab16191",
   "metadata": {},
   "source": [
    "Не любая большая партция может считаться перекошенной, для этого необходимо чтобы выплнялись два условия:\n",
    "\n",
    "- партиция больше среднего размера остальных партиций в `spark.sql.adaptive.skewJoin.skewedPartitionFactor` раз (по умолчанию в 5 раз),\n",
    "- партиция превышает по размеру значение `spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes` (по умолчанию в 256МБ)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132bffe9-ae90-4609-9160-6474fe69da8c",
   "metadata": {},
   "source": [
    "AQE Optimizing Skewed Join может не активироваться, т.к. она привносит дополнительную операцию перемешивания (Shuffle), а Catalyst может найти более быстрый план.\n",
    "\n",
    "Для принудительной активации оптимизации AQE Optimizing Skewed Join в Apache Spark 3.3.0 появилась настройка `spark.sql.adaptive.forceOptimizeSkewedJoin`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccdd709-91e3-411b-8186-2f490cddae0c",
   "metadata": {},
   "source": [
    "### Объединение партиций небольшого размера"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f7ac09-9977-4b5a-9de0-cc5f821d70d3",
   "metadata": {},
   "source": [
    "Apache Spark создает `spark.sql.shuffle.partitions` партиций после перемешивания (shuffle), но может так получиться, что какие-то из партиций получаются очень маленького размера. AQE может автоматически объединить их при помощи **Coalescing Post Shuffling Partitions** (без дополнительных Shuffle операций).\n",
    "\n",
    "![](../imgs/catalyst-post-shuffle-coalesce.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3704a555-363a-487d-bf32-0f6e4d18828d",
   "metadata": {},
   "source": [
    "#### Условия активации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258dfb9a-157d-4bde-b135-85b46568eeaf",
   "metadata": {},
   "source": [
    "По умолчанию **AQE Coalescing Post Shuffle Partitions** оптимизация включена. Дополнительно можно проверить значение настройки `spark.sql.adaptive.coalescePartitions.enabled`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7db3bb-877c-473c-bb27-d55d1851e214",
   "metadata": {},
   "outputs": [],
   "source": [
    "active = \"Включен\" if spark.conf.get(\"spark.sql.adaptive.coalescePartitions.enabled\") == \"true\" else \"Выключен\"\n",
    "\n",
    "print(f\"AQE Coalescing Post Shuffle Partitions: {active}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133ea3d8-c6d4-40e5-b929-b6d022e5ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setJobDescription(\"Сгенерировать датафреймы\")\n",
    "\n",
    "source = spark.range(1, 10000, 1, 10).toDF(\"id\")\n",
    "left = source.select(F.expr(\"id % 3\").alias(\"id\"), col(\"id\").alias(\"value\")) \n",
    "right = source.select(F.lit(0).alias(\"id\"), col(\"id\").alias(\"value\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645e66fc-3996-4ac1-8fe2-a960491ae39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "left.write.mode(\"overwrite\").parquet(\"/tmp/left\")\n",
    "right.write.mode(\"overwrite\").parquet(\"/tmp/right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a8e351-9b00-4526-845a-85dbd72f342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "left = spark.read.parquet(\"/tmp/left\")\n",
    "right = spark.read.parquet(\"/tmp/right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cff1aa-f5dd-4fc2-97af-26a3c3d0a26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setJobDescription(\"Получить распределение по партициям в `left`\")\n",
    "\n",
    "left.groupBy(F.spark_partition_id()).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519b10d3-938c-4b08-a133-eb14d50650c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setJobDescription(\"Получить распределение по партициям в `right`\")\n",
    "\n",
    "right.groupBy(F.spark_partition_id()).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9271acf6-c0a3-45e5-a1da-5038c2c1cc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setJobDescription(\"Соединить `left` и `right`\")\n",
    "\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)\n",
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\", True)\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 77)\n",
    "\n",
    "left.join(right, \"id\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f43273-af9b-4d9a-9e68-16d8887ef9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setJobDescription(\"Соединить `left` и `right`: Без автоматического слияния партций\")\n",
    "\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)\n",
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\", False)\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 77)\n",
    "\n",
    "left.join(right, \"id\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d326f79c-09ef-4cc0-8cf3-842d0ab8a8f3",
   "metadata": {},
   "source": [
    "На плане видно:\n",
    "\n",
    "1. оптимизатор добавил дополнительный узел `AQEShuffleRead` в план с автоматическим слиянием партиций,\n",
    "2. После `AQEShuffleRead` количество партиций снизилось до 1 в плане с автоматическим слиянием партиций.\n",
    "\n",
    "\n",
    "![](../imgs/catalyst-post-shuffle-coalesce-plan.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edd78c0-c2de-4573-9aba-a1e7934d6f82",
   "metadata": {},
   "source": [
    "#### Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04305526-4787-4b6e-b42f-0d006403e14f",
   "metadata": {},
   "source": [
    "1. Сколько заданий (task) было выполнено в запросе с AQE Coalescing Post Shuffle Partitions?\n",
    "1. Сколько заданий (task) было выполнено в запросе без AQE Coalescing Post Shuffle Partitions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a771f7f3-ceba-4f9b-85d8-02a23cf9972b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
